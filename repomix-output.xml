This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
msme_underwriting/
  agents/
    __init__.py
    base.py
    document_classification.py
  config/
    __init__.py
    settings.py
  models/
    __init__.py
    banking.py
    base.py
    documents.py
    entity.py
    final_report.py
    financial.py
    kmp.py
    loan_application.py
    state.py
    verification.py
  services/
    __init__.py
    document_processing.py
    external_apis.py
  __init__.py
  orchestrator.py
env.example
pyproject.toml
README.md
requirements.txt
specs.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="msme_underwriting/agents/__init__.py">
"""Agents for MSME loan underwriting workflow."""

from .base import BaseAgent
from .document_classification import DocumentClassificationAgent
from .entity_kmp_identification import EntityKMPIdentificationAgent
from .verification_compliance import VerificationComplianceAgent
from .financial_analysis import FinancialAnalysisAgent
from .banking_analysis import BankingAnalysisAgent
from .final_assembly import FinalAssemblyAgent

__all__ = [
    "BaseAgent",
    "DocumentClassificationAgent",
    "EntityKMPIdentificationAgent", 
    "VerificationComplianceAgent",
    "FinancialAnalysisAgent",
    "BankingAnalysisAgent",
    "FinalAssemblyAgent",
]
</file>

<file path="msme_underwriting/agents/base.py">
"""Base agent class for MSME loan underwriting agents."""

import logging
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, Optional

from ..models.state import MSMELoanState
from ..models.base import ProcessingResult, ProcessingMetadata, RoutingDecision
from ..config import settings

logger = logging.getLogger(__name__)


class BaseAgent(ABC):
    """
    Base class for all MSME loan underwriting agents.
    
    This class provides common functionality for all agents including
    logging, error handling, and state management.
    """
    
    def __init__(self, agent_name: str):
        """Initialize the base agent."""
        self.agent_name = agent_name
        self.logger = logging.getLogger(f"{__name__}.{agent_name}")
        self.start_time: Optional[datetime] = None
        self.api_calls_made = 0
        self.total_api_cost = 0.0
    
    async def process(self, state: MSMELoanState) -> ProcessingResult:
        """
        Process the loan application state.
        
        Args:
            state: Current loan application state
            
        Returns:
            Processing result with updated data and routing decision
        """
        self.start_time = datetime.utcnow()
        self.api_calls_made = 0
        self.total_api_cost = 0.0
        
        try:
            self.logger.info(f"Starting {self.agent_name} processing for thread {state.thread_id}")
            
            # Validate prerequisites
            self._validate_prerequisites(state)
            
            # Execute agent-specific processing
            result = await self._execute_processing(state)
            
            # Create processing metadata
            end_time = datetime.utcnow()
            processing_metadata = ProcessingMetadata(
                start_time=self.start_time,
                end_time=end_time,
                total_processing_time=(end_time - self.start_time).total_seconds(),
                api_calls_made=self.api_calls_made,
                total_api_cost=self.total_api_cost
            )
            
            # Create processing result
            processing_result = ProcessingResult(
                agent_name=self.agent_name,
                processing_status="completed",
                thread_id=state.thread_id,
                processing_metadata=processing_metadata,
                next_action=result.get("next_action", "proceed"),
                routing_decision=result.get("routing_decision", self._default_routing_decision())
            )
            
            # Add agent-specific results to the processing result
            for key, value in result.items():
                if key not in ["next_action", "routing_decision"]:
                    setattr(processing_result, key, value)
            
            self.logger.info(f"Completed {self.agent_name} processing for thread {state.thread_id}")
            return processing_result
            
        except Exception as e:
            self.logger.error(f"Error in {self.agent_name} processing: {str(e)}")
            
            # Create error processing result
            end_time = datetime.utcnow()
            processing_metadata = ProcessingMetadata(
                start_time=self.start_time or datetime.utcnow(),
                end_time=end_time,
                total_processing_time=(end_time - (self.start_time or datetime.utcnow())).total_seconds(),
                api_calls_made=self.api_calls_made,
                total_api_cost=self.total_api_cost
            )
            
            error_result = ProcessingResult(
                agent_name=self.agent_name,
                processing_status="failed",
                thread_id=state.thread_id,
                processing_metadata=processing_metadata,
                next_action="error_handling",
                routing_decision=RoutingDecision(
                    next_agent="error_handler",
                    routing_reason=f"Error in {self.agent_name}: {str(e)}",
                    conditions_met=[],
                    bypass_conditions=[]
                )
            )
            
            # Add error details
            setattr(error_result, "error", str(e))
            
            return error_result
    
    @abstractmethod
    async def _execute_processing(self, state: MSMELoanState) -> Dict[str, Any]:
        """
        Execute agent-specific processing logic.
        
        Args:
            state: Current loan application state
            
        Returns:
            Dictionary containing processing results
        """
        pass
    
    @abstractmethod
    def _validate_prerequisites(self, state: MSMELoanState) -> None:
        """
        Validate that prerequisites for this agent are met.
        
        Args:
            state: Current loan application state
            
        Raises:
            ValueError: If prerequisites are not met
        """
        pass
    
    def _default_routing_decision(self) -> RoutingDecision:
        """Get default routing decision for this agent."""
        return RoutingDecision(
            next_agent="next_agent",
            routing_reason="Default routing",
            conditions_met=[],
            bypass_conditions=[]
        )
    
    def _log_api_call(self, api_name: str, cost: float = 0.0) -> None:
        """Log an API call."""
        self.api_calls_made += 1
        self.total_api_cost += cost
        self.logger.debug(f"API call to {api_name}, cost: ${cost:.4f}")
    
    def _validate_business_rules(self, state: MSMELoanState, rule_name: str, value: Any, threshold: Any) -> bool:
        """
        Validate a business rule.
        
        Args:
            state: Current state
            rule_name: Name of the rule
            value: Value to check
            threshold: Threshold to compare against
            
        Returns:
            True if rule passes, False otherwise
        """
        try:
            if rule_name == "minimum_kmp_coverage":
                return value >= threshold
            elif rule_name == "minimum_consumer_cibil":
                return value >= threshold
            elif rule_name == "maximum_commercial_cmr":
                return value <= threshold
            elif rule_name == "eligible_constitutions":
                return value in threshold
            else:
                self.logger.warning(f"Unknown business rule: {rule_name}")
                return True
        except Exception as e:
            self.logger.error(f"Error validating business rule {rule_name}: {str(e)}")
            return False
    
    def _get_business_rule_value(self, state: MSMELoanState, rule_name: str) -> Any:
        """Get business rule value from state or settings."""
        if rule_name in state.business_rules:
            return state.business_rules[rule_name]
        
        # Fallback to settings
        return getattr(settings, rule_name, None)
    
    def _create_validation_warning(self, warning_type: str, message: str, 
                                 severity: str = "medium") -> Dict[str, Any]:
        """Create a validation warning."""
        return {
            "type": warning_type,
            "message": message,
            "severity": severity,
            "agent": self.agent_name,
            "timestamp": datetime.utcnow()
        }
    
    def _calculate_confidence_score(self, scores: list[float]) -> float:
        """Calculate average confidence score from a list of scores."""
        if not scores:
            return 0.0
        return sum(scores) / len(scores)
    
    def _is_high_confidence(self, score: float) -> bool:
        """Check if a confidence score is considered high."""
        return score >= settings.high_confidence_threshold
    
    def _meets_minimum_confidence(self, score: float) -> bool:
        """Check if a confidence score meets minimum threshold."""
        return score >= settings.minimum_document_confidence
</file>

<file path="msme_underwriting/agents/document_classification.py">
"""
Agent 1: Document Classification & Extraction Agent

This agent transforms user-uploaded files into classified, structured data using 
the existing PDF/Image Processing Service and prepares data for entity analysis.
"""

import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime

from ..models.state import MSMELoanState
from ..models.documents import (
    ClassifiedDocuments, DocumentAnalysis, ExtractedDocument, 
    DocumentClass, MissingDocument, ValidationWarning,
    PANCardData, AadhaarCardData, GSTCertificateData, 
    PartnershipDeedData, FinancialStatementData, BankStatementData
)
from ..models.base import RoutingDecision
from ..services.document_processing import DocumentProcessingService
from ..services.external_apis import FileStorageService
from .base import BaseAgent


class DocumentClassificationAgent(BaseAgent):
    """
    Agent 1: Document Classification & Extraction Agent
    
    Responsibilities:
    1. Validate loan type and file uploads
    2. Call existing PDF/Image Processing Service
    3. Parse and normalize structured data
    4. Apply MSME-specific document classification
    5. Identify financial documents (2 years audited + 1 year provisional)
    6. Detect banking documents for all declared accounts
    7. Map documents to borrower vs KMPs
    8. Analyze missing documents
    9. Assess data quality
    """
    
    def __init__(self):
        """Initialize the document classification agent."""
        super().__init__("document_classification")
        self.document_service = DocumentProcessingService()
        self.file_storage = FileStorageService()
        
        # Document classification rules
        self.msme_required_documents = {
            "borrower": ["pan_card", "gst_certificate"],
            "kmp": ["pan_card", "aadhaar_card"],
            "business": ["partnership_deed", "moa_aoa"],
            "financial": ["audited_financials_2yr", "provisional_financials_1yr", "itr_documents"],
            "banking": ["bank_statements"],
            "gst": ["gst_returns"]
        }
        
        # Financial document requirements
        self.financial_requirements = {
            "audited_financials_required": 2,
            "provisional_financials_required": 1,
            "itr_documents_required": 3
        }
    
    def _validate_prerequisites(self, state: MSMELoanState) -> None:
        """Validate prerequisites for document classification."""
        if not state.loan_application:
            raise ValueError("Loan application data is required")
        
        if not state.loan_application.uploaded_files:
            raise ValueError("No uploaded files found")
        
        # Validate loan type
        loan_type = state.loan_application.loan_context.loan_type
        if loan_type != "MSM_supply_chain":
            raise ValueError(f"Unsupported loan type: {loan_type}")
    
    async def _execute_processing(self, state: MSMELoanState) -> Dict[str, Any]:
        """Execute document classification and extraction."""
        loan_app = state.loan_application
        
        # Step 1: Validate loan type and files
        self._validate_loan_type(loan_app.loan_context.loan_type)
        self._validate_uploaded_files(loan_app.uploaded_files)
        
        # Step 2: Call document processing service
        processing_response = await self._call_document_processing_service(
            loan_app.uploaded_files,
            loan_app.processing_options
        )
        
        # Step 3: Parse and normalize structured data
        extracted_documents = await self._parse_processing_response(processing_response)
        
        # Step 4: Apply MSME document classification
        classified_documents = self._classify_documents_for_msme(extracted_documents)
        
        # Step 5: Identify financial documents
        self._identify_financial_documents(classified_documents)
        
        # Step 6: Identify banking documents
        self._identify_banking_documents(classified_documents)
        
        # Step 7: Map documents to entities
        self._map_documents_to_entities(classified_documents)
        
        # Step 8: Analyze missing documents
        missing_documents = self._analyze_missing_documents(classified_documents)
        
        # Step 9: Assess data quality
        validation_warnings = self._assess_data_quality(classified_documents)
        
        # Step 10: Create document analysis
        document_analysis = self._create_document_analysis(
            classified_documents, extracted_documents
        )
        
        # Determine routing decision
        routing_decision = self._determine_routing_decision(
            classified_documents, missing_documents, validation_warnings
        )
        
        return {
            "classified_documents": classified_documents,
            "document_analysis": document_analysis,
            "missing_documents": missing_documents,
            "validation_warnings": validation_warnings,
            "next_action": "proceed_to_entity_analysis",
            "routing_decision": routing_decision
        }
    
    def _validate_loan_type(self, loan_type: str) -> None:
        """Validate loan type matches MSM Supply Chain Finance requirements."""
        if loan_type != "MSM_supply_chain":
            raise ValueError(f"Invalid loan type: {loan_type}. Expected: MSM_supply_chain")
        
        self.logger.info(f"Loan type validation passed: {loan_type}")
    
    def _validate_uploaded_files(self, uploaded_files: List[Any]) -> None:
        """Validate uploaded files against business rules."""
        if not uploaded_files:
            raise ValueError("No files uploaded")
        
        total_size = sum(file.file_size for file in uploaded_files)
        max_size = 50 * 1024 * 1024  # 50MB
        
        if total_size > max_size:
            raise ValueError(f"Total file size ({total_size}) exceeds maximum ({max_size})")
        
        # Validate file types
        allowed_types = ["application/pdf", "image/jpeg", "image/png", "application/zip"]
        for file in uploaded_files:
            if file.file_type not in allowed_types:
                raise ValueError(f"Unsupported file type: {file.file_type}")
        
        self.logger.info(f"File validation passed: {len(uploaded_files)} files, {total_size} bytes")
    
    async def _call_document_processing_service(self, uploaded_files: List[Any], 
                                              processing_options: Any) -> Dict[str, Any]:
        """Call the existing PDF/Image Processing Service."""
        try:
            self.logger.info("Calling document processing service")
            
            # Prepare request payload
            request_payload = {
                "files": [
                    {
                        "file_name": file.file_name,
                        "file_path": file.file_path,
                        "file_type": file.file_type
                    }
                    for file in uploaded_files
                ],
                "processing_options": {
                    "max_pages_per_document": processing_options.max_pages_per_document,
                    "include_raw_responses": processing_options.include_raw_responses,
                    "vision_model": processing_options.vision_model,
                    "confidence_threshold": processing_options.confidence_threshold,
                    "enable_ocr": processing_options.enable_ocr,
                    "language": processing_options.language
                }
            }
            
            # Call the service
            response = await self.document_service.process_documents(request_payload)
            self._log_api_call("document_processing_service", 0.34)  # Example cost
            
            if not response.success:
                raise ValueError(f"Document processing failed: {response.error}")
            
            self.logger.info(f"Document processing completed: {len(response.data.get('documents', []))} documents")
            return response.data
            
        except Exception as e:
            self.logger.error(f"Error calling document processing service: {str(e)}")
            raise
    
    async def _parse_processing_response(self, response: Dict[str, Any]) -> List[ExtractedDocument]:
        """Parse and normalize structured data from API response."""
        extracted_documents = []
        
        for doc_data in response.get("documents", []):
            try:
                # Determine document class
                doc_class = self._determine_document_class(doc_data)
                
                # Extract structured data based on document class
                extracted_data = self._extract_structured_data(doc_data, doc_class)
                
                # Create extracted document
                extracted_doc = ExtractedDocument(
                    file_name=doc_data.get("file_name", "unknown"),
                    document_class=doc_class,
                    extracted_data=extracted_data,
                    quality_flags=self._assess_document_quality(doc_data),
                    processing_time=doc_data.get("processing_time")
                )
                
                extracted_documents.append(extracted_doc)
                
            except Exception as e:
                self.logger.error(f"Error parsing document {doc_data.get('file_name')}: {str(e)}")
                continue
        
        self.logger.info(f"Parsed {len(extracted_documents)} documents")
        return extracted_documents
    
    def _determine_document_class(self, doc_data: Dict[str, Any]) -> DocumentClass:
        """Determine document class from processing response."""
        # This would use the classification from the document processing service
        # and map it to our DocumentClass enum
        
        doc_type = doc_data.get("document_type", "").lower()
        
        if "pan" in doc_type:
            if "individual" in doc_type:
                return DocumentClass.PAN_INDIVIDUAL
            else:
                return DocumentClass.PAN_FIRM
        elif "aadhaar" in doc_type:
            return DocumentClass.AADHAAR_INDIVIDUAL
        elif "gst" in doc_type and "certificate" in doc_type:
            return DocumentClass.GST_CERTIFICATE
        elif "partnership" in doc_type:
            return DocumentClass.PARTNERSHIP_DEED
        elif "financial" in doc_type:
            if "audited" in doc_type:
                return DocumentClass.AUDITED_FINANCIAL_STATEMENT
            else:
                return DocumentClass.PROVISIONAL_FINANCIAL_STATEMENT
        elif "bank" in doc_type:
            return DocumentClass.BANK_STATEMENT
        elif "itr" in doc_type or "income_tax" in doc_type:
            return DocumentClass.INCOME_TAX_RETURN
        elif "gst_return" in doc_type:
            return DocumentClass.GST_RETURNS
        else:
            return DocumentClass.UNKNOWN
    
    def _extract_structured_data(self, doc_data: Dict[str, Any], doc_class: DocumentClass) -> Any:
        """Extract structured data based on document class."""
        extracted_data = doc_data.get("extracted_data", {})
        confidence = doc_data.get("confidence_score", 0.0)
        
        if doc_class in [DocumentClass.PAN_FIRM, DocumentClass.PAN_INDIVIDUAL]:
            return PANCardData(
                pan_number=extracted_data.get("pan_number", ""),
                name=extracted_data.get("name"),
                entity_name=extracted_data.get("entity_name"),
                father_name=extracted_data.get("father_name"),
                date_of_birth=extracted_data.get("date_of_birth"),
                constitution_indicator=extracted_data.get("constitution_indicator"),
                address=extracted_data.get("address"),
                confidence_score=confidence
            )
        elif doc_class == DocumentClass.AADHAAR_INDIVIDUAL:
            return AadhaarCardData(
                aadhaar_number=extracted_data.get("aadhaar_number", ""),
                name=extracted_data.get("name", ""),
                address=extracted_data.get("address"),
                phone=extracted_data.get("phone"),
                date_of_birth=extracted_data.get("date_of_birth"),
                confidence_score=confidence
            )
        elif doc_class == DocumentClass.GST_CERTIFICATE:
            return GSTCertificateData(
                gst_number=extracted_data.get("gst_number", ""),
                business_name=extracted_data.get("business_name", ""),
                registration_date=extracted_data.get("registration_date"),
                address=extracted_data.get("address"),
                status=extracted_data.get("status"),
                confidence_score=confidence
            )
        elif doc_class == DocumentClass.PARTNERSHIP_DEED:
            return PartnershipDeedData(
                firm_name=extracted_data.get("firm_name", ""),
                registration_date=extracted_data.get("registration_date"),
                partners=extracted_data.get("partners", []),
                business_activity=extracted_data.get("business_activity"),
                confidence_score=confidence
            )
        elif doc_class in [DocumentClass.AUDITED_FINANCIAL_STATEMENT, DocumentClass.PROVISIONAL_FINANCIAL_STATEMENT]:
            return FinancialStatementData(
                fiscal_year=extracted_data.get("fiscal_year", 0),
                balance_sheet=extracted_data.get("balance_sheet", {}),
                profit_loss=extracted_data.get("profit_loss", {}),
                cash_flow=extracted_data.get("cash_flow"),
                auditor_name=extracted_data.get("auditor_name"),
                audit_date=extracted_data.get("audit_date"),
                confidence_score=confidence
            )
        elif doc_class == DocumentClass.BANK_STATEMENT:
            return BankStatementData(
                bank_name=extracted_data.get("bank_name", ""),
                account_number=extracted_data.get("account_number"),
                account_type=extracted_data.get("account_type"),
                period=extracted_data.get("period", ""),
                transaction_count=extracted_data.get("transaction_count", 0),
                average_balance=extracted_data.get("average_balance"),
                opening_balance=extracted_data.get("opening_balance"),
                closing_balance=extracted_data.get("closing_balance"),
                confidence_score=confidence
            )
        else:
            # Generic extracted data
            from ..models.documents import ExtractedData
            return ExtractedData(
                confidence_score=confidence,
                raw_text=extracted_data.get("raw_text"),
                structured_data=extracted_data
            )
    
    def _assess_document_quality(self, doc_data: Dict[str, Any]) -> List[str]:
        """Assess document quality and return quality flags."""
        quality_flags = []
        
        confidence = doc_data.get("confidence_score", 0.0)
        if confidence >= 0.9:
            quality_flags.append("high_confidence")
        elif confidence < 0.7:
            quality_flags.append("low_confidence")
        
        if doc_data.get("image_quality") == "clear":
            quality_flags.append("clear_image")
        elif doc_data.get("image_quality") == "blurry":
            quality_flags.append("blurry_image")
        
        if doc_data.get("text_extraction_quality") == "good":
            quality_flags.append("good_text_extraction")
        
        return quality_flags
    
    def _classify_documents_for_msme(self, extracted_documents: List[ExtractedDocument]) -> ClassifiedDocuments:
        """Apply MSME-specific document categorization."""
        classified = ClassifiedDocuments()
        
        for doc in extracted_documents:
            if doc.document_class in [DocumentClass.PAN_FIRM]:
                if "pan_cards" not in classified.borrower_documents:
                    classified.borrower_documents["pan_cards"] = []
                classified.borrower_documents["pan_cards"].append(doc)
            
            elif doc.document_class == DocumentClass.GST_CERTIFICATE:
                if "gst_certificates" not in classified.borrower_documents:
                    classified.borrower_documents["gst_certificates"] = []
                classified.borrower_documents["gst_certificates"].append(doc)
            
            elif doc.document_class == DocumentClass.PAN_INDIVIDUAL:
                if "pan_cards" not in classified.kmp_documents:
                    classified.kmp_documents["pan_cards"] = []
                classified.kmp_documents["pan_cards"].append(doc)
            
            elif doc.document_class == DocumentClass.AADHAAR_INDIVIDUAL:
                if "aadhaar_cards" not in classified.kmp_documents:
                    classified.kmp_documents["aadhaar_cards"] = []
                classified.kmp_documents["aadhaar_cards"].append(doc)
            
            elif doc.document_class == DocumentClass.PARTNERSHIP_DEED:
                if "partnership_deeds" not in classified.business_documents:
                    classified.business_documents["partnership_deeds"] = []
                classified.business_documents["partnership_deeds"].append(doc)
            
            elif doc.document_class in [DocumentClass.AUDITED_FINANCIAL_STATEMENT, DocumentClass.PROVISIONAL_FINANCIAL_STATEMENT]:
                category = "audited_financials_2yr" if doc.document_class == DocumentClass.AUDITED_FINANCIAL_STATEMENT else "provisional_financials_1yr"
                if category not in classified.financial_documents:
                    classified.financial_documents[category] = []
                classified.financial_documents[category].append(doc)
            
            elif doc.document_class == DocumentClass.INCOME_TAX_RETURN:
                if "itr_documents" not in classified.financial_documents:
                    classified.financial_documents["itr_documents"] = []
                classified.financial_documents["itr_documents"].append(doc)
            
            elif doc.document_class == DocumentClass.BANK_STATEMENT:
                if "bank_statements" not in classified.banking_documents:
                    classified.banking_documents["bank_statements"] = []
                classified.banking_documents["bank_statements"].append(doc)
            
            elif doc.document_class == DocumentClass.GST_RETURNS:
                if "gst_returns" not in classified.gst_documents:
                    classified.gst_documents["gst_returns"] = []
                classified.gst_documents["gst_returns"].append(doc)
        
        self.logger.info(f"Classified documents into {len(classified.get_all_documents())} total documents")
        return classified
    
    def _identify_financial_documents(self, classified_documents: ClassifiedDocuments) -> None:
        """Identify 2 years audited + 1 year provisional financials."""
        audited_docs = classified_documents.financial_documents.get("audited_financials_2yr", [])
        provisional_docs = classified_documents.financial_documents.get("provisional_financials_1yr", [])
        
        # Sort by fiscal year
        audited_docs.sort(key=lambda x: getattr(x.extracted_data, 'fiscal_year', 0), reverse=True)
        provisional_docs.sort(key=lambda x: getattr(x.extracted_data, 'fiscal_year', 0), reverse=True)
        
        self.logger.info(f"Identified {len(audited_docs)} audited and {len(provisional_docs)} provisional financial documents")
    
    def _identify_banking_documents(self, classified_documents: ClassifiedDocuments) -> None:
        """Identify bank statements for all declared accounts."""
        bank_statements = classified_documents.banking_documents.get("bank_statements", [])
        
        # Group by bank name
        banks = {}
        for stmt in bank_statements:
            bank_name = getattr(stmt.extracted_data, 'bank_name', 'Unknown')
            if bank_name not in banks:
                banks[bank_name] = []
            banks[bank_name].append(stmt)
        
        self.logger.info(f"Identified bank statements from {len(banks)} banks")
    
    def _map_documents_to_entities(self, classified_documents: ClassifiedDocuments) -> None:
        """Map documents to borrower vs KMPs."""
        # This is already done in the classification step
        # Additional logic could be added here for more sophisticated mapping
        
        borrower_docs = sum(len(docs) for docs in classified_documents.borrower_documents.values())
        kmp_docs = sum(len(docs) for docs in classified_documents.kmp_documents.values())
        
        self.logger.info(f"Mapped {borrower_docs} borrower documents and {kmp_docs} KMP documents")
    
    def _analyze_missing_documents(self, classified_documents: ClassifiedDocuments) -> List[MissingDocument]:
        """Analyze missing documents against MSME requirements."""
        missing_documents = []
        
        # Check borrower documents
        if not classified_documents.borrower_documents.get("pan_cards"):
            missing_documents.append(MissingDocument(
                document_type="pan_card",
                missing_for="Borrowing Entity",
                mandatory=True,
                reason="Required for entity identification"
            ))
        
        # Check financial documents
        audited_count = len(classified_documents.financial_documents.get("audited_financials_2yr", []))
        if audited_count < self.financial_requirements["audited_financials_required"]:
            missing_documents.append(MissingDocument(
                document_type="audited_financials",
                missing_for="Borrowing Entity",
                mandatory=True,
                reason=f"Required {self.financial_requirements['audited_financials_required']} years, found {audited_count}"
            ))
        
        provisional_count = len(classified_documents.financial_documents.get("provisional_financials_1yr", []))
        if provisional_count < self.financial_requirements["provisional_financials_required"]:
            missing_documents.append(MissingDocument(
                document_type="provisional_financials",
                missing_for="Borrowing Entity",
                mandatory=True,
                reason=f"Required {self.financial_requirements['provisional_financials_required']} year, found {provisional_count}"
            ))
        
        itr_count = len(classified_documents.financial_documents.get("itr_documents", []))
        if itr_count < self.financial_requirements["itr_documents_required"]:
            missing_documents.append(MissingDocument(
                document_type="itr_documents",
                missing_for="Borrowing Entity",
                mandatory=True,
                reason=f"Required {self.financial_requirements['itr_documents_required']} years, found {itr_count}"
            ))
        
        self.logger.info(f"Identified {len(missing_documents)} missing documents")
        return missing_documents
    
    def _assess_data_quality(self, classified_documents: ClassifiedDocuments) -> List[ValidationWarning]:
        """Assess data quality and flag low-quality extractions."""
        warnings = []
        
        all_docs = classified_documents.get_all_documents()
        low_confidence_docs = [
            doc for doc in all_docs 
            if hasattr(doc.extracted_data, 'confidence_score') and 
            doc.extracted_data.confidence_score < 0.9
        ]
        
        for doc in low_confidence_docs:
            warnings.append(ValidationWarning(
                type="low_confidence",
                document=doc.file_name,
                confidence=doc.extracted_data.confidence_score,
                threshold=0.9,
                recommendation="Manual review recommended",
                severity="medium"
            ))
        
        # Check average confidence
        if all_docs:
            avg_confidence = sum(
                getattr(doc.extracted_data, 'confidence_score', 0.0) 
                for doc in all_docs
            ) / len(all_docs)
            
            if avg_confidence < 0.7:
                warnings.append(ValidationWarning(
                    type="low_average_confidence",
                    confidence=avg_confidence,
                    threshold=0.7,
                    recommendation="Review document quality and consider re-upload",
                    severity="high"
                ))
        
        self.logger.info(f"Generated {len(warnings)} validation warnings")
        return warnings
    
    def _create_document_analysis(self, classified_documents: ClassifiedDocuments, 
                                extracted_documents: List[ExtractedDocument]) -> DocumentAnalysis:
        """Create document analysis summary."""
        all_docs = classified_documents.get_all_documents()
        
        # Calculate statistics
        total_pages = sum(
            getattr(doc, 'page_count', 1) for doc in extracted_documents
        )
        
        confidence_scores = [
            getattr(doc.extracted_data, 'confidence_score', 0.0) 
            for doc in all_docs
            if hasattr(doc.extracted_data, 'confidence_score')
        ]
        
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
        classification_success_rate = len([doc for doc in all_docs if doc.document_class != DocumentClass.UNKNOWN]) / len(all_docs) if all_docs else 0.0
        
        # Financial documents coverage
        financial_coverage = {
            "audited_financials_required": self.financial_requirements["audited_financials_required"],
            "audited_financials_available": len(classified_documents.financial_documents.get("audited_financials_2yr", [])),
            "provisional_financials_required": self.financial_requirements["provisional_financials_required"],
            "provisional_financials_available": len(classified_documents.financial_documents.get("provisional_financials_1yr", [])),
            "itr_documents_required": self.financial_requirements["itr_documents_required"],
            "itr_documents_available": len(classified_documents.financial_documents.get("itr_documents", []))
        }
        
        return DocumentAnalysis(
            total_documents_processed=len(extracted_documents),
            total_pages_processed=total_pages,
            classification_success_rate=classification_success_rate,
            average_confidence_score=avg_confidence,
            financial_documents_coverage=financial_coverage
        )
    
    def _determine_routing_decision(self, classified_documents: ClassifiedDocuments,
                                  missing_documents: List[MissingDocument],
                                  validation_warnings: List[ValidationWarning]) -> RoutingDecision:
        """Determine routing decision based on processing results."""
        
        # Check if we have borrower PAN card with good confidence
        borrower_pans = classified_documents.borrower_documents.get("pan_cards", [])
        if not borrower_pans:
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="No borrower PAN card found",
                conditions_met=[],
                bypass_conditions=["borrower_pan_available"]
            )
        
        # Check confidence of borrower PAN
        pan_confidence = getattr(borrower_pans[0].extracted_data, 'confidence_score', 0.0)
        if pan_confidence < 0.8:
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="Low confidence in borrower PAN card extraction",
                conditions_met=[],
                bypass_conditions=["high_confidence_extraction"]
            )
        
        # Check for critical missing documents
        critical_missing = [doc for doc in missing_documents if doc.mandatory]
        if len(critical_missing) > 3:  # Too many critical documents missing
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="Too many critical documents missing",
                conditions_met=[],
                bypass_conditions=["sufficient_documents"]
            )
        
        # Check average confidence
        all_docs = classified_documents.get_all_documents()
        if all_docs:
            avg_confidence = sum(
                getattr(doc.extracted_data, 'confidence_score', 0.0) 
                for doc in all_docs
            ) / len(all_docs)
            
            if avg_confidence < 0.7:
                return RoutingDecision(
                    next_agent="human_review",
                    routing_reason="Average document confidence below threshold",
                    conditions_met=[],
                    bypass_conditions=["minimum_confidence"]
                )
        
        # Success route
        return RoutingDecision(
            next_agent="entity_kmp_identification",
            routing_reason="Sufficient documents available for entity analysis",
            conditions_met=[
                "borrower_pan_available",
                "sufficient_document_quality",
                "basic_documents_classified"
            ],
            bypass_conditions=[]
        )
</file>

<file path="msme_underwriting/config/__init__.py">
"""Configuration module for MSME underwriting system."""

from .settings import settings, Settings

__all__ = ["settings", "Settings"]
</file>

<file path="msme_underwriting/config/settings.py">
"""Application settings and configuration."""

import os
from typing import Optional, List
from pydantic import Field
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""
    
    # Application
    environment: str = Field(default="development", description="Environment (development/staging/production)")
    log_level: str = Field(default="INFO", description="Logging level")
    max_concurrent_agents: int = Field(default=5, description="Maximum concurrent agents")
    agent_timeout_seconds: int = Field(default=300, description="Agent timeout in seconds")
    
    # LLM Configuration
    openai_api_key: Optional[str] = Field(default=None, description="OpenAI API key")
    anthropic_api_key: Optional[str] = Field(default=None, description="Anthropic API key")
    default_llm_provider: str = Field(default="openai", description="Default LLM provider")
    default_model: str = Field(default="gpt-4o", description="Default model name")
    
    # Database
    database_url: str = Field(default="postgresql://user:password@localhost:5432/msme_underwriting")
    redis_url: str = Field(default="redis://localhost:6379/0")
    
    # External APIs
    pan_api_key: Optional[str] = Field(default=None, description="PAN validation API key")
    mca_api_key: Optional[str] = Field(default=None, description="MCA API key")
    cibil_api_key: Optional[str] = Field(default=None, description="CIBIL API key")
    gst_api_key: Optional[str] = Field(default=None, description="GST API key")
    
    # Document Processing Service
    document_processing_service_url: str = Field(
        default="http://localhost:8001", 
        description="PDF/Image processing service URL"
    )
    document_processing_api_key: Optional[str] = Field(
        default=None, 
        description="Document processing service API key"
    )
    
    # File Storage
    upload_dir: str = Field(default="./uploads", description="Upload directory")
    max_file_size_mb: int = Field(default=50, description="Maximum file size in MB")
    
    # Security
    secret_key: str = Field(default="your_secret_key_here", description="Application secret key")
    jwt_secret: str = Field(default="your_jwt_secret_here", description="JWT secret key")
    
    # Monitoring and Tracing
    langsmith_api_key: Optional[str] = Field(default=None, description="LangSmith API key")
    langsmith_project: str = Field(default="msme-underwriting", description="LangSmith project name")
    langsmith_tracing: bool = Field(default=True, description="Enable LangSmith tracing")
    
    # Business Rules
    minimum_kmp_coverage: float = Field(default=0.5, description="Minimum KMP coverage percentage")
    minimum_consumer_cibil: int = Field(default=680, description="Minimum consumer CIBIL score")
    maximum_commercial_cmr: int = Field(default=8, description="Maximum commercial CMR score")
    minimum_commercial_score: int = Field(default=1, description="Minimum commercial score")
    
    # Eligible constitutions for MSME loans
    eligible_constitutions: List[str] = Field(
        default=["sole_proprietorship", "partnership", "llp", "company", "huf"],
        description="Eligible entity constitutions"
    )
    
    # Document confidence thresholds
    minimum_document_confidence: float = Field(default=0.7, description="Minimum document confidence score")
    high_confidence_threshold: float = Field(default=0.9, description="High confidence threshold")
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False


# Global settings instance
settings = Settings()


def get_settings() -> Settings:
    """Get application settings."""
    return settings
</file>

<file path="msme_underwriting/models/__init__.py">
"""Data models for MSME underwriting system."""

from .base import BaseModel, TimestampedModel
from .loan_application import (
    LoanApplication,
    LoanContext,
    UploadedFile,
    ProcessingOptions,
)
from .documents import (
    DocumentClass,
    ExtractedDocument,
    ClassifiedDocuments,
    DocumentAnalysis,
    MissingDocument,
    ValidationWarning,
)
from .entity import (
    EntityProfile,
    BorrowingEntity,
    ConstitutionEligibility,
    DateOfEstablishment,
    RegisteredAddress,
)
from .kmp import (
    KMPAnalysis,
    IdentifiedKMP,
    KMPCoverageAnalysis,
    ConstitutionRequirements,
)
from .verification import (
    BureauVerificationResults,
    EntityCommercialBureau,
    KMPConsumerBureau,
    PartnershipCibilCompliance,
    EnhancedGSTAnalysis,
    PolicyComplianceAssessment,
    RiskAssessment,
    EligibilityDetermination,
)
from .financial import (
    FinancialHealthAssessment,
    TurnoverAnalysis,
    ProfitabilityRatios,
    LiquidityRatios,
    LeverageRatios,
    CashFlowAnalysis,
    LoanServicingCapacity,
)
from .banking import (
    BankingAssessment,
    AccountSummary,
    CashFlowAnalysisBank,
    AccountConduct,
    TransactionPatterns,
    FinancialIntegration,
)
from .state import (
    MSMELoanState,
    AgentContext,
    ProcessingMetadata,
    RoutingDecision,
)
from .final_report import (
    FinalReport,
    ExecutiveSummary,
    ComprehensiveBorrowerProfile,
    VerificationSummary,
    RiskAssessmentSummary,
    LoanRecommendation,
)

__all__ = [
    # Base models
    "BaseModel",
    "TimestampedModel",
    
    # Loan application
    "LoanApplication",
    "LoanContext", 
    "UploadedFile",
    "ProcessingOptions",
    
    # Documents
    "DocumentClass",
    "ExtractedDocument",
    "ClassifiedDocuments",
    "DocumentAnalysis",
    "MissingDocument",
    "ValidationWarning",
    
    # Entity
    "EntityProfile",
    "BorrowingEntity",
    "ConstitutionEligibility",
    "DateOfEstablishment",
    "RegisteredAddress",
    
    # KMP
    "KMPAnalysis",
    "IdentifiedKMP",
    "KMPCoverageAnalysis",
    "ConstitutionRequirements",
    
    # Verification
    "BureauVerificationResults",
    "EntityCommercialBureau",
    "KMPConsumerBureau",
    "PartnershipCibilCompliance",
    "EnhancedGSTAnalysis",
    "PolicyComplianceAssessment",
    "RiskAssessment",
    "EligibilityDetermination",
    
    # Financial
    "FinancialHealthAssessment",
    "TurnoverAnalysis",
    "ProfitabilityRatios",
    "LiquidityRatios",
    "LeverageRatios",
    "CashFlowAnalysis",
    "LoanServicingCapacity",
    
    # Banking
    "BankingAssessment",
    "AccountSummary",
    "CashFlowAnalysisBank",
    "AccountConduct",
    "TransactionPatterns",
    "FinancialIntegration",
    
    # State
    "MSMELoanState",
    "AgentContext",
    "ProcessingMetadata",
    "RoutingDecision",
    
    # Final report
    "FinalReport",
    "ExecutiveSummary",
    "ComprehensiveBorrowerProfile",
    "VerificationSummary",
    "RiskAssessmentSummary",
    "LoanRecommendation",
]
</file>

<file path="msme_underwriting/models/banking.py">
"""Models for banking analysis."""

from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel


class AccountSummary(BaseModel):
    """Summary of bank accounts analyzed."""
    
    total_accounts_analyzed: int = Field(description="Total number of accounts analyzed")
    current_accounts: int = Field(default=0, description="Number of current accounts")
    savings_accounts: int = Field(default=0, description="Number of savings accounts")
    od_cc_accounts: int = Field(default=0, description="Number of OD/CC accounts")
    loan_accounts: int = Field(default=0, description="Number of loan accounts")
    
    analysis_period: str = Field(description="Period of analysis (e.g., '12 months')")
    total_statements_processed: int = Field(description="Total statements processed")
    
    # Account details
    primary_account_bank: Optional[str] = Field(default=None, description="Primary account bank")
    account_vintage: Optional[int] = Field(default=None, description="Account vintage in months")
    
    @property
    def has_multiple_accounts(self) -> bool:
        """Check if entity has multiple accounts."""
        return self.total_accounts_analyzed > 1
    
    @property
    def has_credit_facilities(self) -> bool:
        """Check if entity has credit facilities."""
        return self.od_cc_accounts > 0


class CashFlowAnalysisBank(BaseModel):
    """Cash flow analysis from banking data."""
    
    # Monthly averages
    average_monthly_credits: Optional[float] = Field(default=None, description="Average monthly credits")
    average_monthly_debits: Optional[float] = Field(default=None, description="Average monthly debits")
    net_monthly_surplus: Optional[float] = Field(default=None, description="Net monthly surplus")
    
    # Cash flow patterns
    cash_flow_consistency: str = Field(description="Cash flow consistency (high/medium/low)")
    cash_flow_volatility: Optional[float] = Field(default=None, description="Cash flow volatility coefficient")
    
    # Seasonal analysis
    seasonality_detected: Optional[str] = Field(default=None, description="Seasonality pattern")
    seasonal_adjustment_factor: Optional[float] = Field(default=None, description="Seasonal adjustment factor")
    seasonality_adjusted_flow: Optional[float] = Field(default=None, description="Seasonality adjusted cash flow")
    
    # Trend analysis
    cash_flow_trend: Optional[str] = Field(default=None, description="Cash flow trend (improving/stable/declining)")
    growth_rate: Optional[float] = Field(default=None, description="Cash flow growth rate")
    
    # Monthly breakdown
    monthly_cash_flows: Optional[List[Dict[str, Any]]] = Field(
        default=None,
        description="Monthly cash flow breakdown"
    )
    
    @property
    def has_positive_cash_flow(self) -> bool:
        """Check if entity has positive cash flow."""
        return self.net_monthly_surplus is not None and self.net_monthly_surplus > 0
    
    @property
    def has_consistent_cash_flow(self) -> bool:
        """Check if cash flow is consistent."""
        return self.cash_flow_consistency == "high"


class AccountConduct(BaseModel):
    """Account conduct assessment."""
    
    # Balance analysis
    average_balance: Optional[float] = Field(default=None, description="Average balance")
    minimum_balance: Optional[float] = Field(default=None, description="Minimum balance")
    maximum_balance: Optional[float] = Field(default=None, description="Maximum balance")
    balance_volatility: Optional[float] = Field(default=None, description="Balance volatility")
    
    # Credit facility utilization
    od_limit: Optional[float] = Field(default=None, description="Overdraft limit")
    cc_limit: Optional[float] = Field(default=None, description="Cash credit limit")
    od_utilization: Optional[float] = Field(default=None, description="OD utilization percentage")
    cc_utilization: Optional[float] = Field(default=None, description="CC utilization percentage")
    
    # Conduct issues
    bounce_incidents: int = Field(default=0, description="Number of bounce incidents")
    return_incidents: int = Field(default=0, description="Number of return incidents")
    penal_charges: Optional[float] = Field(default=None, description="Total penal charges")
    
    # Overall assessment
    conduct_rating: str = Field(description="Overall conduct rating (excellent/satisfactory/poor)")
    conduct_score: Optional[float] = Field(default=None, description="Numerical conduct score")
    
    # Detailed conduct history
    monthly_conduct: Optional[List[Dict[str, Any]]] = Field(
        default=None,
        description="Monthly conduct details"
    )
    
    @property
    def has_good_conduct(self) -> bool:
        """Check if account conduct is good."""
        return self.conduct_rating in ["excellent", "satisfactory"]
    
    @property
    def has_bounce_issues(self) -> bool:
        """Check if there are bounce issues."""
        return self.bounce_incidents > 0
    
    @property
    def utilizes_credit_facilities_well(self) -> bool:
        """Check if credit facilities are utilized well."""
        if self.od_utilization is not None:
            return 20 <= self.od_utilization <= 80
        return True


class TransactionPatterns(BaseModel):
    """Transaction pattern analysis."""
    
    # Transaction volume
    total_transactions: int = Field(description="Total number of transactions")
    average_monthly_transactions: Optional[float] = Field(default=None, description="Average monthly transactions")
    
    # Transaction types
    credit_transactions: int = Field(default=0, description="Number of credit transactions")
    debit_transactions: int = Field(default=0, description="Number of debit transactions")
    
    # Business pattern analysis
    primary_business_pattern: Optional[str] = Field(default=None, description="Primary business pattern identified")
    business_type_indicators: List[str] = Field(default_factory=list, description="Business type indicators")
    
    # Counterparty analysis
    major_counterparties: List[str] = Field(default_factory=list, description="Major counterparties")
    supplier_concentration: Optional[float] = Field(default=None, description="Supplier concentration ratio")
    customer_concentration: Optional[float] = Field(default=None, description="Customer concentration ratio")
    
    # Transaction regularity
    transaction_regularity: str = Field(description="Transaction regularity (consistent/irregular)")
    recurring_transactions: Optional[int] = Field(default=None, description="Number of recurring transactions")
    
    # Anomaly detection
    anomalies_detected: int = Field(default=0, description="Number of anomalies detected")
    anomaly_severity: str = Field(default="none", description="Anomaly severity (none/low/medium/high)")
    anomaly_details: List[Dict[str, Any]] = Field(default_factory=list, description="Anomaly details")
    
    # Digital transaction analysis
    digital_transaction_percentage: Optional[float] = Field(
        default=None,
        description="Percentage of digital transactions"
    )
    cash_transaction_percentage: Optional[float] = Field(
        default=None,
        description="Percentage of cash transactions"
    )
    
    @property
    def shows_business_activity(self) -> bool:
        """Check if transactions show genuine business activity."""
        return (
            self.total_transactions > 100 and
            self.transaction_regularity == "consistent" and
            len(self.major_counterparties) > 0
        )
    
    @property
    def has_concerning_anomalies(self) -> bool:
        """Check if there are concerning anomalies."""
        return self.anomaly_severity in ["medium", "high"]


class FinancialIntegration(BaseModel):
    """Integration analysis with financial statements."""
    
    # Reconciliation status
    reported_turnover_vs_banking: str = Field(description="Turnover reconciliation status")
    cash_flow_reconciliation: str = Field(description="Cash flow reconciliation status")
    
    # Variance analysis
    turnover_variance_percentage: Optional[float] = Field(
        default=None,
        description="Variance between reported and banking turnover"
    )
    cash_flow_variance_percentage: Optional[float] = Field(
        default=None,
        description="Variance between reported and banking cash flow"
    )
    
    # Discrepancy details
    discrepancies: str = Field(description="Level of discrepancies (minimal/moderate/significant)")
    discrepancy_explanations: List[str] = Field(
        default_factory=list,
        description="Explanations for discrepancies"
    )
    
    # Integration score
    integration_score: Optional[float] = Field(default=None, description="Integration score (0-100)")
    
    @property
    def has_good_integration(self) -> bool:
        """Check if banking data integrates well with financials."""
        return (
            self.reported_turnover_vs_banking == "consistent" and
            self.cash_flow_reconciliation == "verified" and
            self.discrepancies == "minimal"
        )


class BankingAssessment(BaseModel):
    """Complete banking assessment results."""
    
    account_summary: AccountSummary = Field(description="Account summary")
    cash_flow_analysis: CashFlowAnalysisBank = Field(description="Cash flow analysis")
    account_conduct: AccountConduct = Field(description="Account conduct assessment")
    transaction_patterns: TransactionPatterns = Field(description="Transaction patterns")
    financial_integration: FinancialIntegration = Field(description="Financial integration analysis")
    
    # Overall banking assessment
    overall_banking_score: Optional[float] = Field(default=None, description="Overall banking score")
    banking_risk_rating: Optional[str] = Field(default=None, description="Banking risk rating")
    
    # Key findings
    key_strengths: List[str] = Field(default_factory=list, description="Key banking strengths")
    areas_of_concern: List[str] = Field(default_factory=list, description="Areas of concern")
    red_flags: List[str] = Field(default_factory=list, description="Red flags identified")
    
    # Recommendations
    recommendations: List[str] = Field(default_factory=list, description="Banking recommendations")
    
    # Additional analysis
    peer_comparison: Optional[Dict[str, Any]] = Field(default=None, description="Peer comparison")
    industry_benchmarks: Optional[Dict[str, Any]] = Field(default=None, description="Industry benchmarks")
    
    def calculate_overall_score(self) -> float:
        """Calculate overall banking score."""
        scores = []
        
        # Cash flow score (40% weight)
        if self.cash_flow_analysis.has_positive_cash_flow:
            cf_score = 80 if self.cash_flow_analysis.has_consistent_cash_flow else 60
        else:
            cf_score = 20
        scores.append(cf_score * 0.4)
        
        # Conduct score (30% weight)
        if self.account_conduct.conduct_score is not None:
            conduct_score = self.account_conduct.conduct_score
        else:
            conduct_score = 70 if self.account_conduct.has_good_conduct else 40
        scores.append(conduct_score * 0.3)
        
        # Transaction pattern score (20% weight)
        if self.transaction_patterns.shows_business_activity:
            pattern_score = 70 if not self.transaction_patterns.has_concerning_anomalies else 50
        else:
            pattern_score = 30
        scores.append(pattern_score * 0.2)
        
        # Integration score (10% weight)
        if self.financial_integration.integration_score is not None:
            integration_score = self.financial_integration.integration_score
        else:
            integration_score = 70 if self.financial_integration.has_good_integration else 40
        scores.append(integration_score * 0.1)
        
        return sum(scores)
    
    @property
    def supports_loan_application(self) -> bool:
        """Check if banking analysis supports loan application."""
        return (
            self.cash_flow_analysis.has_positive_cash_flow and
            self.account_conduct.has_good_conduct and
            self.transaction_patterns.shows_business_activity and
            not self.transaction_patterns.has_concerning_anomalies and
            self.financial_integration.has_good_integration
        )
    
    @property
    def has_major_red_flags(self) -> bool:
        """Check if there are major red flags."""
        return len(self.red_flags) > 0
</file>

<file path="msme_underwriting/models/base.py">
"""Base models for the MSME underwriting system."""

from datetime import datetime
from typing import Any, Dict, Optional
from pydantic import BaseModel as PydanticBaseModel, Field, ConfigDict


class BaseModel(PydanticBaseModel):
    """Base model with common configuration."""
    
    model_config = ConfigDict(
        # Allow extra fields for flexibility
        extra="allow",
        # Use enum values instead of names
        use_enum_values=True,
        # Validate assignment
        validate_assignment=True,
        # Allow population by field name
        populate_by_name=True,
        # Serialize by alias
        ser_by_alias=True,
    )


class TimestampedModel(BaseModel):
    """Base model with timestamp fields."""
    
    created_at: datetime = Field(default_factory=datetime.utcnow, description="Creation timestamp")
    updated_at: Optional[datetime] = Field(default=None, description="Last update timestamp")
    
    def update_timestamp(self) -> None:
        """Update the updated_at timestamp."""
        self.updated_at = datetime.utcnow()


class ProcessingResult(BaseModel):
    """Base class for agent processing results."""
    
    agent_name: str = Field(description="Name of the agent that processed this")
    processing_status: str = Field(description="Processing status (completed, failed, partial)")
    thread_id: str = Field(description="Thread ID for this processing session")
    processing_metadata: "ProcessingMetadata" = Field(description="Processing metadata")
    next_action: str = Field(description="Next action to take")
    routing_decision: "RoutingDecision" = Field(description="Routing decision for next agent")


class ProcessingMetadata(BaseModel):
    """Metadata about processing operations."""
    
    start_time: datetime = Field(description="Processing start time")
    end_time: datetime = Field(description="Processing end time")
    total_processing_time: float = Field(description="Total processing time in seconds")
    api_calls_made: int = Field(default=0, description="Number of API calls made")
    total_api_cost: float = Field(default=0.0, description="Total API cost")
    
    @property
    def processing_duration(self) -> float:
        """Calculate processing duration in seconds."""
        return (self.end_time - self.start_time).total_seconds()


class RoutingDecision(BaseModel):
    """Decision about routing to next agent."""
    
    next_agent: str = Field(description="Name of the next agent to route to")
    routing_reason: str = Field(description="Reason for this routing decision")
    conditions_met: list[str] = Field(default_factory=list, description="Conditions that were met")
    bypass_conditions: list[str] = Field(default_factory=list, description="Conditions that were bypassed")


class ValidationResult(BaseModel):
    """Result of a validation check."""
    
    check_name: str = Field(description="Name of the validation check")
    status: str = Field(description="Status (passed, failed, warning)")
    value: Optional[Any] = Field(default=None, description="Value that was checked")
    expected: Optional[Any] = Field(default=None, description="Expected value")
    message: Optional[str] = Field(default=None, description="Validation message")
    severity: str = Field(default="info", description="Severity level")


class APIResponse(BaseModel):
    """Standard API response wrapper."""
    
    success: bool = Field(description="Whether the API call was successful")
    data: Optional[Dict[str, Any]] = Field(default=None, description="Response data")
    error: Optional[str] = Field(default=None, description="Error message if failed")
    status_code: Optional[int] = Field(default=None, description="HTTP status code")
    response_time: Optional[float] = Field(default=None, description="Response time in seconds")


# Forward references for type hints
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    pass
</file>

<file path="msme_underwriting/models/documents.py">
"""Models for document classification and extraction."""

from enum import Enum
from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel


class DocumentClass(str, Enum):
    """Enumeration of document classes."""
    
    # PAN Cards
    PAN_FIRM = "PAN_FIRM"
    PAN_INDIVIDUAL = "PAN_INDIVIDUAL"
    
    # Identity Documents
    AADHAAR_INDIVIDUAL = "AADHAAR_INDIVIDUAL"
    
    # Business Registration
    GST_CERTIFICATE = "GST_CERTIFICATE"
    PARTNERSHIP_DEED = "PARTNERSHIP_DEED"
    MOA_AOA = "MOA_AOA"
    UDYAM_REGISTRATION = "UDYAM_REGISTRATION"
    
    # Financial Documents
    AUDITED_FINANCIAL_STATEMENT = "AUDITED_FINANCIAL_STATEMENT"
    PROVISIONAL_FINANCIAL_STATEMENT = "PROVISIONAL_FINANCIAL_STATEMENT"
    INCOME_TAX_RETURN = "INCOME_TAX_RETURN"
    
    # Banking Documents
    BANK_STATEMENT = "BANK_STATEMENT"
    
    # GST Documents
    GST_RETURNS = "GST_RETURNS"
    
    # Other
    UNKNOWN = "UNKNOWN"


class ExtractedData(BaseModel):
    """Base class for extracted document data."""
    
    confidence_score: float = Field(description="Confidence score of extraction")
    raw_text: Optional[str] = Field(default=None, description="Raw extracted text")
    structured_data: Dict[str, Any] = Field(default_factory=dict, description="Structured extracted data")


class PANCardData(ExtractedData):
    """Extracted data from PAN card."""
    
    pan_number: str = Field(description="PAN number")
    name: Optional[str] = Field(default=None, description="Name on PAN card")
    entity_name: Optional[str] = Field(default=None, description="Entity name (for firm PAN)")
    father_name: Optional[str] = Field(default=None, description="Father's name (for individual PAN)")
    date_of_birth: Optional[str] = Field(default=None, description="Date of birth")
    constitution_indicator: Optional[str] = Field(default=None, description="4th character indicating constitution")
    address: Optional[str] = Field(default=None, description="Address on PAN card")


class AadhaarCardData(ExtractedData):
    """Extracted data from Aadhaar card."""
    
    aadhaar_number: str = Field(description="Aadhaar number")
    name: str = Field(description="Name on Aadhaar card")
    address: Optional[str] = Field(default=None, description="Address")
    phone: Optional[str] = Field(default=None, description="Phone number")
    date_of_birth: Optional[str] = Field(default=None, description="Date of birth")


class GSTCertificateData(ExtractedData):
    """Extracted data from GST certificate."""
    
    gst_number: str = Field(description="GST number")
    business_name: str = Field(description="Business name")
    registration_date: Optional[str] = Field(default=None, description="Registration date")
    address: Optional[str] = Field(default=None, description="Registered address")
    status: Optional[str] = Field(default=None, description="GST status")


class PartnershipDeedData(ExtractedData):
    """Extracted data from partnership deed."""
    
    firm_name: str = Field(description="Firm name")
    registration_date: Optional[str] = Field(default=None, description="Registration date")
    partners: List[Dict[str, str]] = Field(default_factory=list, description="List of partners with shares")
    business_activity: Optional[str] = Field(default=None, description="Business activity")


class FinancialStatementData(ExtractedData):
    """Extracted data from financial statements."""
    
    fiscal_year: int = Field(description="Fiscal year")
    balance_sheet: Dict[str, Any] = Field(default_factory=dict, description="Balance sheet data")
    profit_loss: Dict[str, Any] = Field(default_factory=dict, description="P&L statement data")
    cash_flow: Optional[Dict[str, Any]] = Field(default=None, description="Cash flow statement data")
    auditor_name: Optional[str] = Field(default=None, description="Auditor name")
    audit_date: Optional[str] = Field(default=None, description="Audit date")


class BankStatementData(ExtractedData):
    """Extracted data from bank statement."""
    
    bank_name: str = Field(description="Bank name")
    account_number: Optional[str] = Field(default=None, description="Account number (masked)")
    account_type: Optional[str] = Field(default=None, description="Account type")
    period: str = Field(description="Statement period")
    transaction_count: int = Field(description="Number of transactions")
    average_balance: Optional[float] = Field(default=None, description="Average balance")
    opening_balance: Optional[float] = Field(default=None, description="Opening balance")
    closing_balance: Optional[float] = Field(default=None, description="Closing balance")


class ExtractedDocument(BaseModel):
    """A document with extracted data."""
    
    file_name: str = Field(description="Original file name")
    document_class: DocumentClass = Field(description="Classified document type")
    extracted_data: ExtractedData = Field(description="Extracted structured data")
    quality_flags: List[str] = Field(default_factory=list, description="Quality assessment flags")
    processing_time: Optional[float] = Field(default=None, description="Processing time in seconds")
    
    # Additional metadata
    fiscal_year: Optional[int] = Field(default=None, description="Fiscal year (for financial docs)")
    assessment_year: Optional[str] = Field(default=None, description="Assessment year (for ITR)")
    period: Optional[str] = Field(default=None, description="Period covered by document")


class DocumentCategory(BaseModel):
    """A category of documents."""
    
    category_name: str = Field(description="Name of the document category")
    documents: List[ExtractedDocument] = Field(description="Documents in this category")
    
    def get_by_class(self, doc_class: DocumentClass) -> List[ExtractedDocument]:
        """Get documents by class."""
        return [doc for doc in self.documents if doc.document_class == doc_class]


class ClassifiedDocuments(BaseModel):
    """All classified documents organized by entity."""
    
    borrower_documents: Dict[str, List[ExtractedDocument]] = Field(
        default_factory=dict, 
        description="Documents belonging to borrowing entity"
    )
    kmp_documents: Dict[str, List[ExtractedDocument]] = Field(
        default_factory=dict,
        description="Documents belonging to KMPs"
    )
    business_documents: Dict[str, List[ExtractedDocument]] = Field(
        default_factory=dict,
        description="Business registration and legal documents"
    )
    financial_documents: Dict[str, List[ExtractedDocument]] = Field(
        default_factory=dict,
        description="Financial statements and tax documents"
    )
    banking_documents: Dict[str, List[ExtractedDocument]] = Field(
        default_factory=dict,
        description="Bank statements and banking documents"
    )
    gst_documents: Dict[str, List[ExtractedDocument]] = Field(
        default_factory=dict,
        description="GST returns and related documents"
    )
    
    def get_all_documents(self) -> List[ExtractedDocument]:
        """Get all documents as a flat list."""
        all_docs = []
        for category in [
            self.borrower_documents,
            self.kmp_documents, 
            self.business_documents,
            self.financial_documents,
            self.banking_documents,
            self.gst_documents
        ]:
            for doc_list in category.values():
                all_docs.extend(doc_list)
        return all_docs
    
    def get_documents_by_class(self, doc_class: DocumentClass) -> List[ExtractedDocument]:
        """Get all documents of a specific class."""
        return [doc for doc in self.get_all_documents() if doc.document_class == doc_class]


class DocumentAnalysis(BaseModel):
    """Analysis of document processing results."""
    
    total_documents_processed: int = Field(description="Total number of documents processed")
    total_pages_processed: int = Field(description="Total number of pages processed")
    classification_success_rate: float = Field(description="Classification success rate")
    average_confidence_score: float = Field(description="Average confidence score")
    
    financial_documents_coverage: Dict[str, int] = Field(
        default_factory=dict,
        description="Coverage analysis for financial documents"
    )
    
    processing_statistics: Dict[str, Any] = Field(
        default_factory=dict,
        description="Additional processing statistics"
    )


class MissingDocument(BaseModel):
    """Information about a missing required document."""
    
    document_type: str = Field(description="Type of missing document")
    missing_for: str = Field(description="Entity/person the document is missing for")
    mandatory: bool = Field(description="Whether this document is mandatory")
    reason: str = Field(description="Reason why this document is required")
    alternative_documents: List[str] = Field(
        default_factory=list,
        description="Alternative documents that could substitute"
    )


class ValidationWarning(BaseModel):
    """Warning about document validation issues."""
    
    type: str = Field(description="Type of validation warning")
    document: Optional[str] = Field(default=None, description="Document that triggered the warning")
    confidence: Optional[float] = Field(default=None, description="Confidence score if applicable")
    threshold: Optional[float] = Field(default=None, description="Threshold that was not met")
    recommendation: str = Field(description="Recommended action")
    severity: str = Field(default="medium", description="Severity level")
    impact: Optional[str] = Field(default=None, description="Impact of this warning")
</file>

<file path="msme_underwriting/models/entity.py">
"""Models for entity identification and profiling."""

from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel, ValidationResult


class ConstitutionEligibility(BaseModel):
    """Entity constitution eligibility assessment."""
    
    eligible_types: List[str] = Field(description="List of eligible constitution types")
    detected_type: str = Field(description="Detected constitution type")
    is_eligible: bool = Field(description="Whether the detected type is eligible")
    validation_checks: List[ValidationResult] = Field(description="Validation checks performed")
    confidence: float = Field(description="Confidence in constitution determination")


class DateOfEstablishment(BaseModel):
    """Date of establishment determination."""
    
    determined_date: str = Field(description="Determined establishment date")
    source_document: str = Field(description="Source document for the date")
    hierarchy_used: List[str] = Field(description="Document hierarchy used for determination")
    confidence: float = Field(description="Confidence in date determination")
    alternative_dates: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="Alternative dates found in other documents"
    )


class RegisteredAddress(BaseModel):
    """Standardized registered address."""
    
    line1: str = Field(description="Address line 1")
    line2: Optional[str] = Field(default=None, description="Address line 2")
    city: str = Field(description="City")
    state: str = Field(description="State")
    pincode: str = Field(description="PIN code")
    country: str = Field(default="India", description="Country")
    standardized: bool = Field(description="Whether address has been standardized")
    
    # Validation results
    validation_status: Optional[str] = Field(default=None, description="Address validation status")
    validation_score: Optional[float] = Field(default=None, description="Address validation score")
    
    def get_full_address(self) -> str:
        """Get full formatted address."""
        parts = [self.line1]
        if self.line2:
            parts.append(self.line2)
        parts.extend([self.city, self.state, self.pincode, self.country])
        return ", ".join(parts)


class BorrowingEntity(BaseModel):
    """Information about the borrowing entity."""
    
    pan_number: str = Field(description="Entity PAN number")
    entity_name: str = Field(description="Legal entity name")
    constitution: str = Field(description="Entity constitution type")
    constitution_source: str = Field(description="Source of constitution determination")
    constitution_eligibility: ConstitutionEligibility = Field(description="Constitution eligibility assessment")
    
    # API verification
    api_verified: bool = Field(description="Whether entity is API verified")
    verified_name: Optional[str] = Field(default=None, description="API verified name")
    
    # Registration details
    gst_number: Optional[str] = Field(default=None, description="GST number")
    udyam_number: Optional[str] = Field(default=None, description="Udyam registration number")
    cin_number: Optional[str] = Field(default=None, description="CIN number (for companies)")
    llpin_number: Optional[str] = Field(default=None, description="LLPIN number (for LLPs)")
    
    # Establishment details
    date_of_establishment: DateOfEstablishment = Field(description="Date of establishment")
    registered_address: RegisteredAddress = Field(description="Registered address")
    
    # Business details
    business_activity: Optional[str] = Field(default=None, description="Primary business activity")
    industry_code: Optional[str] = Field(default=None, description="Industry classification code")
    msme_classification: Optional[str] = Field(default=None, description="MSME classification")
    
    # Validation
    entity_validation_score: float = Field(description="Overall entity validation score")
    validation_flags: List[str] = Field(default_factory=list, description="Validation flags")
    
    def get_constitution_from_pan(self) -> str:
        """Determine constitution from PAN 4th character."""
        if len(self.pan_number) >= 4:
            fourth_char = self.pan_number[3].upper()
            constitution_map = {
                'A': 'association_of_persons',
                'B': 'body_of_individuals', 
                'C': 'company',
                'D': 'partnership',
                'E': 'trust',
                'F': 'firm',
                'G': 'government',
                'H': 'huf',
                'J': 'artificial_juridical_person',
                'K': 'krishi_upaj_mandi_samiti',
                'L': 'local_authority',
                'N': 'non_resident',
                'P': 'individual',
                'T': 'trust_ait',
            }
            return constitution_map.get(fourth_char, 'unknown')
        return 'unknown'
    
    @property
    def is_msme_eligible(self) -> bool:
        """Check if entity is eligible for MSME loans."""
        eligible_constitutions = [
            'sole_proprietorship', 'partnership', 'llp', 'company', 'huf'
        ]
        return self.constitution in eligible_constitutions


class EntityProfile(BaseModel):
    """Complete entity profile."""
    
    borrowing_entity: BorrowingEntity = Field(description="Primary borrowing entity details")
    
    # Related entities (for future group analysis)
    related_entities: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="Related entities identified"
    )
    
    # Validation summary
    validation_summary: Dict[str, Any] = Field(
        default_factory=dict,
        description="Summary of all validation checks"
    )
    
    # Risk indicators
    risk_indicators: List[str] = Field(
        default_factory=list,
        description="Risk indicators identified"
    )
    
    def add_related_entity(self, entity_data: Dict[str, Any]) -> None:
        """Add a related entity."""
        self.related_entities.append(entity_data)
    
    def get_primary_pan(self) -> str:
        """Get primary entity PAN number."""
        return self.borrowing_entity.pan_number
    
    def get_primary_name(self) -> str:
        """Get primary entity name."""
        return self.borrowing_entity.entity_name
    
    @property
    def has_gst_registration(self) -> bool:
        """Check if entity has GST registration."""
        return self.borrowing_entity.gst_number is not None
    
    @property
    def has_udyam_registration(self) -> bool:
        """Check if entity has Udyam registration."""
        return self.borrowing_entity.udyam_number is not None
</file>

<file path="msme_underwriting/models/final_report.py">
"""Models for final report generation."""

from datetime import datetime
from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel


class ExecutiveSummary(BaseModel):
    """Executive summary of the loan application."""
    
    application_id: str = Field(description="Unique application ID")
    borrower_name: str = Field(description="Borrower entity name")
    
    # Loan request details
    loan_request: Dict[str, Any] = Field(description="Loan request details")
    
    # Decision summary
    recommendation: str = Field(description="Final recommendation (APPROVED/CONDITIONALLY APPROVED/REJECTED)")
    risk_grade: str = Field(description="Risk grade assigned")
    processing_confidence: float = Field(description="Confidence in processing results")
    
    # Loan sizing
    recommended_loan_amount: Optional[float] = Field(default=None, description="Recommended loan amount")
    
    # Key metrics
    key_metrics: Dict[str, Any] = Field(default_factory=dict, description="Key financial metrics")
    
    @property
    def is_approved(self) -> bool:
        """Check if application is approved."""
        return "APPROVED" in self.recommendation.upper()


class EntitySummary(BaseModel):
    """Summary of entity information."""
    
    legal_name: str = Field(description="Legal entity name")
    constitution: str = Field(description="Entity constitution")
    pan_number: str = Field(description="PAN number")
    gst_number: Optional[str] = Field(default=None, description="GST number")
    date_of_establishment: Optional[str] = Field(default=None, description="Date of establishment")
    registered_address: str = Field(description="Registered address")
    business_activity: Optional[str] = Field(default=None, description="Business activity")
    msm_classification: Optional[str] = Field(default=None, description="MSM classification")


class KMPSummary(BaseModel):
    """Summary of KMP information."""
    
    name: str = Field(description="KMP name")
    role: str = Field(description="Role in entity")
    shareholding: Optional[str] = Field(default=None, description="Shareholding percentage")
    pan_number: Optional[str] = Field(default=None, description="PAN number")
    cibil_score: Optional[int] = Field(default=None, description="CIBIL score")
    kyc_status: str = Field(description="KYC status")
    missing_documents: List[str] = Field(default_factory=list, description="Missing documents")
    risk_flags: str = Field(default="None", description="Risk flags")


class FinancialSummary(BaseModel):
    """Summary of financial information."""
    
    annual_turnover: str = Field(description="Annual turnover")
    growth_rate: str = Field(description="Growth rate")
    net_profit_margin: str = Field(description="Net profit margin")
    debt_equity_ratio: str = Field(description="Debt-to-equity ratio")
    working_capital: str = Field(description="Working capital")
    debt_service_capacity: str = Field(description="Debt service capacity")
    
    # Additional metrics
    current_ratio: Optional[str] = Field(default=None, description="Current ratio")
    interest_coverage: Optional[str] = Field(default=None, description="Interest coverage ratio")


class BankingSummary(BaseModel):
    """Summary of banking information."""
    
    accounts_analyzed: int = Field(description="Number of accounts analyzed")
    average_balance: str = Field(description="Average balance")
    monthly_cash_flow: str = Field(description="Monthly cash flow")
    account_conduct: str = Field(description="Account conduct rating")
    
    # Additional details
    banking_relationship_years: Optional[int] = Field(default=None, description="Banking relationship years")
    credit_facilities: Optional[str] = Field(default=None, description="Credit facilities")


class ComprehensiveBorrowerProfile(BaseModel):
    """Comprehensive borrower profile."""
    
    entity_summary: EntitySummary = Field(description="Entity summary")
    kmp_summary: List[KMPSummary] = Field(description="KMP summaries")
    financial_summary: FinancialSummary = Field(description="Financial summary")
    banking_summary: BankingSummary = Field(description="Banking summary")
    
    # Additional profile information
    business_vintage: Optional[int] = Field(default=None, description="Business vintage in years")
    industry_sector: Optional[str] = Field(default=None, description="Industry sector")
    geographic_presence: Optional[List[str]] = Field(default=None, description="Geographic presence")


class ScoreSummary(BaseModel):
    """Summary of scores."""
    
    cmr_score: Optional[int] = Field(default=None, description="CMR score")
    grade: Optional[str] = Field(default=None, description="Commercial grade")
    status: str = Field(description="Status")


class CibilSummary(BaseModel):
    """Summary of CIBIL scores."""
    
    average_cibil: Optional[int] = Field(default=None, description="Average CIBIL score")
    lowest_score: Optional[int] = Field(default=None, description="Lowest score")
    all_above_threshold: bool = Field(description="All above threshold")


class ComplianceStatus(BaseModel):
    """Compliance status summary."""
    
    gst_compliance: str = Field(description="GST compliance status")
    pan_validation: str = Field(description="PAN validation status")
    documentation: str = Field(description="Documentation status")


class VerificationSummary(BaseModel):
    """Summary of verification results."""
    
    entity_commercial_score: ScoreSummary = Field(description="Entity commercial score")
    kmp_consumer_scores: CibilSummary = Field(description="KMP consumer scores")
    compliance_status: ComplianceStatus = Field(description="Compliance status")


class RiskAssessmentSummary(BaseModel):
    """Summary of risk assessment."""
    
    overall_risk_score: float = Field(description="Overall risk score")
    risk_category: str = Field(description="Risk category")
    risk_grade: str = Field(description="Risk grade")
    
    key_strengths: List[str] = Field(description="Key strengths")
    areas_of_concern: List[str] = Field(description="Areas of concern")
    recommended_mitigations: List[str] = Field(description="Recommended mitigations")


class ProposedTerms(BaseModel):
    """Proposed loan terms."""
    
    loan_amount: float = Field(description="Proposed loan amount")
    tenure: str = Field(description="Proposed tenure")
    interest_rate: str = Field(description="Proposed interest rate")
    emi: str = Field(description="Estimated EMI")
    dscr: float = Field(description="Debt service coverage ratio")
    
    # Additional terms
    security: Optional[str] = Field(default=None, description="Security requirements")
    guarantees: Optional[str] = Field(default=None, description="Guarantee requirements")
    covenants: Optional[List[str]] = Field(default=None, description="Loan covenants")


class LoanRecommendation(BaseModel):
    """Final loan recommendation."""
    
    primary_recommendation: str = Field(description="Primary recommendation")
    confidence_level: str = Field(description="Confidence level")
    recommended_loan_amount: float = Field(description="Recommended loan amount")
    
    suggested_conditions: List[str] = Field(description="Suggested conditions")
    proposed_terms: ProposedTerms = Field(description="Proposed terms")
    
    estimated_processing_timeline: str = Field(description="Estimated processing timeline")
    next_steps: List[str] = Field(description="Next steps")
    
    # Risk mitigation
    risk_mitigation_measures: Optional[List[str]] = Field(
        default=None,
        description="Risk mitigation measures"
    )
    
    # Monitoring requirements
    monitoring_requirements: Optional[List[str]] = Field(
        default=None,
        description="Ongoing monitoring requirements"
    )


class ProcessingSummary(BaseModel):
    """Summary of processing workflow."""
    
    total_processing_time: float = Field(description="Total processing time in seconds")
    agents_executed: List[str] = Field(description="List of agents executed")
    total_api_calls: int = Field(description="Total API calls made")
    total_api_cost: float = Field(description="Total API cost")
    
    # Processing efficiency
    processing_efficiency: Optional[str] = Field(default=None, description="Processing efficiency rating")
    automation_percentage: Optional[float] = Field(default=None, description="Automation percentage")


class QualityMetrics(BaseModel):
    """Quality metrics for the processing."""
    
    document_confidence_average: float = Field(description="Average document confidence")
    data_completeness_score: float = Field(description="Data completeness score")
    cross_validation_score: float = Field(description="Cross-validation score")
    
    # Quality flags
    quality_flags: List[str] = Field(default_factory=list, description="Quality flags")
    manual_review_required: bool = Field(description="Whether manual review is required")


class FinalReport(BaseModel):
    """Complete final report for loan application."""
    
    # Report metadata
    report_id: str = Field(description="Unique report ID")
    thread_id: str = Field(description="Thread ID")
    generated_at: datetime = Field(default_factory=datetime.utcnow, description="Report generation time")
    report_version: str = Field(default="1.0", description="Report version")
    
    # Core sections
    executive_summary: ExecutiveSummary = Field(description="Executive summary")
    comprehensive_borrower_profile: ComprehensiveBorrowerProfile = Field(
        description="Comprehensive borrower profile"
    )
    verification_summary: VerificationSummary = Field(description="Verification summary")
    risk_assessment_summary: RiskAssessmentSummary = Field(description="Risk assessment summary")
    loan_recommendation: LoanRecommendation = Field(description="Loan recommendation")
    
    # Processing information
    processing_summary: ProcessingSummary = Field(description="Processing summary")
    quality_metrics: QualityMetrics = Field(description="Quality metrics")
    
    # Supporting data
    supporting_documents: List[str] = Field(default_factory=list, description="Supporting documents")
    data_sources: List[str] = Field(default_factory=list, description="Data sources used")
    
    # Compliance and audit
    compliance_checklist: Dict[str, bool] = Field(
        default_factory=dict,
        description="Compliance checklist"
    )
    audit_trail: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="Audit trail of processing steps"
    )
    
    # Warnings and disclaimers
    warnings: List[str] = Field(default_factory=list, description="Warnings")
    disclaimers: List[str] = Field(default_factory=list, description="Disclaimers")
    
    # Additional sections for comprehensive reporting
    market_analysis: Optional[Dict[str, Any]] = Field(default=None, description="Market analysis")
    industry_comparison: Optional[Dict[str, Any]] = Field(default=None, description="Industry comparison")
    regulatory_compliance: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Regulatory compliance details"
    )
    
    def add_audit_entry(self, agent: str, action: str, timestamp: datetime, details: Dict[str, Any]) -> None:
        """Add an audit trail entry."""
        entry = {
            "agent": agent,
            "action": action,
            "timestamp": timestamp,
            "details": details
        }
        self.audit_trail.append(entry)
    
    def add_supporting_document(self, document_name: str) -> None:
        """Add a supporting document."""
        if document_name not in self.supporting_documents:
            self.supporting_documents.append(document_name)
    
    def add_data_source(self, source: str) -> None:
        """Add a data source."""
        if source not in self.data_sources:
            self.data_sources.append(source)
    
    def mark_compliance_item(self, item: str, status: bool) -> None:
        """Mark a compliance checklist item."""
        self.compliance_checklist[item] = status
    
    @property
    def is_approved(self) -> bool:
        """Check if the loan is approved."""
        return self.executive_summary.is_approved
    
    @property
    def requires_manual_review(self) -> bool:
        """Check if manual review is required."""
        return self.quality_metrics.manual_review_required
    
    @property
    def processing_time_minutes(self) -> float:
        """Get processing time in minutes."""
        return self.processing_summary.total_processing_time / 60.0
    
    def get_recommendation_summary(self) -> str:
        """Get a brief recommendation summary."""
        return f"{self.loan_recommendation.primary_recommendation} - {self.loan_recommendation.confidence_level}"
</file>

<file path="msme_underwriting/models/financial.py">
"""Models for financial analysis."""

from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel


class TurnoverAnalysis(BaseModel):
    """Turnover analysis results."""
    
    annual_turnover_2023: Optional[float] = Field(default=None, description="Annual turnover for 2023")
    annual_turnover_2022: Optional[float] = Field(default=None, description="Annual turnover for 2022")
    annual_turnover_2021: Optional[float] = Field(default=None, description="Annual turnover for 2021")
    
    growth_rate: Optional[float] = Field(default=None, description="Year-over-year growth rate")
    cagr_3_year: Optional[float] = Field(default=None, description="3-year CAGR")
    industry_benchmark: Optional[float] = Field(default=None, description="Industry benchmark growth")
    assessment: str = Field(description="Turnover assessment (above_average/average/below_average)")
    
    # Seasonal analysis
    seasonal_patterns: Optional[Dict[str, Any]] = Field(default=None, description="Seasonal patterns")
    monthly_breakdown: Optional[List[Dict[str, Any]]] = Field(default=None, description="Monthly breakdown")
    
    @property
    def shows_growth(self) -> bool:
        """Check if turnover shows growth."""
        return self.growth_rate is not None and self.growth_rate > 0
    
    @property
    def outperforms_industry(self) -> bool:
        """Check if growth outperforms industry benchmark."""
        return (
            self.growth_rate is not None and 
            self.industry_benchmark is not None and
            self.growth_rate > self.industry_benchmark
        )


class ProfitabilityRatios(BaseModel):
    """Profitability ratio analysis."""
    
    # Margin ratios
    net_profit_margin_2023: Optional[float] = Field(default=None, description="Net profit margin 2023")
    net_profit_margin_2022: Optional[float] = Field(default=None, description="Net profit margin 2022")
    gross_profit_margin_2023: Optional[float] = Field(default=None, description="Gross profit margin 2023")
    operating_profit_margin_2023: Optional[float] = Field(default=None, description="Operating profit margin 2023")
    ebitda_margin_2023: Optional[float] = Field(default=None, description="EBITDA margin 2023")
    
    # Return ratios
    return_on_assets: Optional[float] = Field(default=None, description="Return on assets")
    return_on_equity: Optional[float] = Field(default=None, description="Return on equity")
    return_on_capital_employed: Optional[float] = Field(default=None, description="Return on capital employed")
    
    # Trend analysis
    trend: str = Field(description="Profitability trend (improving/stable/declining)")
    industry_comparison: str = Field(description="Industry comparison (favorable/average/unfavorable)")
    
    # Benchmarking
    industry_benchmarks: Optional[Dict[str, float]] = Field(default=None, description="Industry benchmarks")
    
    @property
    def is_profitable(self) -> bool:
        """Check if entity is profitable."""
        return self.net_profit_margin_2023 is not None and self.net_profit_margin_2023 > 0
    
    @property
    def margins_improving(self) -> bool:
        """Check if profit margins are improving."""
        return (
            self.net_profit_margin_2023 is not None and
            self.net_profit_margin_2022 is not None and
            self.net_profit_margin_2023 > self.net_profit_margin_2022
        )


class LiquidityRatios(BaseModel):
    """Liquidity ratio analysis."""
    
    current_ratio_2023: Optional[float] = Field(default=None, description="Current ratio 2023")
    current_ratio_2022: Optional[float] = Field(default=None, description="Current ratio 2022")
    quick_ratio_2023: Optional[float] = Field(default=None, description="Quick ratio 2023")
    cash_ratio: Optional[float] = Field(default=None, description="Cash ratio")
    
    # Working capital
    working_capital: Optional[float] = Field(default=None, description="Working capital amount")
    working_capital_ratio: Optional[float] = Field(default=None, description="Working capital ratio")
    working_capital_cycle: Optional[int] = Field(default=None, description="Working capital cycle in days")
    
    # Assessment
    assessment: str = Field(description="Liquidity assessment (excellent/adequate/poor)")
    
    # Components
    current_assets: Optional[float] = Field(default=None, description="Current assets")
    current_liabilities: Optional[float] = Field(default=None, description="Current liabilities")
    inventory: Optional[float] = Field(default=None, description="Inventory")
    receivables: Optional[float] = Field(default=None, description="Accounts receivable")
    
    @property
    def has_adequate_liquidity(self) -> bool:
        """Check if liquidity is adequate."""
        return self.current_ratio_2023 is not None and self.current_ratio_2023 >= 1.2
    
    @property
    def liquidity_improving(self) -> bool:
        """Check if liquidity is improving."""
        return (
            self.current_ratio_2023 is not None and
            self.current_ratio_2022 is not None and
            self.current_ratio_2023 > self.current_ratio_2022
        )


class LeverageRatios(BaseModel):
    """Leverage ratio analysis."""
    
    debt_equity_ratio_2023: Optional[float] = Field(default=None, description="Debt-to-equity ratio 2023")
    debt_equity_ratio_2022: Optional[float] = Field(default=None, description="Debt-to-equity ratio 2022")
    debt_service_coverage_ratio: Optional[float] = Field(default=None, description="Debt service coverage ratio")
    interest_coverage_ratio: Optional[float] = Field(default=None, description="Interest coverage ratio")
    
    # Debt components
    total_debt: Optional[float] = Field(default=None, description="Total debt")
    long_term_debt: Optional[float] = Field(default=None, description="Long-term debt")
    short_term_debt: Optional[float] = Field(default=None, description="Short-term debt")
    total_equity: Optional[float] = Field(default=None, description="Total equity")
    
    # Assessment
    assessment: str = Field(description="Leverage assessment (conservative/manageable/aggressive)")
    
    # Capacity analysis
    additional_debt_capacity: Optional[float] = Field(default=None, description="Additional debt capacity")
    optimal_debt_level: Optional[float] = Field(default=None, description="Optimal debt level")
    
    @property
    def has_manageable_leverage(self) -> bool:
        """Check if leverage is manageable."""
        return (
            self.debt_equity_ratio_2023 is not None and 
            self.debt_equity_ratio_2023 <= 2.0 and
            self.debt_service_coverage_ratio is not None and
            self.debt_service_coverage_ratio >= 1.25
        )
    
    @property
    def can_service_additional_debt(self) -> bool:
        """Check if entity can service additional debt."""
        return self.debt_service_coverage_ratio is not None and self.debt_service_coverage_ratio >= 1.5


class CashFlowAnalysis(BaseModel):
    """Cash flow analysis results."""
    
    # Operating cash flow
    operating_cash_flow: Optional[float] = Field(default=None, description="Operating cash flow")
    operating_cash_flow_margin: Optional[float] = Field(default=None, description="Operating cash flow margin")
    
    # Investing cash flow
    investing_cash_flow: Optional[float] = Field(default=None, description="Investing cash flow")
    capex: Optional[float] = Field(default=None, description="Capital expenditure")
    
    # Financing cash flow
    financing_cash_flow: Optional[float] = Field(default=None, description="Financing cash flow")
    debt_repayment: Optional[float] = Field(default=None, description="Debt repayment")
    
    # Free cash flow
    free_cash_flow: Optional[float] = Field(default=None, description="Free cash flow")
    free_cash_flow_yield: Optional[float] = Field(default=None, description="Free cash flow yield")
    
    # Stability assessment
    cash_flow_stability: str = Field(description="Cash flow stability (stable/volatile/declining)")
    cash_conversion_cycle: Optional[int] = Field(default=None, description="Cash conversion cycle in days")
    
    # Projections
    projected_cash_flows: Optional[List[Dict[str, Any]]] = Field(
        default=None, 
        description="Projected cash flows"
    )
    
    @property
    def generates_positive_operating_cash_flow(self) -> bool:
        """Check if entity generates positive operating cash flow."""
        return self.operating_cash_flow is not None and self.operating_cash_flow > 0
    
    @property
    def has_positive_free_cash_flow(self) -> bool:
        """Check if entity has positive free cash flow."""
        return self.free_cash_flow is not None and self.free_cash_flow > 0


class LoanServicingCapacity(BaseModel):
    """Loan servicing capacity analysis."""
    
    monthly_cash_flow: Optional[float] = Field(default=None, description="Monthly cash flow")
    debt_service_capacity: Optional[float] = Field(default=None, description="Monthly debt service capacity")
    recommended_emi: Optional[float] = Field(default=None, description="Recommended EMI")
    debt_service_coverage_ratio: Optional[float] = Field(default=None, description="DSCR")
    
    # Loan sizing
    maximum_sustainable_loan: Optional[float] = Field(default=None, description="Maximum sustainable loan amount")
    
    # Requested loan analysis
    requested_loan_servicing: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Analysis of requested loan servicing"
    )
    
    # Stress testing
    stress_test_results: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Stress test results"
    )
    
    # Seasonal adjustments
    seasonal_adjustments: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Seasonal cash flow adjustments"
    )
    
    @property
    def can_service_requested_loan(self) -> bool:
        """Check if entity can service the requested loan."""
        if self.requested_loan_servicing is None:
            return False
        
        dscr = self.requested_loan_servicing.get("dscr_at_requested")
        return dscr is not None and dscr >= 1.25
    
    @property
    def has_adequate_dscr(self) -> bool:
        """Check if DSCR is adequate."""
        return self.debt_service_coverage_ratio is not None and self.debt_service_coverage_ratio >= 1.25


class FinancialHealthAssessment(BaseModel):
    """Complete financial health assessment."""
    
    turnover_analysis: TurnoverAnalysis = Field(description="Turnover analysis")
    profitability_ratios: ProfitabilityRatios = Field(description="Profitability ratios")
    liquidity_ratios: LiquidityRatios = Field(description="Liquidity ratios")
    leverage_ratios: LeverageRatios = Field(description="Leverage ratios")
    cash_flow_analysis: CashFlowAnalysis = Field(description="Cash flow analysis")
    
    # Overall assessment
    overall_financial_health: str = Field(description="Overall financial health (excellent/good/fair/poor)")
    financial_strength_score: Optional[float] = Field(default=None, description="Financial strength score")
    
    # Key insights
    key_strengths: List[str] = Field(default_factory=list, description="Key financial strengths")
    areas_of_concern: List[str] = Field(default_factory=list, description="Areas of concern")
    improvement_recommendations: List[str] = Field(default_factory=list, description="Improvement recommendations")
    
    # Industry comparison
    industry_percentile: Optional[float] = Field(default=None, description="Industry percentile ranking")
    peer_comparison: Optional[Dict[str, Any]] = Field(default=None, description="Peer comparison")
    
    def calculate_composite_score(self) -> float:
        """Calculate composite financial health score."""
        scores = []
        
        # Profitability score (0-100)
        if self.profitability_ratios.net_profit_margin_2023 is not None:
            profit_score = min(self.profitability_ratios.net_profit_margin_2023 * 10, 100)
            scores.append(profit_score)
        
        # Liquidity score (0-100)
        if self.liquidity_ratios.current_ratio_2023 is not None:
            liquidity_score = min(self.liquidity_ratios.current_ratio_2023 * 50, 100)
            scores.append(liquidity_score)
        
        # Leverage score (0-100, inverted)
        if self.leverage_ratios.debt_equity_ratio_2023 is not None:
            leverage_score = max(100 - self.leverage_ratios.debt_equity_ratio_2023 * 25, 0)
            scores.append(leverage_score)
        
        # Cash flow score (0-100)
        if self.cash_flow_analysis.operating_cash_flow is not None:
            cf_score = 100 if self.cash_flow_analysis.operating_cash_flow > 0 else 0
            scores.append(cf_score)
        
        return sum(scores) / len(scores) if scores else 0.0
    
    @property
    def is_financially_healthy(self) -> bool:
        """Check if entity is financially healthy."""
        return self.overall_financial_health in ["excellent", "good"]
    
    @property
    def meets_lending_criteria(self) -> bool:
        """Check if entity meets basic lending criteria."""
        return (
            self.profitability_ratios.is_profitable and
            self.liquidity_ratios.has_adequate_liquidity and
            self.leverage_ratios.has_manageable_leverage and
            self.cash_flow_analysis.generates_positive_operating_cash_flow
        )
</file>

<file path="msme_underwriting/models/kmp.py">
"""Models for Key Management Personnel (KMP) analysis."""

from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel


class ConstitutionRequirements(BaseModel):
    """Requirements based on entity constitution."""
    
    entity_type: str = Field(description="Type of entity")
    minimum_partners_required: Optional[int] = Field(default=None, description="Minimum partners required")
    maximum_partners_allowed: Optional[int] = Field(default=None, description="Maximum partners allowed")
    minimum_coverage_required: float = Field(description="Minimum coverage percentage required")
    required_documents: List[str] = Field(description="Required documents for this constitution")
    
    def get_coverage_requirement(self) -> float:
        """Get the minimum coverage requirement."""
        return self.minimum_coverage_required


class IdentifiedKMP(BaseModel):
    """Information about an identified Key Management Personnel."""
    
    kmp_id: str = Field(description="Unique KMP identifier")
    name: str = Field(description="KMP name")
    role: str = Field(description="Role in the entity (partner, director, etc.)")
    
    # Identity documents
    pan_number: Optional[str] = Field(default=None, description="PAN number")
    aadhaar_number: Optional[str] = Field(default=None, description="Aadhaar number")
    
    # Shareholding/Partnership details
    shareholding_percentage: Optional[float] = Field(default=None, description="Shareholding percentage")
    partnership_share: Optional[float] = Field(default=None, description="Partnership share")
    
    # Document availability
    documents_available: List[str] = Field(description="List of available documents")
    missing_documents: List[str] = Field(default_factory=list, description="List of missing documents")
    
    # API verification
    api_verified: bool = Field(default=False, description="Whether KMP is API verified")
    verified_name: Optional[str] = Field(default=None, description="API verified name")
    
    # Contact information
    address: Optional[Dict[str, str]] = Field(default=None, description="Address information")
    phone_number: Optional[str] = Field(default=None, description="Phone number")
    email: Optional[str] = Field(default=None, description="Email address")
    
    # KYC status
    kyc_completeness: str = Field(description="KYC completeness status")
    kyc_score: Optional[float] = Field(default=None, description="KYC completeness score")
    
    # Risk assessment
    risk_flags: List[str] = Field(default_factory=list, description="Risk flags for this KMP")
    risk_score: Optional[float] = Field(default=None, description="Individual risk score")
    
    # Additional details
    date_of_birth: Optional[str] = Field(default=None, description="Date of birth")
    appointment_date: Optional[str] = Field(default=None, description="Date of appointment")
    
    @property
    def has_complete_kyc(self) -> bool:
        """Check if KMP has complete KYC."""
        return self.kyc_completeness == "complete"
    
    @property
    def effective_share(self) -> float:
        """Get effective shareholding/partnership share."""
        return self.shareholding_percentage or self.partnership_share or 0.0
    
    def get_missing_documents_for_kyc(self) -> List[str]:
        """Get documents missing for complete KYC."""
        required_docs = ["pan_card", "aadhaar_card"]
        available_docs = [doc.lower() for doc in self.documents_available]
        return [doc for doc in required_docs if doc not in available_docs]


class KMPCoverageAnalysis(BaseModel):
    """Analysis of KMP coverage."""
    
    total_partners_identified: int = Field(description="Total number of partners/directors identified")
    partners_with_complete_kyc: int = Field(description="Partners with complete KYC")
    partners_with_partial_kyc: int = Field(description="Partners with partial KYC")
    partners_with_no_kyc: int = Field(default=0, description="Partners with no KYC")
    
    total_shareholding_covered: float = Field(description="Total shareholding percentage covered")
    coverage_percentage: float = Field(description="Coverage percentage (0.0 to 1.0)")
    minimum_coverage_met: bool = Field(description="Whether minimum coverage is met")
    
    # Detailed breakdown
    coverage_by_kyc_status: Dict[str, float] = Field(
        default_factory=dict,
        description="Coverage breakdown by KYC status"
    )
    
    def calculate_coverage_metrics(self, kmps: List[IdentifiedKMP]) -> None:
        """Calculate coverage metrics from KMP list."""
        total_share = sum(kmp.effective_share for kmp in kmps)
        complete_kyc_share = sum(
            kmp.effective_share for kmp in kmps if kmp.has_complete_kyc
        )
        
        self.total_shareholding_covered = total_share
        self.coverage_percentage = complete_kyc_share / 100.0 if total_share > 0 else 0.0
        
        # Update counts
        self.partners_with_complete_kyc = sum(1 for kmp in kmps if kmp.has_complete_kyc)
        self.partners_with_partial_kyc = sum(
            1 for kmp in kmps 
            if not kmp.has_complete_kyc and len(kmp.documents_available) > 0
        )
        self.partners_with_no_kyc = sum(
            1 for kmp in kmps 
            if len(kmp.documents_available) == 0
        )


class KMPAnalysis(BaseModel):
    """Complete KMP analysis results."""
    
    constitution_requirements: ConstitutionRequirements = Field(
        description="Requirements based on entity constitution"
    )
    identified_kmps: List[IdentifiedKMP] = Field(description="List of identified KMPs")
    kmp_coverage_analysis: KMPCoverageAnalysis = Field(description="Coverage analysis")
    
    # Cross-validation results
    cross_validation_results: Dict[str, Any] = Field(
        default_factory=dict,
        description="Cross-validation results across documents"
    )
    
    # Missing requirements
    missing_requirements: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="Missing KMP requirements"
    )
    
    # Data sources used
    data_sources_used: List[str] = Field(
        default_factory=list,
        description="Data sources used for KMP identification"
    )
    
    def get_kmp_by_id(self, kmp_id: str) -> Optional[IdentifiedKMP]:
        """Get KMP by ID."""
        for kmp in self.identified_kmps:
            if kmp.kmp_id == kmp_id:
                return kmp
        return None
    
    def get_kmps_by_role(self, role: str) -> List[IdentifiedKMP]:
        """Get KMPs by role."""
        return [kmp for kmp in self.identified_kmps if kmp.role.lower() == role.lower()]
    
    def get_kmps_with_complete_kyc(self) -> List[IdentifiedKMP]:
        """Get KMPs with complete KYC."""
        return [kmp for kmp in self.identified_kmps if kmp.has_complete_kyc]
    
    def get_kmps_missing_documents(self) -> List[IdentifiedKMP]:
        """Get KMPs with missing documents."""
        return [kmp for kmp in self.identified_kmps if len(kmp.missing_documents) > 0]
    
    def add_missing_requirement(self, requirement_type: str, missing_for: str, 
                              required_documents: List[str], shareholding_impact: float,
                              mandatory: bool, business_justification: str) -> None:
        """Add a missing requirement."""
        requirement = {
            "requirement_type": requirement_type,
            "missing_for": missing_for,
            "required_documents": required_documents,
            "shareholding_impact": shareholding_impact,
            "mandatory": mandatory,
            "business_justification": business_justification
        }
        self.missing_requirements.append(requirement)
    
    @property
    def total_identified_kmps(self) -> int:
        """Get total number of identified KMPs."""
        return len(self.identified_kmps)
    
    @property
    def meets_minimum_coverage(self) -> bool:
        """Check if minimum coverage requirement is met."""
        return self.kmp_coverage_analysis.minimum_coverage_met
    
    @property
    def coverage_percentage(self) -> float:
        """Get coverage percentage."""
        return self.kmp_coverage_analysis.coverage_percentage
    
    def calculate_risk_score(self) -> float:
        """Calculate overall KMP risk score."""
        if not self.identified_kmps:
            return 1.0  # High risk if no KMPs identified
        
        # Calculate based on coverage and individual risk scores
        coverage_score = self.coverage_percentage
        individual_risk_scores = [
            kmp.risk_score for kmp in self.identified_kmps 
            if kmp.risk_score is not None
        ]
        
        if individual_risk_scores:
            avg_individual_risk = sum(individual_risk_scores) / len(individual_risk_scores)
        else:
            avg_individual_risk = 0.5  # Neutral if no individual scores
        
        # Combine coverage and individual risk (weighted)
        overall_risk = (1 - coverage_score) * 0.6 + avg_individual_risk * 0.4
        return min(max(overall_risk, 0.0), 1.0)  # Clamp between 0 and 1
</file>

<file path="msme_underwriting/models/loan_application.py">
"""Models for loan application data."""

from datetime import datetime
from typing import List, Optional
from pydantic import Field

from .base import BaseModel, TimestampedModel


class LoanContext(BaseModel):
    """Context information about the loan application."""
    
    loan_type: str = Field(description="Type of loan (e.g., MSM_supply_chain)")
    loan_amount: int = Field(description="Requested loan amount")
    application_timestamp: datetime = Field(description="When the application was submitted")
    purpose: Optional[str] = Field(default=None, description="Purpose of the loan")
    tenure_months: Optional[int] = Field(default=None, description="Requested tenure in months")


class UploadedFile(BaseModel):
    """Information about an uploaded file."""
    
    file_name: str = Field(description="Name of the uploaded file")
    file_path: str = Field(description="Path to the uploaded file")
    file_size: int = Field(description="Size of the file in bytes")
    upload_timestamp: datetime = Field(description="When the file was uploaded")
    file_type: str = Field(description="MIME type of the file")
    checksum: Optional[str] = Field(default=None, description="File checksum for integrity")


class ProcessingOptions(BaseModel):
    """Options for document processing."""
    
    max_pages_per_document: int = Field(default=50, description="Maximum pages to process per document")
    include_raw_responses: bool = Field(default=False, description="Include raw API responses")
    vision_model: str = Field(default="gpt-4o", description="Vision model to use for processing")
    confidence_threshold: float = Field(default=0.7, description="Minimum confidence threshold")
    enable_ocr: bool = Field(default=True, description="Enable OCR processing")
    language: str = Field(default="en", description="Document language")


class LoanApplication(TimestampedModel):
    """Complete loan application data."""
    
    thread_id: str = Field(description="Unique thread ID for this application")
    user_id: str = Field(description="ID of the user submitting the application")
    loan_context: LoanContext = Field(description="Loan context information")
    uploaded_files: List[UploadedFile] = Field(description="List of uploaded files")
    processing_options: ProcessingOptions = Field(description="Processing options")
    
    # Application status tracking
    current_step: str = Field(default="start", description="Current processing step")
    status: str = Field(default="submitted", description="Application status")
    priority: str = Field(default="normal", description="Processing priority")
    
    # Metadata
    source: str = Field(default="web", description="Application source")
    ip_address: Optional[str] = Field(default=None, description="Client IP address")
    user_agent: Optional[str] = Field(default=None, description="Client user agent")
    
    def update_step(self, step: str) -> None:
        """Update the current processing step."""
        self.current_step = step
        self.update_timestamp()
    
    def update_status(self, status: str) -> None:
        """Update the application status."""
        self.status = status
        self.update_timestamp()
    
    @property
    def total_file_size(self) -> int:
        """Calculate total size of all uploaded files."""
        return sum(file.file_size for file in self.uploaded_files)
    
    @property
    def file_count(self) -> int:
        """Get the number of uploaded files."""
        return len(self.uploaded_files)
    
    def get_files_by_type(self, file_type: str) -> List[UploadedFile]:
        """Get files filtered by MIME type."""
        return [file for file in self.uploaded_files if file.file_type == file_type]
</file>

<file path="msme_underwriting/models/state.py">
"""State models for LangGraph workflow."""

from datetime import datetime
from typing import Dict, List, Optional, Any, Literal
from pydantic import Field
from langgraph.graph import MessagesState

from .base import BaseModel, ProcessingMetadata, RoutingDecision
from .loan_application import LoanApplication
from .documents import ClassifiedDocuments, DocumentAnalysis, MissingDocument, ValidationWarning
from .entity import EntityProfile
from .kmp import KMPAnalysis
from .verification import BureauVerificationResults, EnhancedGSTAnalysis, PolicyComplianceAssessment, RiskAssessment, EligibilityDetermination
from .financial import FinancialHealthAssessment, LoanServicingCapacity
from .banking import BankingAssessment
from .final_report import FinalReport


class AgentContext(BaseModel):
    """Context information for agent execution."""
    
    previous_agent: Optional[str] = Field(default=None, description="Name of the previous agent")
    trigger_reason: str = Field(description="Reason this agent was triggered")
    processing_timestamp: datetime = Field(default_factory=datetime.utcnow, description="When processing started")
    retry_count: int = Field(default=0, description="Number of retries for this agent")
    timeout_seconds: int = Field(default=300, description="Timeout for this agent")


class MSMELoanState(MessagesState):
    """
    Complete state for MSME loan processing workflow.
    
    This state is shared across all agents in the LangGraph workflow and contains
    all the data needed for loan processing decisions.
    """
    
    # Core application data
    thread_id: str = Field(description="Unique thread ID for this loan application")
    loan_application: LoanApplication = Field(description="Original loan application data")
    current_step: str = Field(default="start", description="Current processing step")
    
    # Agent context
    agent_context: Optional[AgentContext] = Field(default=None, description="Current agent context")
    
    # Processing results from each agent
    agent_results: Dict[str, Any] = Field(default_factory=dict, description="Results from each agent")
    
    # Agent 1: Document Classification Results
    classified_documents: Optional[ClassifiedDocuments] = Field(
        default=None, 
        description="Classified and extracted documents"
    )
    document_analysis: Optional[DocumentAnalysis] = Field(
        default=None,
        description="Analysis of document processing"
    )
    missing_documents: List[MissingDocument] = Field(
        default_factory=list,
        description="List of missing required documents"
    )
    validation_warnings: List[ValidationWarning] = Field(
        default_factory=list,
        description="Document validation warnings"
    )
    
    # Agent 2: Entity & KMP Results
    entity_profile: Optional[EntityProfile] = Field(
        default=None,
        description="Identified entity profile"
    )
    kmp_analysis: Optional[KMPAnalysis] = Field(
        default=None,
        description="KMP identification and analysis"
    )
    basic_group_identification: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Basic group company identification"
    )
    cross_validation_results: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Cross-validation results across documents"
    )
    
    # Agent 3: Verification & Compliance Results
    bureau_verification_results: Optional[BureauVerificationResults] = Field(
        default=None,
        description="Bureau verification results"
    )
    enhanced_gst_analysis: Optional[EnhancedGSTAnalysis] = Field(
        default=None,
        description="Enhanced GST analysis results"
    )
    pan_validation: Optional[Dict[str, Any]] = Field(
        default=None,
        description="PAN validation results"
    )
    policy_compliance_assessment: Optional[PolicyComplianceAssessment] = Field(
        default=None,
        description="Policy compliance assessment"
    )
    risk_assessment: Optional[RiskAssessment] = Field(
        default=None,
        description="Risk assessment results"
    )
    eligibility_determination: Optional[EligibilityDetermination] = Field(
        default=None,
        description="Eligibility determination"
    )
    
    # Agent 4: Financial Analysis Results
    financial_health_assessment: Optional[FinancialHealthAssessment] = Field(
        default=None,
        description="Financial health assessment"
    )
    banking_integration_analysis: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Banking integration analysis"
    )
    gst_financial_reconciliation: Optional[Dict[str, Any]] = Field(
        default=None,
        description="GST-Financial reconciliation"
    )
    loan_servicing_capacity: Optional[LoanServicingCapacity] = Field(
        default=None,
        description="Loan servicing capacity analysis"
    )
    risk_assessment_enhancement: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Enhanced risk assessment from financial analysis"
    )
    
    # Agent 7: Banking Analysis Results
    banking_assessment: Optional[BankingAssessment] = Field(
        default=None,
        description="Comprehensive banking assessment"
    )
    
    # Agent 5: Relationship Mapping Results (Phase 2)
    relationship_mapping: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Relationship mapping results"
    )
    corporate_family_tree: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Corporate family tree"
    )
    group_exposure_analysis: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Group exposure analysis"
    )
    
    # Agent 6: Final Report
    final_report: Optional[FinalReport] = Field(
        default=None,
        description="Final comprehensive report"
    )
    
    # Workflow control
    processing_metadata: Dict[str, ProcessingMetadata] = Field(
        default_factory=dict,
        description="Processing metadata for each agent"
    )
    routing_decisions: List[RoutingDecision] = Field(
        default_factory=list,
        description="History of routing decisions"
    )
    
    # Error handling
    errors: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="List of errors encountered during processing"
    )
    warnings: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="List of warnings encountered during processing"
    )
    
    # Status tracking
    workflow_status: str = Field(default="in_progress", description="Overall workflow status")
    last_updated: datetime = Field(default_factory=datetime.utcnow, description="Last update timestamp")
    
    # Configuration
    business_rules: Dict[str, Any] = Field(
        default_factory=dict,
        description="Business rules and thresholds"
    )
    
    def update_step(self, step: str) -> None:
        """Update the current processing step."""
        self.current_step = step
        self.last_updated = datetime.utcnow()
    
    def add_agent_result(self, agent_name: str, result: Any) -> None:
        """Add result from an agent."""
        self.agent_results[agent_name] = result
        self.last_updated = datetime.utcnow()
    
    def add_processing_metadata(self, agent_name: str, metadata: ProcessingMetadata) -> None:
        """Add processing metadata for an agent."""
        self.processing_metadata[agent_name] = metadata
        self.last_updated = datetime.utcnow()
    
    def add_routing_decision(self, decision: RoutingDecision) -> None:
        """Add a routing decision."""
        self.routing_decisions.append(decision)
        self.last_updated = datetime.utcnow()
    
    def add_error(self, agent_name: str, error: str, details: Optional[Dict[str, Any]] = None) -> None:
        """Add an error."""
        error_entry = {
            "agent": agent_name,
            "error": error,
            "timestamp": datetime.utcnow(),
            "details": details or {}
        }
        self.errors.append(error_entry)
        self.last_updated = datetime.utcnow()
    
    def add_warning(self, agent_name: str, warning: str, details: Optional[Dict[str, Any]] = None) -> None:
        """Add a warning."""
        warning_entry = {
            "agent": agent_name,
            "warning": warning,
            "timestamp": datetime.utcnow(),
            "details": details or {}
        }
        self.warnings.append(warning_entry)
        self.last_updated = datetime.utcnow()
    
    def get_total_processing_time(self) -> float:
        """Get total processing time across all agents."""
        return sum(
            metadata.total_processing_time 
            for metadata in self.processing_metadata.values()
        )
    
    def get_total_api_cost(self) -> float:
        """Get total API cost across all agents."""
        return sum(
            metadata.total_api_cost 
            for metadata in self.processing_metadata.values()
        )
    
    def is_eligible_for_next_agent(self, agent_name: str) -> bool:
        """Check if the state is eligible for the next agent."""
        # This would contain business logic to determine if we can proceed
        # to the next agent based on current state
        
        if agent_name == "entity_kmp_identification":
            return (
                self.classified_documents is not None and
                len(self.classified_documents.borrower_documents.get("pan_cards", [])) > 0
            )
        elif agent_name == "verification_compliance":
            return (
                self.entity_profile is not None and
                self.kmp_analysis is not None and
                self.kmp_analysis.kmp_coverage_analysis.coverage_percentage >= 0.5
            )
        elif agent_name == "financial_analysis":
            return (
                self.eligibility_determination is not None and
                self.eligibility_determination.overall_eligibility != "rejected"
            )
        elif agent_name == "banking_analysis":
            return (
                self.financial_health_assessment is not None and
                self.classified_documents is not None and
                len(self.classified_documents.banking_documents) > 0
            )
        elif agent_name == "final_assembly":
            return (
                self.banking_assessment is not None and
                self.eligibility_determination is not None and
                self.eligibility_determination.overall_eligibility != "rejected"
            )
        
        return True
    
    @property
    def current_agent_count(self) -> int:
        """Get the number of agents that have processed this application."""
        return len(self.processing_metadata)
    
    @property
    def has_errors(self) -> bool:
        """Check if there are any errors."""
        return len(self.errors) > 0
    
    @property
    def has_warnings(self) -> bool:
        """Check if there are any warnings."""
        return len(self.warnings) > 0
</file>

<file path="msme_underwriting/models/verification.py">
"""Models for verification and compliance analysis."""

from datetime import datetime
from typing import Dict, List, Optional, Any
from pydantic import Field

from .base import BaseModel, ValidationResult


class EntityCommercialBureau(BaseModel):
    """Commercial bureau results for entity."""
    
    bureau_provider: str = Field(description="Bureau provider (e.g., CIBIL)")
    cmr_score: Optional[int] = Field(default=None, description="CMR score")
    commercial_score: Optional[str] = Field(default=None, description="Commercial score grade")
    score_date: Optional[str] = Field(default=None, description="Score date")
    credit_history_months: Optional[int] = Field(default=None, description="Credit history in months")
    total_exposure: Optional[float] = Field(default=None, description="Total credit exposure")
    overdue_amount: Optional[float] = Field(default=None, description="Overdue amount")
    status: str = Field(description="Verification status (pass/fail)")
    risk_indicators: List[str] = Field(default_factory=list, description="Risk indicators")
    
    # Detailed bureau data
    account_summary: Optional[Dict[str, Any]] = Field(default=None, description="Account summary")
    payment_history: Optional[Dict[str, Any]] = Field(default=None, description="Payment history")
    enquiry_summary: Optional[Dict[str, Any]] = Field(default=None, description="Enquiry summary")
    
    @property
    def is_within_cmr_limit(self) -> bool:
        """Check if CMR score is within acceptable limits."""
        if self.cmr_score is None:
            return False
        return 1 <= self.cmr_score <= 8
    
    @property
    def has_overdue_amounts(self) -> bool:
        """Check if there are overdue amounts."""
        return self.overdue_amount is not None and self.overdue_amount > 0


class KMPConsumerBureau(BaseModel):
    """Consumer bureau results for KMP."""
    
    kmp_id: str = Field(description="KMP identifier")
    name: str = Field(description="KMP name")
    pan_number: str = Field(description="PAN number")
    
    # CIBIL details
    cibil_score: Optional[int] = Field(default=None, description="CIBIL score")
    score_date: Optional[str] = Field(default=None, description="Score date")
    credit_history_months: Optional[int] = Field(default=None, description="Credit history in months")
    
    # Account details
    total_accounts: Optional[int] = Field(default=None, description="Total accounts")
    active_accounts: Optional[int] = Field(default=None, description="Active accounts")
    overdue_accounts: Optional[int] = Field(default=None, description="Overdue accounts")
    closed_accounts: Optional[int] = Field(default=None, description="Closed accounts")
    
    # Exposure details
    total_exposure: Optional[float] = Field(default=None, description="Total exposure")
    current_balance: Optional[float] = Field(default=None, description="Current balance")
    overdue_amount: Optional[float] = Field(default=None, description="Overdue amount")
    
    # Status and flags
    status: str = Field(description="Verification status (pass/fail)")
    risk_flags: List[str] = Field(default_factory=list, description="Risk flags")
    
    # Detailed data
    account_details: List[Dict[str, Any]] = Field(default_factory=list, description="Account details")
    enquiry_details: List[Dict[str, Any]] = Field(default_factory=list, description="Enquiry details")
    
    @property
    def meets_cibil_threshold(self) -> bool:
        """Check if CIBIL score meets threshold (680+)."""
        return self.cibil_score is not None and self.cibil_score >= 680
    
    @property
    def has_recent_enquiries(self) -> bool:
        """Check if there are recent credit enquiries."""
        return len(self.enquiry_details) > 0


class PartnershipCibilCompliance(BaseModel):
    """CIBIL compliance for partnership entities."""
    
    requirement: str = Field(description="Compliance requirement")
    total_partners: int = Field(description="Total number of partners")
    partners_with_scores: int = Field(description="Partners with CIBIL scores")
    partners_above_threshold: int = Field(description="Partners above CIBIL threshold")
    compliance_status: str = Field(description="Compliance status")
    additional_kmps_needed: int = Field(default=0, description="Additional KMPs needed for compliance")
    
    @property
    def compliance_percentage(self) -> float:
        """Calculate compliance percentage."""
        if self.total_partners == 0:
            return 0.0
        return self.partners_above_threshold / self.total_partners
    
    @property
    def meets_50_percent_rule(self) -> bool:
        """Check if 50% of partners meet CIBIL threshold."""
        return self.compliance_percentage >= 0.5


class GSTCompliance(BaseModel):
    """GST compliance details."""
    
    gst_number: str = Field(description="GST number")
    registration_status: str = Field(description="Registration status")
    registration_date: Optional[str] = Field(default=None, description="Registration date")
    last_return_filed: Optional[str] = Field(default=None, description="Last return filed date")
    filing_frequency: Optional[str] = Field(default=None, description="Filing frequency")
    compliance_score: Optional[int] = Field(default=None, description="Compliance score")
    pending_returns: int = Field(default=0, description="Number of pending returns")
    status: str = Field(description="Overall compliance status")
    
    # Detailed compliance data
    return_filing_history: List[Dict[str, Any]] = Field(
        default_factory=list, 
        description="Return filing history"
    )
    tax_payment_history: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="Tax payment history"
    )
    
    @property
    def is_active(self) -> bool:
        """Check if GST registration is active."""
        return self.registration_status.lower() == "active"
    
    @property
    def has_pending_returns(self) -> bool:
        """Check if there are pending returns."""
        return self.pending_returns > 0


class GSTTransactionAnalysis(BaseModel):
    """GST transaction analysis results."""
    
    analysis_period: str = Field(description="Analysis period")
    total_turnover: float = Field(description="Total turnover from GST")
    average_monthly_turnover: float = Field(description="Average monthly turnover")
    turnover_growth_rate: Optional[float] = Field(default=None, description="Turnover growth rate")
    
    # Geographic analysis
    major_states: List[str] = Field(description="Major states of operation")
    interstate_percentage: Optional[float] = Field(default=None, description="Interstate transaction percentage")
    
    # Compliance patterns
    filing_regularity: str = Field(description="Filing regularity assessment")
    tax_payment_pattern: str = Field(description="Tax payment pattern")
    
    # Revenue reconciliation
    revenue_reconciliation: Dict[str, Any] = Field(description="Revenue reconciliation details")
    
    @property
    def shows_consistent_growth(self) -> bool:
        """Check if turnover shows consistent growth."""
        return self.turnover_growth_rate is not None and self.turnover_growth_rate > 0
    
    @property
    def reconciliation_within_tolerance(self) -> bool:
        """Check if revenue reconciliation is within tolerance."""
        reconciliation = self.revenue_reconciliation
        return reconciliation.get("reconciliation_status") == "within_tolerance"


class EnhancedGSTAnalysis(BaseModel):
    """Enhanced GST analysis results."""
    
    gst_compliance: GSTCompliance = Field(description="GST compliance details")
    gst_transaction_analysis: GSTTransactionAnalysis = Field(description="Transaction analysis")
    
    # Additional analysis
    supplier_analysis: Optional[Dict[str, Any]] = Field(default=None, description="Supplier analysis")
    customer_analysis: Optional[Dict[str, Any]] = Field(default=None, description="Customer analysis")
    seasonal_patterns: Optional[Dict[str, Any]] = Field(default=None, description="Seasonal patterns")


class PolicyComplianceCheck(BaseModel):
    """Individual policy compliance check."""
    
    check_name: str = Field(description="Name of the compliance check")
    required: str = Field(description="Required value/condition")
    achieved: Any = Field(description="Achieved value")
    status: str = Field(description="Check status (pass/fail/requires_additional_data)")
    details: Optional[Dict[str, Any]] = Field(default=None, description="Additional details")


class PolicyComplianceAssessment(BaseModel):
    """Overall policy compliance assessment."""
    
    bureau_score_compliance: Dict[str, PolicyComplianceCheck] = Field(
        description="Bureau score compliance checks"
    )
    coverage_compliance: Dict[str, PolicyComplianceCheck] = Field(
        description="Coverage compliance checks"
    )
    documentation_compliance: Dict[str, PolicyComplianceCheck] = Field(
        description="Documentation compliance checks"
    )
    gst_compliance_check: Dict[str, str] = Field(
        description="GST compliance check results"
    )
    
    def get_overall_status(self) -> str:
        """Get overall compliance status."""
        all_checks = []
        all_checks.extend(self.bureau_score_compliance.values())
        all_checks.extend(self.coverage_compliance.values())
        all_checks.extend(self.documentation_compliance.values())
        
        if all(check.status == "pass" for check in all_checks):
            return "pass"
        elif any(check.status == "fail" for check in all_checks):
            return "fail"
        else:
            return "requires_additional_data"


class RiskFactor(BaseModel):
    """Individual risk factor."""
    
    factor: str = Field(description="Risk factor description")
    impact: str = Field(description="Impact (positive/negative/neutral)")
    weight: float = Field(description="Weight in overall risk calculation")
    score: Optional[float] = Field(default=None, description="Individual factor score")


class RiskAssessment(BaseModel):
    """Comprehensive risk assessment."""
    
    overall_risk_score: float = Field(description="Overall risk score (0.0 to 1.0)")
    risk_category: str = Field(description="Risk category (low/medium/high)")
    risk_grade: str = Field(description="Risk grade (A1, A2, B1, etc.)")
    
    contributing_factors: List[RiskFactor] = Field(description="Contributing risk factors")
    mitigating_factors: List[str] = Field(default_factory=list, description="Mitigating factors")
    risk_mitigation_required: bool = Field(description="Whether risk mitigation is required")
    
    # Detailed risk breakdown
    credit_risk_score: Optional[float] = Field(default=None, description="Credit risk component")
    operational_risk_score: Optional[float] = Field(default=None, description="Operational risk component")
    compliance_risk_score: Optional[float] = Field(default=None, description="Compliance risk component")
    
    def add_risk_factor(self, factor: str, impact: str, weight: float, score: Optional[float] = None) -> None:
        """Add a risk factor."""
        risk_factor = RiskFactor(factor=factor, impact=impact, weight=weight, score=score)
        self.contributing_factors.append(risk_factor)
    
    @property
    def is_low_risk(self) -> bool:
        """Check if this is low risk."""
        return self.risk_category.lower() == "low"
    
    @property
    def is_high_risk(self) -> bool:
        """Check if this is high risk."""
        return self.risk_category.lower() == "high"


class EligibilityDetermination(BaseModel):
    """Final eligibility determination."""
    
    overall_eligibility: str = Field(description="Overall eligibility (approved/conditionally_approved/rejected)")
    approval_confidence: float = Field(description="Confidence in approval decision")
    
    conditions: List[str] = Field(default_factory=list, description="Conditions for approval")
    recommendations: List[str] = Field(default_factory=list, description="Recommendations")
    
    # Decision factors
    key_decision_factors: List[str] = Field(default_factory=list, description="Key factors in decision")
    blocking_factors: List[str] = Field(default_factory=list, description="Factors blocking approval")
    
    @property
    def is_approved(self) -> bool:
        """Check if application is approved."""
        return self.overall_eligibility in ["approved", "conditionally_approved"]
    
    @property
    def is_rejected(self) -> bool:
        """Check if application is rejected."""
        return self.overall_eligibility == "rejected"
    
    @property
    def has_conditions(self) -> bool:
        """Check if approval has conditions."""
        return len(self.conditions) > 0


class BureauVerificationResults(BaseModel):
    """Complete bureau verification results."""
    
    entity_commercial_bureau: EntityCommercialBureau = Field(description="Entity commercial bureau results")
    kmp_consumer_bureaus: List[KMPConsumerBureau] = Field(description="KMP consumer bureau results")
    partnership_cibil_compliance: Optional[PartnershipCibilCompliance] = Field(
        default=None, 
        description="Partnership CIBIL compliance (if applicable)"
    )
    
    # Summary statistics
    total_kmps_checked: int = Field(description="Total KMPs checked")
    kmps_meeting_threshold: int = Field(description="KMPs meeting CIBIL threshold")
    average_kmp_score: Optional[float] = Field(default=None, description="Average KMP CIBIL score")
    
    def get_kmp_bureau_by_id(self, kmp_id: str) -> Optional[KMPConsumerBureau]:
        """Get KMP bureau result by ID."""
        for bureau in self.kmp_consumer_bureaus:
            if bureau.kmp_id == kmp_id:
                return bureau
        return None
    
    def calculate_summary_stats(self) -> None:
        """Calculate summary statistics."""
        self.total_kmps_checked = len(self.kmp_consumer_bureaus)
        self.kmps_meeting_threshold = sum(
            1 for bureau in self.kmp_consumer_bureaus 
            if bureau.meets_cibil_threshold
        )
        
        valid_scores = [
            bureau.cibil_score for bureau in self.kmp_consumer_bureaus 
            if bureau.cibil_score is not None
        ]
        if valid_scores:
            self.average_kmp_score = sum(valid_scores) / len(valid_scores)
</file>

<file path="msme_underwriting/services/__init__.py">
"""Services for MSME underwriting system."""

from .document_processing import DocumentProcessingService
from .external_apis import (
    FileStorageService,
    PANValidationService,
    MCAService,
    CIBILService,
    GSTService,
    BureauService,
)

__all__ = [
    "DocumentProcessingService",
    "FileStorageService", 
    "PANValidationService",
    "MCAService",
    "CIBILService",
    "GSTService",
    "BureauService",
]
</file>

<file path="msme_underwriting/services/document_processing.py">
"""Document processing service integration."""

import asyncio
import httpx
from typing import Dict, Any, Optional
import logging

from ..models.base import APIResponse
from ..config import settings

logger = logging.getLogger(__name__)


class DocumentProcessingService:
    """
    Service for integrating with the existing PDF/Image Processing Service.
    
    This service handles communication with the external document processing
    API that extracts structured data from uploaded documents.
    """
    
    def __init__(self):
        """Initialize the document processing service."""
        self.base_url = settings.document_processing_service_url
        self.api_key = settings.document_processing_api_key
        self.timeout = 300  # 5 minutes timeout for document processing
        
    async def process_documents(self, request_payload: Dict[str, Any]) -> APIResponse:
        """
        Process documents using the external service.
        
        Args:
            request_payload: Request payload containing files and options
            
        Returns:
            API response with processed document data
        """
        try:
            logger.info(f"Processing {len(request_payload.get('files', []))} documents")
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}" if self.api_key else None
            }
            
            # Remove None values from headers
            headers = {k: v for k, v in headers.items() if v is not None}
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.base_url}/process-documents",
                    json=request_payload,
                    headers=headers
                )
                
                response_time = response.elapsed.total_seconds()
                
                if response.status_code == 200:
                    data = response.json()
                    logger.info(f"Document processing completed successfully in {response_time:.2f}s")
                    
                    return APIResponse(
                        success=True,
                        data=data,
                        status_code=response.status_code,
                        response_time=response_time
                    )
                else:
                    error_msg = f"Document processing failed with status {response.status_code}"
                    logger.error(error_msg)
                    
                    return APIResponse(
                        success=False,
                        error=error_msg,
                        status_code=response.status_code,
                        response_time=response_time
                    )
                    
        except httpx.TimeoutException:
            error_msg = "Document processing service timeout"
            logger.error(error_msg)
            return APIResponse(
                success=False,
                error=error_msg,
                status_code=408
            )
            
        except httpx.RequestError as e:
            error_msg = f"Document processing service request error: {str(e)}"
            logger.error(error_msg)
            return APIResponse(
                success=False,
                error=error_msg,
                status_code=500
            )
            
        except Exception as e:
            error_msg = f"Unexpected error in document processing: {str(e)}"
            logger.error(error_msg)
            return APIResponse(
                success=False,
                error=error_msg,
                status_code=500
            )
    
    async def get_processing_status(self, job_id: str) -> APIResponse:
        """
        Get the status of a document processing job.
        
        Args:
            job_id: Job ID to check status for
            
        Returns:
            API response with job status
        """
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}" if self.api_key else None
            }
            headers = {k: v for k, v in headers.items() if v is not None}
            
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(
                    f"{self.base_url}/job-status/{job_id}",
                    headers=headers
                )
                
                if response.status_code == 200:
                    data = response.json()
                    return APIResponse(
                        success=True,
                        data=data,
                        status_code=response.status_code
                    )
                else:
                    return APIResponse(
                        success=False,
                        error=f"Failed to get job status: {response.status_code}",
                        status_code=response.status_code
                    )
                    
        except Exception as e:
            return APIResponse(
                success=False,
                error=f"Error getting job status: {str(e)}",
                status_code=500
            )
    
    async def validate_document_format(self, file_path: str, file_type: str) -> bool:
        """
        Validate if a document format is supported.
        
        Args:
            file_path: Path to the file
            file_type: MIME type of the file
            
        Returns:
            True if format is supported, False otherwise
        """
        supported_types = [
            "application/pdf",
            "image/jpeg", 
            "image/jpg",
            "image/png",
            "application/zip"
        ]
        
        return file_type.lower() in supported_types
    
    async def estimate_processing_time(self, files: list) -> int:
        """
        Estimate processing time for a list of files.
        
        Args:
            files: List of files to process
            
        Returns:
            Estimated processing time in seconds
        """
        # Simple estimation based on file count and size
        base_time = 30  # Base processing time
        time_per_file = 15  # Additional time per file
        
        total_files = len(files)
        total_size = sum(file.get("file_size", 0) for file in files)
        
        # Add time based on total size (rough estimate)
        size_factor = total_size / (1024 * 1024)  # Size in MB
        size_time = size_factor * 2  # 2 seconds per MB
        
        estimated_time = base_time + (total_files * time_per_file) + size_time
        return int(estimated_time)
    
    def get_supported_formats(self) -> list[str]:
        """Get list of supported document formats."""
        return [
            "PDF documents (.pdf)",
            "JPEG images (.jpg, .jpeg)",
            "PNG images (.png)",
            "ZIP archives (.zip)"
        ]
    
    def get_processing_limits(self) -> Dict[str, Any]:
        """Get processing limits and constraints."""
        return {
            "max_file_size_mb": 50,
            "max_files_per_request": 20,
            "max_pages_per_document": 100,
            "supported_languages": ["en", "hi"],
            "timeout_seconds": self.timeout
        }
</file>

<file path="msme_underwriting/services/external_apis.py">
"""External API services for MSME underwriting."""

import asyncio
import httpx
from typing import Dict, Any, Optional, List
import logging
from datetime import datetime

from ..models.base import APIResponse
from ..config import settings

logger = logging.getLogger(__name__)


class BaseAPIService:
    """Base class for external API services."""
    
    def __init__(self, service_name: str, base_url: str, api_key: Optional[str] = None):
        """Initialize base API service."""
        self.service_name = service_name
        self.base_url = base_url
        self.api_key = api_key
        self.timeout = 30
        
    async def _make_request(self, method: str, endpoint: str, 
                          data: Optional[Dict[str, Any]] = None,
                          params: Optional[Dict[str, Any]] = None) -> APIResponse:
        """Make HTTP request to external API."""
        try:
            headers = {
                "Content-Type": "application/json",
                "User-Agent": "MSME-Underwriting/1.0"
            }
            
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"
            
            url = f"{self.base_url}/{endpoint.lstrip('/')}"
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                if method.upper() == "GET":
                    response = await client.get(url, headers=headers, params=params)
                elif method.upper() == "POST":
                    response = await client.post(url, headers=headers, json=data, params=params)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")
                
                response_time = response.elapsed.total_seconds()
                
                if response.status_code == 200:
                    try:
                        response_data = response.json()
                    except:
                        response_data = {"raw_response": response.text}
                    
                    return APIResponse(
                        success=True,
                        data=response_data,
                        status_code=response.status_code,
                        response_time=response_time
                    )
                else:
                    error_msg = f"{self.service_name} API error: {response.status_code}"
                    logger.error(f"{error_msg} - {response.text}")
                    
                    return APIResponse(
                        success=False,
                        error=error_msg,
                        status_code=response.status_code,
                        response_time=response_time
                    )
                    
        except httpx.TimeoutException:
            error_msg = f"{self.service_name} API timeout"
            logger.error(error_msg)
            return APIResponse(success=False, error=error_msg, status_code=408)
            
        except Exception as e:
            error_msg = f"{self.service_name} API error: {str(e)}"
            logger.error(error_msg)
            return APIResponse(success=False, error=error_msg, status_code=500)


class FileStorageService(BaseAPIService):
    """Service for file storage operations."""
    
    def __init__(self):
        """Initialize file storage service."""
        super().__init__("FileStorage", "http://localhost:8002")  # Example URL
    
    async def store_file(self, file_path: str, metadata: Dict[str, Any]) -> APIResponse:
        """Store a file with metadata."""
        data = {
            "file_path": file_path,
            "metadata": metadata,
            "timestamp": datetime.utcnow().isoformat()
        }
        return await self._make_request("POST", "/store", data=data)
    
    async def retrieve_file(self, file_id: str) -> APIResponse:
        """Retrieve a file by ID."""
        return await self._make_request("GET", f"/retrieve/{file_id}")
    
    async def delete_file(self, file_id: str) -> APIResponse:
        """Delete a file by ID."""
        return await self._make_request("DELETE", f"/delete/{file_id}")


class PANValidationService(BaseAPIService):
    """Service for PAN validation."""
    
    def __init__(self):
        """Initialize PAN validation service."""
        super().__init__("PAN", "https://api.pan-validation.com", settings.pan_api_key)
    
    async def validate_pan(self, pan_number: str) -> APIResponse:
        """
        Validate PAN number and get details.
        
        Args:
            pan_number: PAN number to validate
            
        Returns:
            API response with PAN validation results
        """
        data = {
            "pan_number": pan_number,
            "consent": "Y",
            "consent_text": "I hereby declare my consent agreement for fetching my information via AADHAR & PAN APIs"
        }
        
        response = await self._make_request("POST", "/validate", data=data)
        
        if response.success and response.data:
            # Standardize response format
            pan_data = response.data
            standardized_data = {
                "pan_number": pan_number,
                "is_valid": pan_data.get("valid", False),
                "name": pan_data.get("name"),
                "category": pan_data.get("category"),
                "status": pan_data.get("status"),
                "last_updated": pan_data.get("last_updated")
            }
            response.data = standardized_data
        
        return response
    
    async def bulk_validate_pans(self, pan_numbers: List[str]) -> APIResponse:
        """Validate multiple PAN numbers."""
        data = {
            "pan_numbers": pan_numbers,
            "consent": "Y"
        }
        return await self._make_request("POST", "/bulk-validate", data=data)


class MCAService(BaseAPIService):
    """Service for MCA (Ministry of Corporate Affairs) data."""
    
    def __init__(self):
        """Initialize MCA service."""
        super().__init__("MCA", "https://api.mca.gov.in", settings.mca_api_key)
    
    async def get_company_details(self, cin: str) -> APIResponse:
        """Get company details by CIN."""
        params = {"cin": cin}
        return await self._make_request("GET", "/company-details", params=params)
    
    async def get_director_details(self, din: str) -> APIResponse:
        """Get director details by DIN."""
        params = {"din": din}
        return await self._make_request("GET", "/director-details", params=params)
    
    async def search_company_by_name(self, company_name: str) -> APIResponse:
        """Search company by name."""
        params = {"name": company_name}
        return await self._make_request("GET", "/search-company", params=params)


class CIBILService(BaseAPIService):
    """Service for CIBIL credit bureau data."""
    
    def __init__(self):
        """Initialize CIBIL service."""
        super().__init__("CIBIL", "https://api.cibil.com", settings.cibil_api_key)
    
    async def get_consumer_report(self, pan_number: str, consent: bool = True) -> APIResponse:
        """
        Get consumer credit report.
        
        Args:
            pan_number: PAN number
            consent: User consent flag
            
        Returns:
            API response with credit report
        """
        data = {
            "pan_number": pan_number,
            "consent": consent,
            "report_type": "consumer",
            "purpose": "loan_underwriting"
        }
        
        response = await self._make_request("POST", "/consumer-report", data=data)
        
        if response.success and response.data:
            # Extract key information
            report_data = response.data
            standardized_data = {
                "pan_number": pan_number,
                "cibil_score": report_data.get("score"),
                "score_date": report_data.get("score_date"),
                "credit_history_months": report_data.get("credit_history_months"),
                "total_accounts": report_data.get("total_accounts"),
                "active_accounts": report_data.get("active_accounts"),
                "overdue_accounts": report_data.get("overdue_accounts"),
                "total_exposure": report_data.get("total_exposure"),
                "overdue_amount": report_data.get("overdue_amount"),
                "enquiries_last_30_days": report_data.get("enquiries_30d"),
                "account_details": report_data.get("accounts", []),
                "enquiry_details": report_data.get("enquiries", [])
            }
            response.data = standardized_data
        
        return response
    
    async def get_commercial_report(self, pan_number: str, consent: bool = True) -> APIResponse:
        """
        Get commercial credit report.
        
        Args:
            pan_number: Entity PAN number
            consent: User consent flag
            
        Returns:
            API response with commercial credit report
        """
        data = {
            "pan_number": pan_number,
            "consent": consent,
            "report_type": "commercial",
            "purpose": "loan_underwriting"
        }
        
        response = await self._make_request("POST", "/commercial-report", data=data)
        
        if response.success and response.data:
            # Extract key information
            report_data = response.data
            standardized_data = {
                "pan_number": pan_number,
                "cmr_score": report_data.get("cmr_score"),
                "commercial_score": report_data.get("commercial_score"),
                "score_date": report_data.get("score_date"),
                "credit_history_months": report_data.get("credit_history_months"),
                "total_exposure": report_data.get("total_exposure"),
                "overdue_amount": report_data.get("overdue_amount"),
                "account_summary": report_data.get("account_summary"),
                "payment_history": report_data.get("payment_history"),
                "enquiry_summary": report_data.get("enquiry_summary")
            }
            response.data = standardized_data
        
        return response


class GSTService(BaseAPIService):
    """Service for GST data and compliance."""
    
    def __init__(self):
        """Initialize GST service."""
        super().__init__("GST", "https://api.gst.gov.in", settings.gst_api_key)
    
    async def get_gst_details(self, gst_number: str) -> APIResponse:
        """Get GST registration details."""
        params = {"gstin": gst_number}
        return await self._make_request("GET", "/taxpayer", params=params)
    
    async def get_gst_returns(self, gst_number: str, period: str) -> APIResponse:
        """
        Get GST returns for a specific period.
        
        Args:
            gst_number: GST number
            period: Period in format MMYYYY
            
        Returns:
            API response with GST returns data
        """
        params = {
            "gstin": gst_number,
            "ret_period": period
        }
        return await self._make_request("GET", "/returns", params=params)
    
    async def get_filing_status(self, gst_number: str) -> APIResponse:
        """Get GST filing status and compliance."""
        params = {"gstin": gst_number}
        response = await self._make_request("GET", "/filing-status", params=params)
        
        if response.success and response.data:
            # Calculate compliance score
            filing_data = response.data
            total_returns = filing_data.get("total_returns_due", 0)
            filed_returns = filing_data.get("returns_filed", 0)
            
            compliance_score = (filed_returns / total_returns * 100) if total_returns > 0 else 0
            
            standardized_data = {
                "gst_number": gst_number,
                "registration_status": filing_data.get("status"),
                "compliance_score": compliance_score,
                "total_returns_due": total_returns,
                "returns_filed": filed_returns,
                "pending_returns": total_returns - filed_returns,
                "last_return_filed": filing_data.get("last_return_date"),
                "filing_frequency": filing_data.get("filing_frequency")
            }
            response.data = standardized_data
        
        return response
    
    async def analyze_turnover(self, gst_number: str, start_period: str, end_period: str) -> APIResponse:
        """
        Analyze GST turnover for a period range.
        
        Args:
            gst_number: GST number
            start_period: Start period (MMYYYY)
            end_period: End period (MMYYYY)
            
        Returns:
            API response with turnover analysis
        """
        data = {
            "gstin": gst_number,
            "start_period": start_period,
            "end_period": end_period
        }
        
        response = await self._make_request("POST", "/turnover-analysis", data=data)
        
        if response.success and response.data:
            # Calculate additional metrics
            turnover_data = response.data
            monthly_turnovers = turnover_data.get("monthly_turnover", [])
            
            if monthly_turnovers:
                total_turnover = sum(monthly_turnovers)
                average_monthly = total_turnover / len(monthly_turnovers)
                
                # Calculate growth rate
                if len(monthly_turnovers) >= 2:
                    first_half = sum(monthly_turnovers[:len(monthly_turnovers)//2])
                    second_half = sum(monthly_turnovers[len(monthly_turnovers)//2:])
                    growth_rate = ((second_half - first_half) / first_half * 100) if first_half > 0 else 0
                else:
                    growth_rate = 0
                
                standardized_data = {
                    "gst_number": gst_number,
                    "analysis_period": f"{start_period} to {end_period}",
                    "total_turnover": total_turnover,
                    "average_monthly_turnover": average_monthly,
                    "turnover_growth_rate": growth_rate,
                    "monthly_breakdown": monthly_turnovers,
                    "interstate_percentage": turnover_data.get("interstate_percentage"),
                    "major_states": turnover_data.get("major_states", [])
                }
                response.data = standardized_data
        
        return response


class BureauService:
    """Unified service for credit bureau operations."""
    
    def __init__(self):
        """Initialize bureau service."""
        self.cibil_service = CIBILService()
    
    async def get_consumer_bureau_report(self, pan_number: str) -> APIResponse:
        """Get consumer bureau report (CIBIL)."""
        return await self.cibil_service.get_consumer_report(pan_number)
    
    async def get_commercial_bureau_report(self, pan_number: str) -> APIResponse:
        """Get commercial bureau report (CIBIL)."""
        return await self.cibil_service.get_commercial_report(pan_number)
    
    async def get_multiple_consumer_reports(self, pan_numbers: List[str]) -> Dict[str, APIResponse]:
        """Get consumer reports for multiple PANs."""
        tasks = [
            self.cibil_service.get_consumer_report(pan) 
            for pan in pan_numbers
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return {
            pan: result if not isinstance(result, Exception) else APIResponse(
                success=False, 
                error=str(result)
            )
            for pan, result in zip(pan_numbers, results)
        }
    
    def calculate_partnership_cibil_compliance(self, bureau_results: Dict[str, APIResponse], 
                                             threshold: int = 680) -> Dict[str, Any]:
        """
        Calculate CIBIL compliance for partnership entities.
        
        Args:
            bureau_results: Dictionary of PAN -> APIResponse
            threshold: CIBIL score threshold
            
        Returns:
            Compliance analysis
        """
        total_partners = len(bureau_results)
        partners_with_scores = 0
        partners_above_threshold = 0
        scores = []
        
        for pan, response in bureau_results.items():
            if response.success and response.data:
                cibil_score = response.data.get("cibil_score")
                if cibil_score is not None:
                    partners_with_scores += 1
                    scores.append(cibil_score)
                    if cibil_score >= threshold:
                        partners_above_threshold += 1
        
        compliance_percentage = partners_above_threshold / total_partners if total_partners > 0 else 0
        meets_50_percent_rule = compliance_percentage >= 0.5
        
        return {
            "requirement": f"50%_partners_above_{threshold}",
            "total_partners": total_partners,
            "partners_with_scores": partners_with_scores,
            "partners_above_threshold": partners_above_threshold,
            "compliance_percentage": compliance_percentage,
            "meets_50_percent_rule": meets_50_percent_rule,
            "average_score": sum(scores) / len(scores) if scores else None,
            "compliance_status": "compliant" if meets_50_percent_rule else "non_compliant",
            "additional_kmps_needed": max(0, int(total_partners * 0.5) - partners_above_threshold)
        }
</file>

<file path="msme_underwriting/__init__.py">
"""
MSME Loan Processing Agent Architecture using LangGraph

This package implements a comprehensive multi-agent system for MSME loan underwriting
using LangGraph orchestration. The system processes loan applications through a series
of specialized agents that handle document classification, entity identification,
verification, financial analysis, and final report generation.

Architecture:
- Agent 1: Document Classification & Extraction
- Agent 2: Entity & KMP Identification  
- Agent 3: Verification & Compliance
- Agent 4: Financial Analysis
- Agent 7: Banking Analysis
- Agent 6: Final Assembly & Report Generation
- Agent 5: Relationship Mapping (Phase 2)

The system integrates with external APIs for PAN validation, bureau checks, GST analysis,
and document processing services.
"""

__version__ = "0.1.0"
__author__ = "Development Team"
__email__ = "dev@company.com"

from .config import settings
from .models import *
from .agents import *
from .services import *

__all__ = [
    "settings",
    # Models will be imported from models module
    # Agents will be imported from agents module  
    # Services will be imported from services module
]
</file>

<file path="msme_underwriting/orchestrator.py">
"""
LangGraph orchestrator for MSME loan underwriting workflow.

This module implements the main workflow orchestrator that coordinates
the execution of all agents in the MSME loan processing pipeline.
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, Optional, Literal

from langgraph.graph import StateGraph, START, END
from langgraph.types import Command
from langgraph.checkpoint.postgres import PostgresCheckpointer
from langchain_core.runnables import RunnableConfig

from .models.state import MSMELoanState, AgentContext, ProcessingMetadata, RoutingDecision
from .models.loan_application import LoanApplication
from .agents import (
    DocumentClassificationAgent,
    EntityKMPIdentificationAgent,
    VerificationComplianceAgent,
    FinancialAnalysisAgent,
    BankingAnalysisAgent,
    FinalAssemblyAgent,
)
from .config import settings

logger = logging.getLogger(__name__)


class MSMELoanOrchestrator:
    """
    Main orchestrator for MSME loan processing workflow.
    
    This class manages the execution flow of all agents and handles
    state transitions, error handling, and routing decisions.
    """
    
    def __init__(self, checkpointer: Optional[PostgresCheckpointer] = None):
        """Initialize the orchestrator."""
        self.checkpointer = checkpointer
        self.agents = self._initialize_agents()
        self.graph = self._build_graph()
        
    def _initialize_agents(self) -> Dict[str, Any]:
        """Initialize all agents."""
        return {
            "document_classification": DocumentClassificationAgent(),
            "entity_kmp_identification": EntityKMPIdentificationAgent(),
            "verification_compliance": VerificationComplianceAgent(),
            "financial_analysis": FinancialAnalysisAgent(),
            "banking_analysis": BankingAnalysisAgent(),
            "final_assembly": FinalAssemblyAgent(),
        }
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow."""
        # Create the state graph
        builder = StateGraph(MSMELoanState)
        
        # Add agent nodes
        builder.add_node("document_classification", self._document_classification_node)
        builder.add_node("entity_kmp_identification", self._entity_kmp_identification_node)
        builder.add_node("verification_compliance", self._verification_compliance_node)
        builder.add_node("financial_analysis", self._financial_analysis_node)
        builder.add_node("banking_analysis", self._banking_analysis_node)
        builder.add_node("final_assembly", self._final_assembly_node)
        
        # Add error handling node
        builder.add_node("error_handler", self._error_handler_node)
        
        # Add human review node
        builder.add_node("human_review", self._human_review_node)
        
        # Define the workflow edges
        builder.add_edge(START, "document_classification")
        
        # Conditional edges based on routing decisions
        builder.add_conditional_edges(
            "document_classification",
            self._route_from_document_classification,
            {
                "entity_kmp_identification": "entity_kmp_identification",
                "human_review": "human_review",
                "error_handler": "error_handler",
            }
        )
        
        builder.add_conditional_edges(
            "entity_kmp_identification",
            self._route_from_entity_kmp,
            {
                "verification_compliance": "verification_compliance",
                "human_review": "human_review",
                "error_handler": "error_handler",
            }
        )
        
        builder.add_conditional_edges(
            "verification_compliance",
            self._route_from_verification,
            {
                "financial_analysis": "financial_analysis",
                "human_review": "human_review",
                "error_handler": "error_handler",
            }
        )
        
        builder.add_conditional_edges(
            "financial_analysis",
            self._route_from_financial,
            {
                "banking_analysis": "banking_analysis",
                "human_review": "human_review",
                "error_handler": "error_handler",
            }
        )
        
        builder.add_conditional_edges(
            "banking_analysis",
            self._route_from_banking,
            {
                "final_assembly": "final_assembly",
                "human_review": "human_review",
                "error_handler": "error_handler",
            }
        )
        
        builder.add_edge("final_assembly", END)
        builder.add_edge("human_review", END)
        builder.add_edge("error_handler", END)
        
        # Compile the graph
        return builder.compile(checkpointer=self.checkpointer)
    
    async def _document_classification_node(self, state: MSMELoanState) -> Command[Literal["entity_kmp_identification", "human_review", "error_handler"]]:
        """Execute document classification agent."""
        try:
            logger.info(f"Starting document classification for thread {state.thread_id}")
            
            # Set agent context
            state.agent_context = AgentContext(
                trigger_reason="workflow_start",
                processing_timestamp=datetime.utcnow()
            )
            state.update_step("document_classification")
            
            # Execute agent
            agent = self.agents["document_classification"]
            result = await agent.process(state)
            
            # Update state with results
            state.classified_documents = result.classified_documents
            state.document_analysis = result.document_analysis
            state.missing_documents = result.missing_documents
            state.validation_warnings = result.validation_warnings
            
            # Add processing metadata
            metadata = ProcessingMetadata(
                start_time=state.agent_context.processing_timestamp,
                end_time=datetime.utcnow(),
                total_processing_time=(datetime.utcnow() - state.agent_context.processing_timestamp).total_seconds(),
                api_calls_made=result.processing_metadata.api_calls_made,
                total_api_cost=result.processing_metadata.total_api_cost
            )
            state.add_processing_metadata("document_classification", metadata)
            
            # Determine routing
            routing_decision = self._determine_document_classification_routing(result)
            state.add_routing_decision(routing_decision)
            
            return Command(goto=routing_decision.next_agent)
            
        except Exception as e:
            logger.error(f"Error in document classification: {str(e)}")
            state.add_error("document_classification", str(e))
            return Command(goto="error_handler")
    
    async def _entity_kmp_identification_node(self, state: MSMELoanState) -> Command[Literal["verification_compliance", "human_review", "error_handler"]]:
        """Execute entity and KMP identification agent."""
        try:
            logger.info(f"Starting entity KMP identification for thread {state.thread_id}")
            
            # Set agent context
            state.agent_context = AgentContext(
                previous_agent="document_classification",
                trigger_reason="documents_classified_successfully",
                processing_timestamp=datetime.utcnow()
            )
            state.update_step("entity_kmp_identification")
            
            # Execute agent
            agent = self.agents["entity_kmp_identification"]
            result = await agent.process(state)
            
            # Update state with results
            state.entity_profile = result.entity_profile
            state.kmp_analysis = result.kmp_analysis
            state.basic_group_identification = result.basic_group_identification
            state.cross_validation_results = result.cross_validation_results
            
            # Add processing metadata
            metadata = ProcessingMetadata(
                start_time=state.agent_context.processing_timestamp,
                end_time=datetime.utcnow(),
                total_processing_time=(datetime.utcnow() - state.agent_context.processing_timestamp).total_seconds(),
                api_calls_made=result.processing_metadata.api_calls_made,
                total_api_cost=result.processing_metadata.total_api_cost
            )
            state.add_processing_metadata("entity_kmp_identification", metadata)
            
            # Determine routing
            routing_decision = self._determine_entity_kmp_routing(result)
            state.add_routing_decision(routing_decision)
            
            return Command(goto=routing_decision.next_agent)
            
        except Exception as e:
            logger.error(f"Error in entity KMP identification: {str(e)}")
            state.add_error("entity_kmp_identification", str(e))
            return Command(goto="error_handler")
    
    async def _verification_compliance_node(self, state: MSMELoanState) -> Command[Literal["financial_analysis", "human_review", "error_handler"]]:
        """Execute verification and compliance agent."""
        try:
            logger.info(f"Starting verification compliance for thread {state.thread_id}")
            
            # Set agent context
            state.agent_context = AgentContext(
                previous_agent="entity_kmp_identification",
                trigger_reason="minimum_coverage_achieved",
                processing_timestamp=datetime.utcnow()
            )
            state.update_step("verification_compliance")
            
            # Execute agent
            agent = self.agents["verification_compliance"]
            result = await agent.process(state)
            
            # Update state with results
            state.bureau_verification_results = result.bureau_verification_results
            state.enhanced_gst_analysis = result.enhanced_gst_analysis
            state.pan_validation = result.pan_validation
            state.policy_compliance_assessment = result.policy_compliance_assessment
            state.risk_assessment = result.risk_assessment
            state.eligibility_determination = result.eligibility_determination
            
            # Add processing metadata
            metadata = ProcessingMetadata(
                start_time=state.agent_context.processing_timestamp,
                end_time=datetime.utcnow(),
                total_processing_time=(datetime.utcnow() - state.agent_context.processing_timestamp).total_seconds(),
                api_calls_made=result.processing_metadata.api_calls_made,
                total_api_cost=result.processing_metadata.total_api_cost
            )
            state.add_processing_metadata("verification_compliance", metadata)
            
            # Determine routing
            routing_decision = self._determine_verification_routing(result)
            state.add_routing_decision(routing_decision)
            
            return Command(goto=routing_decision.next_agent)
            
        except Exception as e:
            logger.error(f"Error in verification compliance: {str(e)}")
            state.add_error("verification_compliance", str(e))
            return Command(goto="error_handler")
    
    async def _financial_analysis_node(self, state: MSMELoanState) -> Command[Literal["banking_analysis", "human_review", "error_handler"]]:
        """Execute financial analysis agent."""
        try:
            logger.info(f"Starting financial analysis for thread {state.thread_id}")
            
            # Set agent context
            state.agent_context = AgentContext(
                previous_agent="verification_compliance",
                trigger_reason="comprehensive_analysis_required",
                processing_timestamp=datetime.utcnow()
            )
            state.update_step("financial_analysis")
            
            # Execute agent
            agent = self.agents["financial_analysis"]
            result = await agent.process(state)
            
            # Update state with results
            state.financial_health_assessment = result.financial_health_assessment
            state.banking_integration_analysis = result.banking_integration_analysis
            state.gst_financial_reconciliation = result.gst_financial_reconciliation
            state.loan_servicing_capacity = result.loan_servicing_capacity
            state.risk_assessment_enhancement = result.risk_assessment_enhancement
            
            # Add processing metadata
            metadata = ProcessingMetadata(
                start_time=state.agent_context.processing_timestamp,
                end_time=datetime.utcnow(),
                total_processing_time=(datetime.utcnow() - state.agent_context.processing_timestamp).total_seconds(),
                api_calls_made=result.processing_metadata.api_calls_made,
                total_api_cost=result.processing_metadata.total_api_cost
            )
            state.add_processing_metadata("financial_analysis", metadata)
            
            # Determine routing
            routing_decision = self._determine_financial_routing(result)
            state.add_routing_decision(routing_decision)
            
            return Command(goto=routing_decision.next_agent)
            
        except Exception as e:
            logger.error(f"Error in financial analysis: {str(e)}")
            state.add_error("financial_analysis", str(e))
            return Command(goto="error_handler")
    
    async def _banking_analysis_node(self, state: MSMELoanState) -> Command[Literal["final_assembly", "human_review", "error_handler"]]:
        """Execute banking analysis agent."""
        try:
            logger.info(f"Starting banking analysis for thread {state.thread_id}")
            
            # Set agent context
            state.agent_context = AgentContext(
                previous_agent="financial_analysis",
                trigger_reason="banking_validation_required",
                processing_timestamp=datetime.utcnow()
            )
            state.update_step("banking_analysis")
            
            # Execute agent
            agent = self.agents["banking_analysis"]
            result = await agent.process(state)
            
            # Update state with results
            state.banking_assessment = result.banking_assessment
            
            # Add processing metadata
            metadata = ProcessingMetadata(
                start_time=state.agent_context.processing_timestamp,
                end_time=datetime.utcnow(),
                total_processing_time=(datetime.utcnow() - state.agent_context.processing_timestamp).total_seconds(),
                api_calls_made=result.processing_metadata.api_calls_made,
                total_api_cost=result.processing_metadata.total_api_cost
            )
            state.add_processing_metadata("banking_analysis", metadata)
            
            # Determine routing
            routing_decision = self._determine_banking_routing(result)
            state.add_routing_decision(routing_decision)
            
            return Command(goto=routing_decision.next_agent)
            
        except Exception as e:
            logger.error(f"Error in banking analysis: {str(e)}")
            state.add_error("banking_analysis", str(e))
            return Command(goto="error_handler")
    
    async def _final_assembly_node(self, state: MSMELoanState) -> MSMELoanState:
        """Execute final assembly agent."""
        try:
            logger.info(f"Starting final assembly for thread {state.thread_id}")
            
            # Set agent context
            state.agent_context = AgentContext(
                previous_agent="banking_analysis",
                trigger_reason="all_analysis_completed",
                processing_timestamp=datetime.utcnow()
            )
            state.update_step("final_assembly")
            
            # Execute agent
            agent = self.agents["final_assembly"]
            result = await agent.process(state)
            
            # Update state with results
            state.final_report = result.final_report
            state.workflow_status = "completed"
            
            # Add processing metadata
            metadata = ProcessingMetadata(
                start_time=state.agent_context.processing_timestamp,
                end_time=datetime.utcnow(),
                total_processing_time=(datetime.utcnow() - state.agent_context.processing_timestamp).total_seconds(),
                api_calls_made=result.processing_metadata.api_calls_made,
                total_api_cost=result.processing_metadata.total_api_cost
            )
            state.add_processing_metadata("final_assembly", metadata)
            
            logger.info(f"Completed loan processing for thread {state.thread_id}")
            return state
            
        except Exception as e:
            logger.error(f"Error in final assembly: {str(e)}")
            state.add_error("final_assembly", str(e))
            state.workflow_status = "error"
            return state
    
    async def _error_handler_node(self, state: MSMELoanState) -> MSMELoanState:
        """Handle errors in the workflow."""
        logger.error(f"Error handler triggered for thread {state.thread_id}")
        state.workflow_status = "error"
        state.update_step("error_handling")
        return state
    
    async def _human_review_node(self, state: MSMELoanState) -> MSMELoanState:
        """Handle human review requirements."""
        logger.info(f"Human review required for thread {state.thread_id}")
        state.workflow_status = "human_review_required"
        state.update_step("human_review")
        return state
    
    # Routing decision methods
    def _route_from_document_classification(self, state: MSMELoanState) -> str:
        """Route from document classification based on results."""
        if state.has_errors:
            return "error_handler"
        
        # Check if we have sufficient documents
        if (state.classified_documents and 
            len(state.classified_documents.borrower_documents.get("pan_cards", [])) > 0):
            return "entity_kmp_identification"
        else:
            return "human_review"
    
    def _route_from_entity_kmp(self, state: MSMELoanState) -> str:
        """Route from entity KMP identification based on results."""
        if state.has_errors:
            return "error_handler"
        
        # Check if minimum KMP coverage is met
        if (state.kmp_analysis and 
            state.kmp_analysis.kmp_coverage_analysis.coverage_percentage >= 0.5):
            return "verification_compliance"
        else:
            return "human_review"
    
    def _route_from_verification(self, state: MSMELoanState) -> str:
        """Route from verification based on results."""
        if state.has_errors:
            return "error_handler"
        
        # Check eligibility determination
        if (state.eligibility_determination and 
            state.eligibility_determination.overall_eligibility != "rejected"):
            return "financial_analysis"
        else:
            return "human_review"
    
    def _route_from_financial(self, state: MSMELoanState) -> str:
        """Route from financial analysis based on results."""
        if state.has_errors:
            return "error_handler"
        
        # Check if we have banking documents for analysis
        if (state.classified_documents and 
            len(state.classified_documents.banking_documents) > 0):
            return "banking_analysis"
        else:
            return "human_review"
    
    def _route_from_banking(self, state: MSMELoanState) -> str:
        """Route from banking analysis based on results."""
        if state.has_errors:
            return "error_handler"
        
        # Always proceed to final assembly after banking analysis
        return "final_assembly"
    
    # Helper methods for routing decisions
    def _determine_document_classification_routing(self, result: Any) -> RoutingDecision:
        """Determine routing decision from document classification."""
        if result.routing_decision.next_agent == "entity_kmp_identification":
            return RoutingDecision(
                next_agent="entity_kmp_identification",
                routing_reason="Sufficient documents available for entity analysis",
                conditions_met=["borrower_pan_available", "documents_classified"]
            )
        else:
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="Insufficient documents for automated processing",
                conditions_met=[]
            )
    
    def _determine_entity_kmp_routing(self, result: Any) -> RoutingDecision:
        """Determine routing decision from entity KMP identification."""
        if result.routing_decision.next_agent == "verification_compliance":
            return RoutingDecision(
                next_agent="verification_compliance",
                routing_reason="Minimum KMP coverage achieved",
                conditions_met=["entity_identified", "minimum_coverage_achieved"]
            )
        else:
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="Insufficient KMP coverage",
                conditions_met=[]
            )
    
    def _determine_verification_routing(self, result: Any) -> RoutingDecision:
        """Determine routing decision from verification."""
        if result.routing_decision.next_agent == "financial_analysis":
            return RoutingDecision(
                next_agent="financial_analysis",
                routing_reason="Basic compliance checks passed",
                conditions_met=["bureau_scores_passed", "compliance_verified"]
            )
        else:
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="Compliance issues require manual review",
                conditions_met=[]
            )
    
    def _determine_financial_routing(self, result: Any) -> RoutingDecision:
        """Determine routing decision from financial analysis."""
        if result.routing_decision.next_agent == "banking_analysis":
            return RoutingDecision(
                next_agent="banking_analysis",
                routing_reason="Financial analysis complete, banking validation required",
                conditions_met=["financial_statements_analyzed", "servicing_capacity_calculated"]
            )
        else:
            return RoutingDecision(
                next_agent="human_review",
                routing_reason="Financial analysis requires manual review",
                conditions_met=[]
            )
    
    def _determine_banking_routing(self, result: Any) -> RoutingDecision:
        """Determine routing decision from banking analysis."""
        return RoutingDecision(
            next_agent="final_assembly",
            routing_reason="Banking analysis complete, ready for final assembly",
            conditions_met=["banking_analysis_completed"]
        )
    
    async def process_loan_application(self, loan_application: LoanApplication) -> MSMELoanState:
        """
        Process a loan application through the complete workflow.
        
        Args:
            loan_application: The loan application to process
            
        Returns:
            Final state after processing
        """
        # Initialize state
        initial_state = MSMELoanState(
            thread_id=loan_application.thread_id,
            loan_application=loan_application,
            messages=[],  # Required by MessagesState
            business_rules={
                "minimum_kmp_coverage": settings.minimum_kmp_coverage,
                "minimum_consumer_cibil": settings.minimum_consumer_cibil,
                "maximum_commercial_cmr": settings.maximum_commercial_cmr,
                "eligible_constitutions": settings.eligible_constitutions,
            }
        )
        
        # Configure the run
        config = RunnableConfig(
            configurable={
                "thread_id": loan_application.thread_id,
                "checkpoint_ns": "msme_loan_processing"
            }
        )
        
        # Execute the workflow
        try:
            final_state = await self.graph.ainvoke(initial_state, config=config)
            return final_state
        except Exception as e:
            logger.error(f"Error processing loan application {loan_application.thread_id}: {str(e)}")
            initial_state.add_error("orchestrator", str(e))
            initial_state.workflow_status = "error"
            return initial_state
    
    async def get_state(self, thread_id: str) -> Optional[MSMELoanState]:
        """Get the current state for a thread."""
        if not self.checkpointer:
            return None
        
        config = RunnableConfig(
            configurable={
                "thread_id": thread_id,
                "checkpoint_ns": "msme_loan_processing"
            }
        )
        
        try:
            state = await self.graph.aget_state(config)
            return state.values if state else None
        except Exception as e:
            logger.error(f"Error getting state for thread {thread_id}: {str(e)}")
            return None
    
    async def resume_processing(self, thread_id: str, user_input: Optional[Dict[str, Any]] = None) -> MSMELoanState:
        """Resume processing from a checkpoint."""
        config = RunnableConfig(
            configurable={
                "thread_id": thread_id,
                "checkpoint_ns": "msme_loan_processing"
            }
        )
        
        try:
            # If user input is provided, update the state
            if user_input:
                await self.graph.aupdate_state(config, user_input)
            
            # Resume processing
            final_state = await self.graph.ainvoke(None, config=config)
            return final_state
        except Exception as e:
            logger.error(f"Error resuming processing for thread {thread_id}: {str(e)}")
            # Return error state
            error_state = MSMELoanState(
                thread_id=thread_id,
                messages=[],
                workflow_status="error"
            )
            error_state.add_error("orchestrator", str(e))
            return error_state
</file>

<file path="env.example">
# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/msme_underwriting
REDIS_URL=redis://localhost:6379/0

# External API Keys
PAN_API_KEY=your_pan_api_key
MCA_API_KEY=your_mca_api_key
CIBIL_API_KEY=your_cibil_api_key
GST_API_KEY=your_gst_api_key

# PDF/Image Processing Service
DOCUMENT_PROCESSING_SERVICE_URL=http://localhost:8001
DOCUMENT_PROCESSING_API_KEY=your_document_service_api_key

# Application Configuration
ENVIRONMENT=development
LOG_LEVEL=INFO
MAX_CONCURRENT_AGENTS=5
AGENT_TIMEOUT_SECONDS=300

# File Storage
UPLOAD_DIR=./uploads
MAX_FILE_SIZE_MB=50

# Security
SECRET_KEY=your_secret_key_here
JWT_SECRET=your_jwt_secret_here

# Monitoring and Tracing
LANGSMITH_API_KEY=your_langsmith_api_key
LANGSMITH_PROJECT=msme-underwriting
LANGSMITH_TRACING=true
</file>

<file path="pyproject.toml">
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "msme-loan-underwriting"
version = "0.1.0"
description = "MSME Loan Processing Agent Architecture using LangGraph"
authors = [
    {name = "Development Team", email = "dev@company.com"}
]
readme = "README.md"
requires-python = ">=3.9"
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Financial Services",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]
dependencies = [
    "langgraph>=0.2.0",
    "langchain>=0.3.0",
    "langchain-openai>=0.2.0",
    "langchain-anthropic>=0.2.0",
    "langchain-community>=0.3.0",
    "pydantic>=2.0.0",
    "pydantic-settings>=2.0.0",
    "httpx>=0.25.0",
    "psycopg2-binary>=2.9.0",
    "sqlalchemy>=2.0.0",
    "pandas>=2.0.0",
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
    "python-dotenv>=1.0.0",
    "structlog>=23.0.0",
    "redis>=5.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-mock>=3.11.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "mypy>=1.5.0",
    "pre-commit>=3.4.0",
]

[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
known_first_party = ["msme_underwriting"]

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short"
asyncio_mode = "auto"
</file>

<file path="README.md">
# MSME Loan Processing Agent Architecture

A comprehensive multi-agent system for MSME (Micro, Small & Medium Enterprise) loan underwriting using LangGraph orchestration. This system processes loan applications through a series of specialized agents that handle document classification, entity identification, verification, financial analysis, and final report generation.

##  Architecture Overview

The system implements a 7-agent architecture orchestrated by LangGraph:

```

                        LangGraph Orchestrator                           
                                                                         
               
     Agent 1      Agent 2      Agent 3     Agent 4   
    Document          Entity        Verification      Financial  
   Classifier         & KMP            Agent          Analysis   
               
                                                                      
                             
     Agent 5          Agent 6         Agent 7       
  Relationship     Final             Banking                       
   Mapping         Assembly          Analysis                      
                              

```

##  Agent Responsibilities

### Agent 1: Document Classification & Extraction
- Validates loan type and file uploads
- Integrates with existing PDF/Image Processing Service
- Applies MSME-specific document classification
- Identifies financial documents (2 years audited + 1 year provisional)
- Maps documents to borrower vs KMPs
- Assesses data quality and identifies missing documents

### Agent 2: Entity & KMP Identification
- Determines entity constitution and eligibility
- Identifies Key Management Personnel (KMP)
- Validates entity structure through external APIs
- Performs basic group company identification
- Ensures minimum KMP coverage requirements

### Agent 3: Verification & Compliance
- Validates entity and KMP information through bureau checks
- Performs enhanced GST analysis and compliance verification
- Conducts policy rule engine validation
- Calculates comprehensive risk assessment
- Determines loan eligibility

### Agent 4: Financial Analysis
- Analyzes financial statements and ratios
- Performs cash flow and profitability analysis
- Calculates debt service capacity
- Reconciles GST turnover with financial statements
- Determines loan servicing capacity

### Agent 7: Banking Analysis
- Analyzes banking behavior and transaction patterns
- Verifies cash flow consistency
- Assesses account conduct and relationships
- Integrates banking data with financial analysis

### Agent 6: Final Assembly & Report Generation
- Consolidates all processed information
- Generates comprehensive loan application report
- Creates executive summary and recommendations
- Provides structured output for underwriter review

### Agent 5: Relationship Mapping (Phase 2)
- Identifies and analyzes group companies
- Maps corporate family tree
- Assesses consolidated group exposure and risk

##  Getting Started

### Prerequisites

- Python 3.9+
- PostgreSQL (for LangGraph checkpointing)
- Redis (for caching)
- Access to external APIs (PAN, CIBIL, GST, MCA)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd msme-loan-underwriting
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
cp env.example .env
# Edit .env with your configuration
```

5. Set up the database:
```bash
# Create PostgreSQL database
createdb msme_underwriting

# Run migrations (if using Alembic)
alembic upgrade head
```

### Configuration

Configure the following environment variables in your `.env` file:

```env
# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/msme_underwriting
REDIS_URL=redis://localhost:6379/0

# External API Keys
PAN_API_KEY=your_pan_api_key
MCA_API_KEY=your_mca_api_key
CIBIL_API_KEY=your_cibil_api_key
GST_API_KEY=your_gst_api_key

# Document Processing Service
DOCUMENT_PROCESSING_SERVICE_URL=http://localhost:8001
DOCUMENT_PROCESSING_API_KEY=your_document_service_api_key
```

##  Usage

### Basic Usage

```python
from msme_underwriting import MSMELoanOrchestrator
from msme_underwriting.models import LoanApplication, LoanContext, UploadedFile

# Initialize orchestrator
orchestrator = MSMELoanOrchestrator()

# Create loan application
loan_application = LoanApplication(
    thread_id="loan_USER001_20240925_143022",
    user_id="USER001",
    loan_context=LoanContext(
        loan_type="MSM_supply_chain",
        loan_amount=5000000,
        application_timestamp=datetime.utcnow()
    ),
    uploaded_files=[
        UploadedFile(
            file_name="documents.zip",
            file_path="/uploads/USER001/loan_001/documents.zip",
            file_size=15728640,
            upload_timestamp=datetime.utcnow(),
            file_type="application/zip"
        )
    ]
)

# Process the application
final_state = await orchestrator.process_loan_application(loan_application)

# Get the final report
if final_state.final_report:
    print(f"Recommendation: {final_state.final_report.loan_recommendation.primary_recommendation}")
    print(f"Risk Grade: {final_state.final_report.executive_summary.risk_grade}")
```

### Advanced Usage with Checkpointing

```python
from langgraph.checkpoint.postgres import PostgresCheckpointer

# Initialize with checkpointing for persistence
checkpointer = PostgresCheckpointer.from_conn_string(DATABASE_URL)
orchestrator = MSMELoanOrchestrator(checkpointer=checkpointer)

# Process with ability to resume
final_state = await orchestrator.process_loan_application(loan_application)

# Resume from checkpoint if needed
resumed_state = await orchestrator.resume_processing(
    thread_id="loan_USER001_20240925_143022",
    user_input={"additional_documents": [...]}
)
```

##  Project Structure

```
msme_underwriting/
 __init__.py
 orchestrator.py          # Main LangGraph orchestrator
 agents/                  # Individual agent implementations
    __init__.py
    base.py             # Base agent class
    document_classification.py
    entity_kmp_identification.py
    verification_compliance.py
    financial_analysis.py
    banking_analysis.py
    final_assembly.py
 models/                  # Pydantic data models
    __init__.py
    base.py
    state.py            # LangGraph state model
    loan_application.py
    documents.py
    entity.py
    kmp.py
    verification.py
    financial.py
    banking.py
    final_report.py
 services/               # External service integrations
    __init__.py
    document_processing.py
    external_apis.py
 config/                 # Configuration management
    __init__.py
    settings.py
 utils/                  # Utility functions
    __init__.py
 api/                    # FastAPI endpoints (optional)
     __init__.py
```

##  Business Rules & Configuration

The system implements configurable business rules:

- **Minimum KMP Coverage**: 50% (configurable)
- **Minimum Consumer CIBIL**: 680 (configurable)
- **Maximum Commercial CMR**: 8 (configurable)
- **Eligible Constitutions**: Sole Proprietorship, Partnership, LLP, Company, HUF
- **Document Confidence Thresholds**: Minimum 70%, High confidence 90%

##  External Integrations

The system integrates with various external services:

- **Document Processing Service**: Existing PDF/Image processing API
- **PAN Validation API**: Entity and individual PAN verification
- **MCA API**: Company and director information
- **CIBIL API**: Consumer and commercial credit reports
- **GST API**: Registration, compliance, and transaction analysis
- **Banking APIs**: Account verification and transaction analysis

##  Monitoring & Observability

The system includes comprehensive monitoring:

- **LangSmith Integration**: Trace all agent executions
- **Structured Logging**: Detailed logging with correlation IDs
- **Performance Metrics**: Processing time, API costs, success rates
- **Quality Metrics**: Document confidence, data completeness
- **Business Metrics**: Approval rates, processing efficiency

##  Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=msme_underwriting

# Run specific test categories
pytest tests/unit/
pytest tests/integration/
```

##  Implementation Roadmap

### Phase 1: MVP (Agents 1, 2, 3, 4, 7, 6) - 10-12 Weeks
-  Foundation setup and data models
-  LangGraph orchestrator implementation
-  Agent 1: Document Classification (In Progress)
-  Agent 2: Entity & KMP Identification
-  Agent 3: Verification & Compliance
-  Agent 4: Financial Analysis
-  Agent 7: Banking Analysis
-  Agent 6: Final Assembly

### Phase 2: Enhanced Processing (Agent 5) - 4-6 Weeks
-  Agent 5: Relationship Mapping
-  Group company analysis
-  Corporate family tree mapping

### Phase 3: Production Hardening - 4-6 Weeks
-  Performance optimization
-  Security hardening
-  Monitoring and alerting
-  Load testing and scalability

##  Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

##  License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

##  Support

For support and questions:

- Create an issue in the GitHub repository
- Contact the development team at dev@company.com
- Check the documentation in the `docs/` directory

##  Acknowledgments

- LangGraph team for the excellent orchestration framework
- LangChain community for the foundational tools
- All contributors and maintainers of the project
</file>

<file path="requirements.txt">
# Core LangGraph and LangChain dependencies
langgraph>=0.2.0
langchain>=0.3.0
langchain-openai>=0.2.0
langchain-anthropic>=0.2.0
langchain-community>=0.3.0

# Data processing and validation
pydantic>=2.0.0
pydantic-settings>=2.0.0
typing-extensions>=4.0.0

# HTTP and API clients
httpx>=0.25.0
requests>=2.31.0
aiohttp>=3.9.0

# Database and persistence
psycopg2-binary>=2.9.0
sqlalchemy>=2.0.0
alembic>=1.12.0

# Data processing
pandas>=2.0.0
numpy>=1.24.0
python-dateutil>=2.8.0

# File processing
PyPDF2>=3.0.0
python-multipart>=0.0.6
Pillow>=10.0.0

# Async and concurrency
asyncio-mqtt>=0.13.0
asyncpg>=0.29.0

# Logging and monitoring
structlog>=23.0.0
python-json-logger>=2.0.0

# Environment and configuration
python-dotenv>=1.0.0
pyyaml>=6.0.0

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-mock>=3.11.0

# Development tools
black>=23.0.0
isort>=5.12.0
mypy>=1.5.0
pre-commit>=3.4.0

# FastAPI for API endpoints
fastapi>=0.104.0
uvicorn>=0.24.0

# Redis for caching
redis>=5.0.0
</file>

<file path="specs.md">
# Complete MSME Loan Processing Agent Architecture: Implementation Specifications (UPDATED)

## **System Architecture Overview**

```

                        LangGraph Orchestrator                           
                                                                         
               
     Agent 1          Agent 2          Agent 3         Agent 4   
    Document      Entity    Verification  Financial  
   Classifier         & KMP            Agent          Analysis   
               
                                                                      
                             
     Agent 5          Agent 6         Agent 7                     
  Relationship     Final             Banking        
   Mapping         Assembly          Analysis                      
                              

                                                               
                                                               

           PDF/Image Processing Service (Existing FastAPI)              
                     POST /process-documents                             

                                                               
                                                               

                     External APIs Layer                                
            
   PAN/MCA        Bureau APIs    GST/Banking    Financial       
   APIs           (CIBIL)        APIs           APIs            
            

```

---

## **Agent 1: Document Classification & Extraction Agent**

### **Purpose**
Transform user-uploaded files into classified, structured data using the existing PDF/Image Processing Service and prepare data for entity analysis.

### **Call Condition**
- **Triggered by**: New loan application initiation
- **Prerequisites**: User file upload completed
- **State Check**: `current_step == "start"` or `current_step == "document_reupload"`

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "user_id": "USER001",
  "loan_context": {
    "loan_type": "MSM_supply_chain",
    "loan_amount": 5000000,
    "application_timestamp": "2024-09-25T14:30:22Z"
  },
  "uploaded_files": [
    {
      "file_name": "documents.zip",
      "file_path": "/uploads/USER001/loan_001/documents.zip",
      "file_size": 15728640,
      "upload_timestamp": "2024-09-25T14:30:22Z",
      "file_type": "application/zip"
    }
  ],
  "processing_options": {
    "max_pages_per_document": 50,
    "include_raw_responses": false,
    "vision_model": "gpt-4o"
  }
}
```

### **Processing Logic**
1. **Loan Type Validation**: Validate loan type matches MSM Supply Chain Finance requirements
2. **File Validation**: Check file types, sizes, formats against business rules
3. **Document Service Integration**: Call existing `/process-documents` endpoint
4. **Response Parsing**: Extract and normalize structured data from API response
5. **MSME Document Classification**: Apply business-specific document categorization
6. **Financial Document Identification**: Identify 2 years audited + 1 year provisional financials
7. **Banking Document Detection**: Identify bank statements for all declared accounts
8. **Entity-Document Mapping**: Identify which documents belong to borrower vs KMPs
9. **Missing Document Analysis**: Compare available documents against MSME requirements
10. **Data Quality Assessment**: Evaluate confidence scores and flag low-quality extractions

### **External Service Calls**
- **PDF/Image Processing Service**: `POST /process-documents` with uploaded files
- **File Storage Service**: Document storage and retrieval

### **Expected Output**
```json
{
  "agent_name": "document_classification",
  "processing_status": "completed",
  "thread_id": "loan_USER001_20240925_143022",
  "processing_metadata": {
    "start_time": "2024-09-25T14:30:25Z",
    "end_time": "2024-09-25T14:32:58Z",
    "total_processing_time": 153.2,
    "api_calls_made": 12,
    "total_api_cost": 0.34
  },
  "loan_type_validation": {
    "requested_loan_type": "MSM_supply_chain",
    "is_eligible": true,
    "validation_checks": [
      {"check": "msm_loan_type", "status": "passed"},
      {"check": "supply_chain_finance", "status": "passed"}
    ]
  },
  "classified_documents": {
    "borrower_documents": {
      "pan_cards": [
        {
          "file_name": "entity_pan.pdf",
          "document_class": "PAN_FIRM",
          "extracted_data": {
            "pan_number": "ABCDE1234F",
            "entity_name": "ABC Enterprises",
            "constitution_indicator": "D",
            "address": "123 Business Street, Mumbai",
            "confidence_score": 0.95
          },
          "quality_flags": ["high_confidence", "clear_image"]
        }
      ],
      "gst_certificates": [
        {
          "file_name": "gst_cert.pdf", 
          "document_class": "GST_CERTIFICATE",
          "extracted_data": {
            "gst_number": "09ABCDE1234F1Z5",
            "business_name": "ABC Enterprises",
            "registration_date": "2019-04-15",
            "address": "123 Business Street, Mumbai",
            "status": "Active",
            "confidence_score": 0.89
          }
        }
      ]
    },
    "kmp_documents": {
      "pan_cards": [
        {
          "file_name": "partner1_pan.pdf",
          "document_class": "PAN_INDIVIDUAL", 
          "extracted_data": {
            "pan_number": "XYZPQ5678R",
            "name": "John Doe",
            "father_name": "Robert Doe",
            "date_of_birth": "1985-03-15",
            "confidence_score": 0.92
          }
        }
      ],
      "aadhaar_cards": [
        {
          "file_name": "partner1_aadhaar.pdf",
          "document_class": "AADHAAR_INDIVIDUAL",
          "extracted_data": {
            "aadhaar_number": "1234-5678-9012", 
            "name": "John Doe",
            "address": "456 Residential Area, Mumbai",
            "phone": "9876543210",
            "confidence_score": 0.88
          }
        }
      ]
    },
    "business_documents": {
      "partnership_deeds": [
        {
          "file_name": "partnership_deed.pdf",
          "document_class": "PARTNERSHIP_DEED",
          "extracted_data": {
            "firm_name": "ABC Enterprises",
            "registration_date": "2019-02-20",
            "partners": [
              {"name": "John Doe", "share": "30%"},
              {"name": "Jane Smith", "share": "35%"},
              {"name": "Mike Johnson", "share": "20%"},
              {"name": "Sarah Wilson", "share": "15%"}
            ],
            "confidence_score": 0.87
          }
        }
      ]
    },
    "financial_documents": {
      "audited_financials_2yr": [
        {
          "file_name": "financials_2023.pdf",
          "document_class": "AUDITED_FINANCIAL_STATEMENT",
          "fiscal_year": 2023,
          "extracted_data": {
            "balance_sheet": {"status": "extracted", "confidence": 0.85},
            "profit_loss": {"status": "extracted", "confidence": 0.83},
            "cash_flow": {"status": "extracted", "confidence": 0.82}
          }
        },
        {
          "file_name": "financials_2022.pdf",
          "document_class": "AUDITED_FINANCIAL_STATEMENT", 
          "fiscal_year": 2022,
          "extracted_data": {
            "balance_sheet": {"status": "extracted", "confidence": 0.86},
            "profit_loss": {"status": "extracted", "confidence": 0.84},
            "cash_flow": {"status": "extracted", "confidence": 0.81}
          }
        }
      ],
      "provisional_financials_1yr": [
        {
          "file_name": "financials_2024_provisional.pdf",
          "document_class": "PROVISIONAL_FINANCIAL_STATEMENT",
          "fiscal_year": 2024,
          "extracted_data": {
            "balance_sheet": {"status": "extracted", "confidence": 0.78},
            "profit_loss": {"status": "extracted", "confidence": 0.76}
          }
        }
      ],
      "itr_documents": [
        {
          "file_name": "itr_2023.pdf",
          "document_class": "INCOME_TAX_RETURN",
          "assessment_year": "2023-24",
          "extracted_data": {
            "itr_form": "ITR-3",
            "schedules_present": ["3AA", "3CA"],
            "income_computation": {"status": "extracted", "confidence": 0.88}
          }
        }
      ]
    },
    "banking_documents": {
      "bank_statements": [
        {
          "file_name": "bank_statement_hdfc.pdf",
          "document_class": "BANK_STATEMENT",
          "bank_name": "HDFC Bank",
          "account_type": "Current Account",
          "period": "2023-04-01 to 2024-03-31",
          "extracted_data": {
            "transaction_count": 2456,
            "average_balance": 1250000,
            "confidence_score": 0.91
          }
        }
      ]
    },
    "gst_documents": {
      "gst_returns": [
        {
          "file_name": "gst_returns_2023.zip",
          "document_class": "GST_RETURNS",
          "period": "2023-2024",
          "extracted_data": {
            "return_forms": ["GSTR-1", "GSTR-3B"],
            "filing_frequency": "Monthly",
            "confidence_score": 0.89
          }
        }
      ]
    }
  },
  "document_analysis": {
    "total_documents_processed": 15,
    "total_pages_processed": 87,
    "classification_success_rate": 0.93,
    "average_confidence_score": 0.91,
    "financial_documents_coverage": {
      "audited_financials_required": 2,
      "audited_financials_available": 2,
      "provisional_financials_required": 1,
      "provisional_financials_available": 1,
      "itr_documents_required": 3,
      "itr_documents_available": 1
    }
  },
  "missing_documents": [
    {
      "document_type": "aadhaar_card",
      "missing_for": "Jane Smith (Partner)",
      "mandatory": true,
      "reason": "Required for KMP KYC completion"
    },
    {
      "document_type": "udyam_registration",
      "missing_for": "ABC Enterprises",
      "mandatory": false, 
      "reason": "Helps establish MSM status"
    },
    {
      "document_type": "itr_documents",
      "missing_for": "2022-23, 2021-22 assessment years",
      "mandatory": true,
      "reason": "Required for 2-year financial analysis"
    }
  ],
  "validation_warnings": [
    {
      "type": "low_confidence",
      "document": "partner1_aadhaar.pdf", 
      "confidence": 0.88,
      "threshold": 0.90,
      "recommendation": "Manual review recommended"
    }
  ],
  "next_action": "proceed_to_entity_analysis",
  "routing_decision": {
    "next_agent": "entity_kmp_identification",
    "routing_reason": "Sufficient documents available for entity analysis",
    "bypass_conditions": []
  }
}
```

### **Routing Conditions**
- **Success Route**: If borrower PAN card available and confidence >0.8  Route to Agent 2
- **Missing Docs Route**: If critical documents missing  Route to Human Interface
- **Quality Issues Route**: If average confidence <0.7  Route to Human Review
- **Error Route**: If API failures or processing errors  Route to Error Handler

---

## **Agent 2: Entity & KMP Identification Agent (ENHANCED)**

### **Purpose**
Determine entity constitution, identify required Key Management Personnel, collect their KYC information, validate entity structure, and perform basic group company identification.

### **Call Condition**
- **Triggered by**: Agent 1 completion with sufficient document classification
- **Prerequisites**: Borrower PAN card available, basic entity documents identified
- **State Check**: `current_step == "entity_analysis"` and `classified_documents.borrower_documents.pan_cards` exists

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "agent_context": {
    "previous_agent": "document_classification",
    "trigger_reason": "documents_classified_successfully", 
    "processing_timestamp": "2024-09-25T14:32:58Z"
  },
  "classified_documents": {
    "borrower_documents": {...},
    "kmp_documents": {...},
    "business_documents": {...},
    "financial_documents": {...},
    "banking_documents": {...},
    "gst_documents": {...}
  },
  "loan_context": {
    "loan_type": "MSM_supply_chain",
    "loan_amount": 5000000
  },
  "business_rules": {
    "minimum_kmp_coverage": 0.5,
    "required_documents_by_constitution": {
      "partnership": ["partnership_deed", "pan_cards", "aadhaar_cards"],
      "company": ["moa_aoa", "pan_cards", "aadhaar_cards"],
      "sole_proprietorship": ["pan_card", "aadhaar_card"]
    },
    "eligible_constitutions": ["sole_proprietorship", "partnership", "llp", "company", "huf"]
  }
}
```

### **Processing Logic**
1. **Primary Entity Identification**: Extract and validate borrowing entity details
2. **Constitution Eligibility Verification**: Validate against 5 eligible constitution types
3. **KMP Requirements Definition**: Define required personnel based on constitution
4. **Document-KMP Matching**: Match available documents to identified individuals
5. **Basic Group Company Identification**: Analyze ITR income sources for group entities
6. **API Validation**: Verify PAN numbers and fetch additional entity data
7. **Coverage Analysis**: Calculate KMP coverage percentage
8. **Cross-Document Validation**: Ensure consistency across documents
9. **Missing KYC Identification**: Identify gaps in required documentation
10. **Establishment Date Determination**: Use document hierarchy for date validation

### **External API Calls**
- **PAN Validation API**: Verify all PAN numbers and extract verified names
- **MCA API**: For companies/LLPs, fetch director/partner details and shareholding
- **Name Matching Service**: Cross-reference names across multiple documents
- **Address Validation API**: Standardize and validate addresses

### **Expected Output**
```json
{
  "agent_name": "entity_kmp_identification",
  "processing_status": "completed",
  "thread_id": "loan_USER001_20240925_143022",
  "processing_metadata": {
    "start_time": "2024-09-25T14:32:59Z",
    "end_time": "2024-09-25T14:35:42Z",
    "total_processing_time": 163.1,
    "api_calls_made": 8,
    "total_api_cost": 0.12
  },
  "entity_profile": {
    "borrowing_entity": {
      "pan_number": "ABCDE1234F",
      "entity_name": "ABC Enterprises",
      "constitution": "partnership",
      "constitution_source": "pan_4th_letter_D",
      "constitution_eligibility": {
        "eligible_types": ["sole_proprietorship", "partnership", "llp", "company", "huf"],
        "detected_type": "partnership",
        "is_eligible": true,
        "validation_checks": [
          {"check": "pan_4th_character", "status": "passed", "value": "D"},
          {"check": "eligible_constitution", "status": "passed"}
        ]
      },
      "api_verified": true,
      "verified_name": "ABC ENTERPRISES",
      "gst_number": "09ABCDE1234F1Z5",
      "udyam_number": null,
      "date_of_establishment": {
        "determined_date": "2019-02-20",
        "source_document": "partnership_deed",
        "hierarchy_used": ["partnership_deed", "pan_card", "gst_certificate"],
        "confidence": 0.95
      },
      "registered_address": {
        "line1": "123 Business Street",
        "line2": "",
        "city": "Mumbai",
        "state": "Maharashtra",
        "pincode": "400001",
        "standardized": true
      },
      "business_activity": "Trading and Services",
      "entity_validation_score": 0.94
    }
  },
  "kmp_analysis": {
    "constitution_requirements": {
      "entity_type": "partnership",
      "minimum_partners_required": 2,
      "maximum_partners_allowed": 20,
      "minimum_coverage_required": 0.5
    },
    "identified_kmps": [
      {
        "kmp_id": "KMP001",
        "name": "John Doe",
        "role": "partner",
        "pan_number": "XYZPQ5678R", 
        "aadhaar_number": "1234-5678-9012",
        "shareholding_percentage": 30,
        "documents_available": ["pan", "aadhaar"],
        "api_verified": true,
        "verified_name": "JOHN DOE",
        "address": {
          "line1": "456 Residential Area",
          "city": "Mumbai", 
          "state": "Maharashtra",
          "pincode": "400002"
        },
        "phone_number": "9876543210",
        "kyc_completeness": "complete",
        "risk_flags": []
      },
      {
        "kmp_id": "KMP002",
        "name": "Jane Smith",
        "role": "partner", 
        "shareholding_percentage": 35,
        "documents_available": ["identified_in_deed"],
        "api_verified": false,
        "kyc_completeness": "incomplete",
        "missing_documents": ["pan_card", "aadhaar_card"]
      }
    ],
    "kmp_coverage_analysis": {
      "total_partners_identified": 4,
      "partners_with_complete_kyc": 1,
      "partners_with_partial_kyc": 1,
      "total_shareholding_covered": 65,
      "minimum_coverage_met": true,
      "coverage_percentage": 0.65
    }
  },
  "basic_group_identification": {
    "analysis_performed": true,
    "data_sources_used": ["itr_documents", "partnership_deed"],
    "identified_related_entities": [
      {
        "entity_name": "XYZ Trading Co.",
        "relation_type": "kmp_affiliation",
        "related_kmp": "John Doe",
        "kmp_role": "proprietor",
        "source_document": "itr_2023.pdf",
        "income_source": "business_income",
        "confidence_level": "medium"
      }
    ],
    "group_mapping_required": true,
    "additional_documents_needed": ["xyz_trading_pan", "xyz_trading_gst"]
  },
  "cross_validation_results": {
    "entity_name_consistency": "passed",
    "address_consistency": "passed_with_variations",
    "pan_cross_reference": "passed",
    "partnership_deed_alignment": "passed",
    "discrepancies": [
      {
        "type": "address_variation",
        "details": "Entity address varies slightly between PAN and GST certificate",
        "severity": "low"
      }
    ]
  },
  "missing_requirements": [
    {
      "requirement_type": "kmp_kyc",
      "missing_for": "Jane Smith",
      "required_documents": ["pan_card", "aadhaar_card"],
      "shareholding_impact": 35,
      "mandatory": true,
      "business_justification": "Required for >50% partner coverage"
    },
    {
      "requirement_type": "kmp_kyc", 
      "missing_for": "Mike Johnson",
      "required_documents": ["pan_card", "aadhaar_card"],
      "shareholding_impact": 20,
      "mandatory": false,
      "business_justification": "Optional - coverage already >50%"
    }
  ],
  "next_action": "proceed_to_verification",
  "routing_decision": {
    "next_agent": "verification_compliance",
    "routing_reason": "Minimum KMP coverage achieved, entity profile complete",
    "conditions_met": [
      "entity_identified",
      "minimum_coverage_achieved", 
      "primary_kmp_validated",
      "constitution_eligible"
    ]
  }
}
```

### **Routing Conditions**
- **Success Route**: If minimum KMP coverage (50%) met and constitution eligible  Route to Agent 3
- **Insufficient Coverage Route**: If <50% KMP coverage  Route to Human Interface for document collection
- **API Validation Failure Route**: If critical API validations fail  Route to Manual Review
- **Constitution Issues Route**: If ineligible constitution type  Route to Rejection Handler

---

## **Agent 3: Verification & Compliance Agent (ENHANCED)**

### **Purpose**
Validate entity and KMP information through bureau checks, ensure regulatory compliance, perform enhanced GST analysis, and assess overall loan eligibility.

### **Call Condition**
- **Triggered by**: Agent 2 completion with minimum KMP coverage
- **Prerequisites**: Entity profile complete, minimum 50% KMP coverage achieved
- **State Check**: `current_step == "verification"` and `kmp_analysis.coverage_percentage >= 0.5`

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "agent_context": {
    "previous_agent": "entity_kmp_identification",
    "trigger_reason": "minimum_coverage_achieved",
    "processing_timestamp": "2024-09-25T14:35:42Z"
  },
  "entity_profile": {...},
  "kmp_analysis": {...},
  "classified_documents": {
    "gst_documents": {...},
    "financial_documents": {...}
  },
  "compliance_requirements": {
    "bureau_score_thresholds": {
      "minimum_consumer_cibil": 680,
      "maximum_commercial_cmr": 8,
      "minimum_commercial_score": 1,
      "partnership_cibil_requirements": "50%_partners_above_680"
    },
    "mandatory_checks": [
      "entity_commercial_bureau",
      "kmp_consumer_bureau", 
      "gst_compliance_check",
      "pan_validation_check",
      "gst_transaction_analysis"
    ],
    "risk_assessment_weights": {
      "bureau_scores": 0.4,
      "document_quality": 0.2,
      "kmp_coverage": 0.2,
      "compliance_status": 0.2
    },
    "gst_analysis_requirements": {
      "turnover_verification": true,
      "filing_regularity_check": true,
      "multi_state_analysis": true,
      "revenue_reconciliation": true
    }
  }
}
```

### **Processing Logic**
1. **Bureau Score Retrieval**: Fetch commercial and consumer bureau scores for all entities
2. **Partnership CIBIL Validation**: Ensure 50% of partners meet 680+ score requirement
3. **Enhanced GST Analysis**: Perform detailed GST return processing and turnover analysis
4. **Compliance Threshold Validation**: Check all scores against business policy thresholds
5. **GST Compliance Verification**: Validate GST registration status and filing compliance
6. **Revenue Reconciliation**: Cross-verify GST turnover with financial statements
7. **Cross-Reference Identity Verification**: Validate identity consistency across all sources
8. **Risk Score Calculation**: Compute weighted risk assessment based on all factors
9. **Policy Rule Engine**: Apply comprehensive business rules for eligibility determination
10. **Exception Handling**: Identify cases requiring manual underwriter review

### **External API Calls**
- **Consumer Bureau API**: CIBIL scores and credit history for all identified KMPs
- **Commercial Bureau API**: Commercial credit score and history for borrowing entity
- **GST Compliance API**: Registration status, return filing history, and compliance score
- **GST Transaction API**: Detailed return analysis for turnover verification
- **PAN Status API**: Validate PAN status and any deactivation issues
- **Identity Cross-Reference API**: Validate identity consistency across databases

### **Expected Output**
```json
{
  "agent_name": "verification_compliance",
  "processing_status": "completed",
  "thread_id": "loan_USER001_20240925_143022",
  "processing_metadata": {
    "start_time": "2024-09-25T14:35:43Z",
    "end_time": "2024-09-25T14:38:21Z", 
    "total_processing_time": 158.4,
    "api_calls_made": 12,
    "total_api_cost": 0.34
  },
  "bureau_verification_results": {
    "entity_commercial_bureau": {
      "bureau_provider": "CIBIL",
      "cmr_score": 6,
      "commercial_score": "BB",
      "score_date": "2024-09-20",
      "credit_history_months": 36,
      "total_exposure": 12500000,
      "overdue_amount": 0,
      "status": "pass",
      "risk_indicators": []
    },
    "kmp_consumer_bureaus": [
      {
        "kmp_id": "KMP001",
        "name": "John Doe",
        "pan_number": "XYZPQ5678R",
        "cibil_score": 742,
        "score_date": "2024-09-18",
        "credit_history_months": 84,
        "total_accounts": 8,
        "active_accounts": 6,
        "overdue_accounts": 0,
        "total_exposure": 850000,
        "status": "pass",
        "risk_flags": []
      }
    ],
    "partnership_cibil_compliance": {
      "requirement": "50%_partners_above_680",
      "total_partners": 4,
      "partners_with_scores": 1,
      "partners_above_threshold": 1,
      "compliance_status": "incomplete_data",
      "additional_kmps_needed": 1
    }
  },
  "enhanced_gst_analysis": {
    "gst_compliance": {
      "gst_number": "09ABCDE1234F1Z5",
      "registration_status": "Active",
      "registration_date": "2019-04-15",
      "last_return_filed": "2024-08-20",
      "filing_frequency": "Monthly",
      "compliance_score": 85,
      "pending_returns": 0,
      "status": "pass"
    },
    "gst_transaction_analysis": {
      "analysis_period": "2023-2024",
      "total_turnover": 125000000,
      "average_monthly_turnover": 10416667,
      "turnover_growth_rate": 0.15,
      "major_states": ["Maharashtra", "Gujarat", "Karnataka"],
      "filing_regularity": "consistent",
      "tax_payment_pattern": "timely",
      "revenue_reconciliation": {
        "gst_turnover": 125000000,
        "financial_statement_turnover": 118000000,
        "variance_percentage": 5.9,
        "reconciliation_status": "within_tolerance",
        "tolerance_threshold": 10.0
      }
    }
  },
  "pan_validation": {
    "entity_pan": "ABCDE1234F",
    "pan_status": "Valid",
    "name_match": "Exact",
    "status": "pass"
  },
  "policy_compliance_assessment": {
    "bureau_score_compliance": {
      "consumer_cibil_check": {
        "required": ">=680",
        "achieved": [742],
        "status": "pass"
      },
      "commercial_cmr_check": {
        "required": "1-8",
        "achieved": 6,
        "status": "pass"
      },
      "partnership_cibil_check": {
        "required": "50%_partners_above_680",
        "achieved": "25%_with_data",
        "status": "requires_additional_data"
      }
    },
    "coverage_compliance": {
      "kmp_coverage_check": {
        "required": ">=50%",
        "achieved": "65%",
        "status": "pass"
      }
    },
    "documentation_compliance": {
      "critical_documents_check": {
        "required": ["entity_pan", "kmp_kyc"],
        "status": "pass"
      }
    },
    "gst_compliance_check": {
      "filing_regularity": "pass",
      "turnover_verification": "pass",
      "revenue_reconciliation": "pass"
    }
  },
  "risk_assessment": {
    "overall_risk_score": 0.32,
    "risk_category": "low",
    "risk_grade": "A2",
    "contributing_factors": [
      {
        "factor": "Strong CIBIL scores",
        "impact": "positive",
        "weight": 0.3
      },
      {
        "factor": "Good commercial bureau rating",
        "impact": "positive", 
        "weight": 0.25
      },
      {
        "factor": "Excellent GST compliance",
        "impact": "positive",
        "weight": 0.2
      },
      {
        "factor": "Incomplete partner CIBIL data",
        "impact": "negative",
        "weight": 0.15
      }
    ],
    "mitigating_factors": [],
    "risk_mitigation_required": false
  },
  "eligibility_determination": {
    "overall_eligibility": "conditionally_approved",
    "approval_confidence": 0.85,
    "conditions": [
      "Complete KMP CIBIL score submission for remaining partners",
      "Provide missing ITR documents for complete financial analysis"
    ],
    "recommendations": [
      "Proceed with financial analysis for loan structuring",
      "Collect additional partner bureau reports"
    ]
  },
  "validation_warnings": [
    {
      "type": "incomplete_kmp_bureau_data",
      "message": "Only 25% of partners have bureau scores available",
      "severity": "medium",
      "impact": "requires_manual_review"
    },
    {
      "type": "incomplete_financial_documents",
      "message": "Missing ITR documents for 2022-23, 2021-22 assessment years",
      "severity": "high",
      "impact": "financial_analysis_limited"
    }
  ],
  "next_action": "proceed_to_financial_analysis",
  "routing_decision": {
    "next_agent": "financial_analysis",
    "routing_reason": "Basic compliance checks passed, financial analysis required",
    "conditions_met": [
      "bureau_scores_passed",
      "compliance_verified",
      "risk_assessment_completed"
    ]
  }
}
```

### **Routing Conditions**
- **Approval Route**: If all compliance checks pass  Route to Agent 4 (Financial Analysis)
- **Conditional Approval Route**: If minor issues but overall eligible  Route to Agent 4 with conditions
- **Manual Review Route**: If bureau scores borderline or mixed results  Route to Human Interface
- **Rejection Route**: If critical compliance failures  Route to Rejection Handler

---

## **Agent 4: Financial Analysis Agent (MOVED TO MVP)**

### **Purpose**
Analyze financial statements, bank statements, GST returns, and ITR documents to assess financial health and loan servicing capacity.

### **Call Condition**
- **Triggered by**: Agent 3 completion with conditional or full approval
- **Prerequisites**: Verification passed, financial documents available
- **State Check**: `current_step == "financial_analysis"` and `eligibility_determination.overall_eligibility != "rejected"`

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "agent_context": {
    "previous_agent": "verification_compliance",
    "trigger_reason": "comprehensive_analysis_required"
  },
  "classified_documents": {
    "financial_documents": {...},
    "banking_documents": {...},
    "gst_documents": {...}
  },
  "entity_profile": {...},
  "enhanced_gst_analysis": {...},
  "analysis_requirements": {
    "analysis_period": "24_months",
    "required_ratios": ["current_ratio", "debt_equity_ratio", "turnover_growth", "profitability_margins"],
    "cash_flow_analysis": true,
    "working_capital_assessment": true,
    "debt_service_capacity": true,
    "financial_statement_reconciliation": true
  }
}
```

### **Processing Logic**
1. **Financial Statement Processing**: Extract and analyze 2 years audited + 1 year provisional financials
2. **Ratio Analysis**: Calculate key financial ratios and trends
3. **Bank Statement Integration**: Correlate banking data with financial statements
4. **GST-Financial Reconciliation**: Cross-verify turnover between GST and financials
5. **Cash Flow Analysis**: Assess operating, investing, and financing cash flows
6. **Debt Service Capacity**: Calculate debt service coverage ratio (DSCR)
7. **Working Capital Assessment**: Analyze working capital requirements and cycle
8. **Profitability Analysis**: Evaluate margins and return metrics
9. **Growth Trend Analysis**: Identify revenue and profit growth patterns
10. **Loan Servicing Capacity**: Determine maximum sustainable EMI

### **External API Calls**
- **Financial Data Extraction API**: Advanced financial statement parsing
- **Banking Analytics API**: Transaction pattern analysis
- **Ratio Analysis Engine**: Industry benchmark comparisons
- **Cash Flow Modeling API**: Projection and sensitivity analysis

### **Expected Output**
```json
{
  "agent_name": "financial_analysis",
  "processing_status": "completed",
  "thread_id": "loan_USER001_20240925_143022",
  "processing_metadata": {
    "start_time": "2024-09-25T14:38:22Z",
    "end_time": "2024-09-25T14:41:15Z",
    "total_processing_time": 173.2,
    "api_calls_made": 9,
    "total_api_cost": 0.28
  },
  "financial_health_assessment": {
    "turnover_analysis": {
      "annual_turnover_2023": 118000000,
      "annual_turnover_2022": 102000000,
      "growth_rate": 15.7,
      "industry_benchmark": 12.0,
      "assessment": "above_average"
    },
    "profitability_ratios": {
      "net_profit_margin_2023": 8.2,
      "net_profit_margin_2022": 7.8,
      "gross_profit_margin_2023": 22.5,
      "operating_profit_margin_2023": 12.3,
      "trend": "improving",
      "industry_comparison": "favorable"
    },
    "liquidity_ratios": {
      "current_ratio_2023": 1.8,
      "quick_ratio_2023": 1.2,
      "working_capital": 8500000,
      "assessment": "adequate"
    },
    "leverage_ratios": {
      "debt_equity_ratio_2023": 1.2,
      "debt_service_coverage_ratio": 2.1,
      "interest_coverage_ratio": 4.8,
      "assessment": "manageable"
    },
    "cash_flow_analysis": {
      "operating_cash_flow": 12500000,
      "investing_cash_flow": -4500000,
      "financing_cash_flow": -3000000,
      "free_cash_flow": 8000000,
      "cash_flow_stability": "stable"
    }
  },
  "banking_integration_analysis": {
    "account_analysis": {
      "total_accounts": 3,
      "average_monthly_balance": 1250000,
      "transaction_volume": 2456,
      "account_conduct": "satisfactory"
    },
    "cash_flow_patterns": {
      "monthly_inflows": 9850000,
      "monthly_outflows": 8720000,
      "net_monthly_surplus": 1130000,
      "seasonality_detected": "moderate"
    }
  },
  "gst_financial_reconciliation": {
    "reconciliation_status": "verified",
    "gst_reported_turnover": 125000000,
    "financial_statement_turnover": 118000000,
    "variance_explanation": "timing_differences_export_sales",
    "adjusted_turnover": 121500000
  },
  "loan_servicing_capacity": {
    "monthly_cash_flow": 1130000,
    "debt_service_capacity": 450000,
    "recommended_emi": 380000,
    "debt_service_coverage_ratio": 2.1,
    "maximum_sustainable_loan": 4500000,
    "requested_loan_servicing": {
      "requested_amount": 5000000,
      "estimated_emi": 422000,
      "dscr_at_requested": 1.98,
      "servicing_comfort": "adequate"
    }
  },
  "risk_assessment_enhancement": {
    "financial_risk_score": 0.18,
    "key_strengths": [
      "Strong revenue growth trajectory",
      "Healthy profitability margins",
      "Adequate liquidity position",
      "Stable cash flow generation"
    ],
    "concerns": [
      "Moderate leverage position",
      "Seasonal business patterns"
    ],
    "mitigation_factors": [
      "Strong debt service coverage",
      "Consistent banking conduct"
    ]
  },
  "recommendations": {
    "loan_amount_adjustment": {
      "recommended_amount": 4500000,
      "rationale": "Optimal balance of funding needs and servicing capacity",
      "confidence": 0.88
    },
    "terms_suggestions": {
      "tenure": "36 months",
      "interest_rate": "12.5%",
      "moratorium_period": "3 months"
    }
  },
  "next_action": "proceed_to_banking_analysis",
  "routing_decision": {
    "next_agent": "banking_analysis",
    "routing_reason": "Financial analysis complete, banking validation required",
    "conditions_met": [
      "financial_statements_analyzed",
      "cash_flow_assessed",
      "servicing_capacity_calculated"
    ]
  }
}
```

### **Routing Conditions**
- **Success Route**: If financial health satisfactory  Route to Agent 7 (Banking Analysis)
- **Marginal Route**: If borderline financials  Route to Human Review with recommendations
- **Poor Financials Route**: If inadequate servicing capacity  Route to Rejection Handler
- **Data Quality Issues**: If insufficient financial data  Route to Document Collection

---

## **Agent 7: Banking Analysis Agent (NEW - MVP)**

### **Purpose**
Comprehensive analysis of banking behavior, transaction patterns, cash flow verification, and account conduct assessment.

### **Call Condition**
- **Triggered by**: Agent 4 completion with financial analysis
- **Prerequisites**: Bank statements available and processed
- **State Check**: `current_step == "banking_analysis"` and `classified_documents.banking_documents` exists

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "agent_context": {
    "previous_agent": "financial_analysis",
    "trigger_reason": "banking_validation_required"
  },
  "classified_documents": {
    "banking_documents": {...}
  },
  "financial_analysis": {...},
  "analysis_requirements": {
    "analysis_period": "12_months",
    "transaction_analysis": true,
    "cash_flow_verification": true,
    "account_conduct_assessment": true,
    "pattern_analysis": true
  }
}
```

### **Processing Logic**
1. **Bank Statement Processing**: Extract all transactions and account details
2. **Cash Flow Verification**: Correlate with financial statement cash flows
3. **Transaction Pattern Analysis**: Identify business patterns and anomalies
4. **Account Conduct Assessment**: Evaluate banking behavior and relationships
5. **Balance Analysis**: Assess average balances and volatility
6. **Bounce Analysis**: Check for cheque returns or payment failures
7. **Integration with Financials**: Verify consistency with reported numbers
8. **Risk Pattern Detection**: Identify suspicious or risky transaction patterns

### **Expected Output**
```json
{
  "agent_name": "banking_analysis",
  "processing_status": "completed",
  "thread_id": "loan_USER001_20240925_143022",
  "banking_assessment": {
    "account_summary": {
      "total_accounts_analyzed": 3,
      "current_accounts": 2,
      "od_cc_accounts": 1,
      "analysis_period": "12 months"
    },
    "cash_flow_analysis": {
      "average_monthly_credits": 9850000,
      "average_monthly_debits": 8720000,
      "net_monthly_surplus": 1130000,
      "cash_flow_consistency": "high",
      "seasonality_adjusted_flow": 1050000
    },
    "account_conduct": {
      "average_balance": 1250000,
      "minimum_balance": 450000,
      "od_utilization": 35.2,
      "bounce_incidents": 2,
      "conduct_rating": "satisfactory"
    },
    "transaction_patterns": {
      "primary_business_pattern": "wholesale_trading",
      "major_counterparties": ["Supplier A", "Customer B", "Customer C"],
      "transaction_regularity": "consistent",
      "anomalies_detected": 3,
      "anomaly_severity": "low"
    },
    "financial_integration": {
      "reported_turnover_vs_banking": "consistent",
      "cash_flow_reconciliation": "verified",
      "discrepancies": "minimal"
    }
  },
  "next_action": "proceed_to_final_assembly"
}
```

---

## **Agent 5: Relationship Mapping Agent (Phase 2)**

### **Purpose**
Identify and analyze group companies, related entities, and corporate family tree to assess overall group exposure and risk.

### **Call Condition**
- **Triggered by**: Agent 4 completion or when group companies detected in KMP income sources
- **Prerequisites**: KMP ITR analysis showing income from other entities
- **State Check**: `group_companies_detected == true` or `comprehensive_due_diligence_required == true`

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "kmp_income_analysis": {...},
  "detected_related_entities": [...],
  "relationship_mapping_requirements": {
    "minimum_shareholding_threshold": 0.1,
    "include_indirect_holdings": true,
    "analyze_group_financials": true
  }
}
```

### **Expected Output**
```json
{
  "agent_name": "relationship_mapping",
  "corporate_family_tree": {...},
  "group_exposure_analysis": {...},
  "consolidated_risk_assessment": {...},
  "next_action": "proceed_to_final_assembly"
}
```

---

## **Agent 6: Final Assembly & Report Generation Agent (UPDATED)**

### **Purpose**
Consolidate all processed information into a comprehensive loan application report for human underwriter review and decision-making.

### **Call Condition**
- **Triggered by**: Agent 7 completion (Banking Analysis) in MVP
- **Prerequisites**: All mandatory validations completed, eligibility determined
- **State Check**: `banking_analysis_completed == true` and `eligibility != "rejected"`

### **Input Specifications**
```json
{
  "thread_id": "loan_USER001_20240925_143022",
  "consolidated_data": {
    "classified_documents": {...},
    "entity_profile": {...},
    "kmp_analysis": {...},
    "verification_results": {...},
    "financial_analysis": {...},
    "banking_analysis": {...},
    "relationship_mapping": {...}  // Optional - Phase 2
  },
  "report_configuration": {
    "report_type": "comprehensive",
    "include_supporting_documents": true,
    "generate_executive_summary": true,
    "output_formats": ["structured_json", "pdf_report", "excel_workbook"]
  }
}
```

### **Processing Logic**
1. **Data Consolidation**: Merge and validate all agent outputs for consistency
2. **Executive Summary Generation**: Create high-level summary for quick underwriter review
3. **Risk Profile Compilation**: Aggregate all risk factors and mitigation strategies
4. **Financial Capacity Integration**: Incorporate banking and financial analysis
5. **Document Package Assembly**: Organize all supporting documents with clear labeling
6. **Recommendation Formulation**: Generate clear recommendation with supporting rationale
7. **Quality Assurance**: Final validation of data completeness and accuracy
8. **Multi-Format Report Generation**: Create reports in multiple formats for different stakeholders

### **Expected Output**
```json
{
  "agent_name": "final_assembly",
  "processing_status": "completed",
  "thread_id": "loan_USER001_20240925_143022",
  "processing_metadata": {
    "start_time": "2024-09-25T14:41:16Z",
    "end_time": "2024-09-25T14:43:15Z",
    "total_processing_time": 119.8,
    "total_workflow_time": 768.3,
    "total_api_cost": 1.08
  },
  "executive_summary": {
    "application_id": "LOAN_2024_001",
    "borrower_name": "ABC Enterprises",
    "loan_request": {
      "amount": 5000000,
      "type": "MSM_supply_chain",
      "purpose": "Working capital financing"
    },
    "recommendation": "CONDITIONALLY APPROVED",
    "risk_grade": "A2",
    "processing_confidence": 0.85,
    "recommended_loan_amount": 4500000
  },
  "comprehensive_borrower_profile": {
    "entity_summary": {
      "legal_name": "ABC Enterprises", 
      "constitution": "Partnership",
      "pan_number": "ABCDE1234F",
      "gst_number": "09ABCDE1234F1Z5",
      "date_of_establishment": "2019-02-20",
      "registered_address": "123 Business Street, Mumbai, Maharashtra 400001",
      "business_activity": "Trading and Services",
      "msm_classification": "Small Enterprise"
    },
    "kmp_summary": [
      {
        "name": "John Doe",
        "role": "Partner",
        "shareholding": "30%",
        "pan_number": "XYZPQ5678R",
        "cibil_score": 742,
        "kyc_status": "Complete",
        "risk_flags": "None"
      },
      {
        "name": "Jane Smith",
        "role": "Partner", 
        "shareholding": "35%",
        "kyc_status": "Incomplete",
        "missing_documents": ["PAN Card", "Aadhaar Card"]
      }
    ],
    "financial_summary": {
      "annual_turnover": "11.8 Cr (2023)",
      "growth_rate": "15.7%",
      "net_profit_margin": "8.2%",
      "debt_equity_ratio": "1.2",
      "working_capital": "85 Lakhs",
      "debt_service_capacity": "4.5 Lakhs/month"
    },
    "banking_summary": {
      "accounts_analyzed": 3,
      "average_balance": "12.5 Lakhs",
      "monthly_cash_flow": "11.3 Lakhs",
      "account_conduct": "Satisfactory"
    }
  },
  "verification_summary": {
    "entity_commercial_score": {
      "cmr_score": 6,
      "grade": "BB",
      "status": "Pass"
    },
    "kmp_consumer_scores": {
      "average_cibil": 742,
      "lowest_score": 742,
      "all_above_threshold": true
    },
    "compliance_status": {
      "gst_compliance": "Active & Compliant",
      "pan_validation": "Valid",
      "documentation": "Adequate"
    }
  },
  "risk_assessment_summary": {
    "overall_risk_score": 0.28,
    "risk_category": "Low",
    "risk_grade": "A2",
    "key_strengths": [
      "Strong CIBIL scores across KMPs",
      "Excellent GST compliance history",
      "Good commercial bureau rating",
      "Adequate partner coverage (65%)",
      "Healthy financial performance",
      "Stable banking conduct"
    ],
    "areas_of_concern": [
      "Incomplete KMP documentation (35% shareholding)",
      "Incomplete partner CIBIL data",
      "Moderate leverage position"
    ],
    "recommended_mitigations": [
      "Collect remaining partner KYC documents",
      "Obtain bureau reports for additional partners",
      "Monitor leverage ratios during loan tenure"
    ]
  },
  "loan_recommendation": {
    "primary_recommendation": "APPROVED WITH CONDITIONS",
    "confidence_level": "High (85%)",
    "recommended_loan_amount": 4500000,
    "suggested_conditions": [
      "Complete KMP documentation for 35% shareholding partners",
      "Submit bureau reports for remaining partners",
      "Standard security and documentation",
      "Regular financial monitoring during loan period"
    ],
    "proposed_terms": {
      "loan_amount": 4500000,
      "tenure": "36 months",
      "interest_rate": "12.5%",
      "emi": "150,000",
      "dscr": 2.1
    },
    "estimated_processing_timeline": "3-5 business days",
    "next_steps": [
      "Underwriter review of conditions",
      "Collection of pending documents",
      "Final credit committee approval"
    ]
  },
  // ... [rest of the output remains similar with enhanced financial and banking sections]
}
```

### **Routing Conditions**
- **Completion Route**: Workflow complete  Store final report and notify human underwriter
- **Enhancement Route**: If group companies identified  Route to Agent 5 (Relationship Mapping)
- **Reprocessing Route**: If critical errors found  Route back to appropriate agent
- **Approval Route**: If auto-approval criteria met  Route to Loan Processing System

---

## **Updated Implementation Roadmap**

### **Phase 1: MVP (Agents 1, 2, 3, 4, 7, 6) - 10-12 Weeks**

#### **Week 1-2: Foundation Setup**
- LangGraph environment setup with PostgreSQL persistence
- Basic state management and thread configuration
- Integration with existing PDF/Image Processing Service
- Core data models and validation schemas

#### **Week 3-4: Agent 1 Development**
- Document classification logic implementation
- API integration with existing document service
- Financial and banking document identification
- Quality assessment and confidence scoring

#### **Week 5-6: Agent 2 Development**
- Entity constitution determination logic
- KMP identification and matching algorithms
- Basic group company identification
- External API integrations (PAN, MCA)

#### **Week 7-8: Agent 3 Development**
- Bureau score integration (CIBIL, Commercial)
- Enhanced GST analysis and transaction processing
- Compliance checking engine
- Risk assessment algorithms

#### **Week 9-10: Agent 4 & 7 Development**
- Financial statement analysis engine
- Banking statement processing algorithms
- Cash flow and ratio analysis
- Loan servicing capacity assessment

#### **Week 11-12: Agent 6 & Integration**
- Final report generation system with financial integration
- Multi-format output generation
- End-to-end workflow testing
- Human interface development

### **Phase 2: Enhanced Processing (Agent 5) - 4-6 Weeks**

#### **Week 13-16: Agent 5 Development**
- Group company identification logic
- Relationship mapping algorithms
- Consolidated risk assessment
- Corporate structure analysis

### **Phase 3: Production Hardening - 4-6 Weeks**

#### **Week 17-20: Production Readiness**
- Performance optimization and caching
- Security hardening and data protection
- Monitoring and alerting systems
- Load testing and scalability validation

#### **Week 21-22: Deployment & Training**
- Production deployment and configuration
- User training and documentation
- Go-live support and monitoring
- Performance tuning and optimization

---
</file>

</files>
